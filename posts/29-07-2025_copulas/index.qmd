---
title: "A Visual Introduction to Copulas"
abstract: "This post offers a concise and intuitive introduction to copula theory, explaining what copulas are, why they are useful, and how they are applied in finance. We'll skip the heavy math and focus on the core ideas."
categories:
  - Statistics
  - Finance
  - Python
author: "Jan Schlegel"
date: "2025-07-29"
format:
  html:
    code-fold: true
    toc: true
    toc-depth: 3
number-sections: true
fig-width: 10
fig-height: 6
fig-dpi: 150
fig-format: png
jupyter: python3
---

![Copulas provide a powerful framework for modeling complex dependence structures while separating marginal distributions from their joint behavior](img/copula_theory_thumbnail.png)

```{python}
#| echo: false
#| output: false

import sys
import os
sys.path.append('/home/janhsc/Documents/projects/JHSchlegel.github.io/.venv/lib/python3.10/site-packages')

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.optimize import minimize, minimize_scalar
from scipy.special import gamma, digamma, polygamma
from scipy.integrate import quad, dblquad
from scipy.linalg import cholesky, solve_triangular
import warnings
warnings.filterwarnings('ignore')

plt.style.use('seaborn-v0_8-whitegrid')
sns.set_palette("husl")
plt.rcParams['figure.dpi'] = 150
plt.rcParams['savefig.dpi'] = 150
plt.rcParams['savefig.bbox'] = 'tight'
plt.rcParams['savefig.pad_inches'] = 0.1
plt.rcParams['font.size'] = 12
plt.rcParams['axes.titlesize'] = 14
plt.rcParams['axes.labelsize'] = 12
plt.rcParams['xtick.labelsize'] = 10
plt.rcParams['ytick.labelsize'] = 10
plt.rcParams['legend.fontsize'] = 10
plt.rcParams['figure.constrained_layout.use'] = False
```

## What are Copulas?

Have you ever tried to model the relationship between two or more variables, but found that they don't follow a nice, clean multivariate normal distribution? Real-world data, especially in finance, is often messy. Variables can have different distributions (some normal, some skewed, some with fat tails), and their dependence can be more complicated than simple linear correlation.

This is where copulas come in. The word "copula" means "link" or "tie," and that's exactly what they do: they **link** marginal distributions of variables together to form a multivariate distribution. The key idea is to separate the dependence structure from the marginal distributions. This means you can model the distribution of each variable on its own, and then use a copula to describe how they move together.

This separation is incredibly powerful. It allows us to model complex dependencies, like the tendency of assets to crash together in a financial crisis (tail dependence), without being constrained by assumptions like normality.

## Sklar's Theorem: The Core Idea

The magic behind copulas is formalized by Sklar's Theorem. In simple terms, the theorem states that any multivariate distribution can be broken down into two parts:

1.  The individual marginal distributions of each variable.
2.  A copula function that describes the dependence structure between them.

For a two-variable case, if you have a joint distribution $F(x_1, x_2)$ with marginals $F_1(x_1)$ and $F_2(x_2)$, Sklar's theorem says:

$$ F(x_1, x_2) = C(F_1(x_1), F_2(x_2)) $$

Here, $C$ is the copula. It's a function that takes the marginal probabilities (which are between 0 and 1) and combines them to give the joint probability.

The plot below illustrates this. We start with two variables that have a certain dependence (a Gaussian copula). We can then apply different marginal distributions (Normal, t-distribution, Exponential) to them, and the underlying dependence structure is preserved.

```{python}
#| label: fig-motivation
#| fig-cap: "The same dependence structure (copula) can be combined with different marginal distributions."
#| fig-width: 12
#| fig-height: 8

np.random.seed(42)
n = 1000

# Generate data with different marginal distributions but same dependence
rho = 0.7
Z = np.random.multivariate_normal([0, 0], [[1, rho], [rho, 1]], n)

# Transform to different margins while preserving dependence
X1 = stats.norm.cdf(Z[:, 0])  # Uniform margins
X2 = stats.norm.cdf(Z[:, 1])

# Apply different marginal transformations
Y1 = stats.norm.ppf(X1)  # Normal margins (original)
Y2_normal = stats.norm.ppf(X2)
Y2_t = stats.t.ppf(X2, df=3)  # t-distribution margins
Y2_exp = stats.expon.ppf(X2)  # Exponential margins

fig, axes = plt.subplots(2, 2, figsize=(12, 8))

# Original data (bivariate normal)
axes[0, 0].scatter(Y1, Y2_normal, alpha=0.6, s=20)
axes[0, 0].set_title('Bivariate Normal')
axes[0, 0].set_xlabel('X₁ ~ N(0,1)')
axes[0, 0].set_ylabel('X₂ ~ N(0,1)')

# Same copula, different margins
axes[0, 1].scatter(Y1, Y2_t, alpha=0.6, s=20, color='orange')
axes[0, 1].set_title('Normal-t Margins')
axes[0, 1].set_xlabel('X₁ ~ N(0,1)')
axes[0, 1].set_ylabel('X₂ ~ t(3)')

axes[1, 0].scatter(Y1, Y2_exp, alpha=0.6, s=20, color='green')
axes[1, 0].set_title('Normal-Exponential Margins')
axes[1, 0].set_xlabel('X₁ ~ N(0,1)')
axes[1, 0].set_ylabel('X₂ ~ Exp(1)')

# Copula data (uniform margins)
axes[1, 1].scatter(X1, X2, alpha=0.6, s=20, color='red')
axes[1, 1].set_title('Underlying Copula (Dependence Structure)')
axes[1, 1].set_xlabel('U₁ ~ U(0,1)')
axes[1, 1].set_ylabel('U₂ ~ U(0,1)')

plt.tight_layout()
plt.show()
```

## Common Copula Families

There are many different families of copulas, each capturing a different type of dependence. Here are a few common ones.

### Archimedean Copulas

These are constructed from a function called a generator. They are popular because they are easy to construct and can model a wide range of dependence patterns.

*   **Clayton Copula:** Good for modeling lower tail dependence. Think of a financial crisis where different stocks crash together.
*   **Gumbel Copula:** Good for modeling upper tail dependence. This could be useful for modeling assets that experience simultaneous extreme positive returns.
*   **Frank Copula:** Models symmetric dependence, but without tail dependence.

The plot below shows how these three copulas capture different dependence structures.

```{python}
#| label: fig-archimedean-families
#| fig-cap: "Comparison of major Archimedean copula families."
#| fig-width: 15
#| fig-height: 5

# Create evaluation grid
u = np.linspace(0.01, 0.99, 100)
U1, U2 = np.meshgrid(u, u)

# Define Clayton copula for comparison
theta_clayton = 2
C_clayton = np.maximum((U1**(-theta_clayton) + U2**(-theta_clayton) - 1)**(-1/theta_clayton), 0)

# Define Gumbel copula
theta_gumbel = 2
C_gumbel = np.exp(-((-np.log(U1))**theta_gumbel + (-np.log(U2))**theta_gumbel)**(1/theta_gumbel))

# Define Frank copula
theta_frank = 5
C_frank = -1/theta_frank * np.log(1 + (np.exp(-theta_frank * U1) - 1) * (np.exp(-theta_frank * U2) - 1) / (np.exp(-theta_frank) - 1))

fig, axes = plt.subplots(1, 3, figsize=(15, 5))
levels = np.linspace(0, 1, 20)

# Clayton
im1 = axes[0].contourf(U1, U2, C_clayton, levels=levels, cmap='viridis')
axes[0].set_title(f'Clayton Copula (θ={theta_clayton})\n(Lower Tail Dependence)')
axes[0].set_xlabel('$u_1$')
axes[0].set_ylabel('$u_2$')
fig.colorbar(im1, ax=axes[0])

# Gumbel
im2 = axes[1].contourf(U1, U2, C_gumbel, levels=levels, cmap='viridis')
axes[1].set_title(f'Gumbel Copula (θ={theta_gumbel})\n(Upper Tail Dependence)')
axes[1].set_xlabel('$u_1$')
axes[1].set_ylabel('$u_2$')
fig.colorbar(im2, ax=axes[1])

# Frank
im3 = axes[2].contourf(U1, U2, C_frank, levels=levels, cmap='viridis')
axes[2].set_title(f'Frank Copula (θ={theta_frank})\n(Symmetric Dependence)')
axes[2].set_xlabel('$u_1$')
axes[2].set_ylabel('$u_2$')
fig.colorbar(im3, ax=axes[2])

plt.tight_layout()
plt.show()
```

### Elliptical Copulas

These are derived from elliptical distributions like the Normal and Student's t distributions.

*   **Gaussian Copula:** This is the copula of the multivariate normal distribution. It's defined by the correlation matrix, but it doesn't have tail dependence. This means it's not great at modeling extreme events.
*   **Student's t Copula:** This copula is derived from the multivariate t-distribution. It has a "degrees of freedom" parameter that allows it to model tail dependence, making it very useful in finance.

The plot below shows simulated data from a Gaussian and a Student's t copula. Notice how the t-copula has more points in the corners (the tails), indicating tail dependence.

```{python}
#| label: fig-elliptical-copulas
#| fig-cap: "Gaussian vs. Student's t copula simulations."
#| fig-width: 12
#| fig-height: 6

# Parameters
rho = 0.7
nu = 3
n_sim = 2000
np.random.seed(42)

# Gaussian copula simulation
mean_gauss = [0, 0]
cov_gauss = [[1, rho], [rho, 1]]
gauss_samples = np.random.multivariate_normal(mean_gauss, cov_gauss, n_sim)
u_gauss = stats.norm.cdf(gauss_samples)

# Student's t copula simulation
t_samples = np.random.multivariate_normal(mean_gauss, cov_gauss, n_sim)
chi2_samples = np.random.chisquare(nu, n_sim)
t_samples = t_samples * np.sqrt(nu / chi2_samples[:, np.newaxis])
u_t = stats.t.cdf(t_samples, nu)

fig, axes = plt.subplots(1, 2, figsize=(12, 6))

axes[0].scatter(u_gauss[:, 0], u_gauss[:, 1], alpha=0.5, s=15)
axes[0].set_title(f'Gaussian Copula (ρ={rho})')
axes[0].set_xlabel('$u_1$')
axes[0].set_ylabel('$u_2$')
axes[0].set_aspect('equal', adjustable='box')


axes[1].scatter(u_t[:, 0], u_t[:, 1], alpha=0.5, s=15)
axes[1].set_title(f"Student's t Copula (ρ={rho}, ν={nu})")
axes[1].set_xlabel('$u_1$')
axes[1].set_ylabel('$u_2$')
axes[1].set_aspect('equal', adjustable='box')

plt.tight_layout()
plt.show()
```

## A Quick Look at Financial Applications

One of the most common uses of copulas is in financial risk management. Let's say you have a portfolio of assets and you want to calculate its Value-at-Risk (VaR), which is the maximum loss you can expect with a certain confidence level.

A traditional approach might assume that asset returns are multivariate normal. However, we know this is often not true. With copulas, we can build a more realistic model:

1.  Model the marginal distribution of each asset's returns individually. We can use a distribution that captures fat tails, like the Student's t-distribution.
2.  Use a copula (e.g., a Student's t copula) to model the dependence between the assets. This will capture the tendency of assets to move together, especially in downturns.
3.  Simulate thousands of scenarios for the portfolio's return from this copula-based model.
4.  Calculate VaR from the simulated returns.

This approach gives a much more accurate picture of the portfolio's risk than traditional methods that rely on unrealistic assumptions.

## Conclusion

Copulas are a powerful tool for modeling complex dependencies in data. By separating the dependence structure from the marginal distributions, they provide a flexibility that is missing in many classical statistical models. While the mathematics can get complicated, the core idea is simple and intuitive. They are especially useful in finance, where they help us build more realistic models of risk.
