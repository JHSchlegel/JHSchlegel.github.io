[
  {
    "objectID": "posts/29-07-2025_copulas/index.html",
    "href": "posts/29-07-2025_copulas/index.html",
    "title": "A Visual Introduction to Copulas",
    "section": "",
    "text": "Copulas provide a powerful framework for modeling complex dependence structures while separating marginal distributions from their joint behavior"
  },
  {
    "objectID": "posts/29-07-2025_copulas/index.html#what-are-copulas",
    "href": "posts/29-07-2025_copulas/index.html#what-are-copulas",
    "title": "A Visual Introduction to Copulas",
    "section": "1 What are Copulas?",
    "text": "1 What are Copulas?\nHave you ever tried to model the relationship between two or more variables, but found that they don’t follow a nice, clean multivariate normal distribution? Real-world data, especially in finance, is often messy. Variables can have different distributions (some normal, some skewed, some with fat tails), and their dependence can be more complicated than simple linear correlation.\nThis is where copulas come in. The word “copula” means “link” or “tie,” and that’s exactly what they do: they link marginal distributions of variables together to form a multivariate distribution. The key idea is to separate the dependence structure from the marginal distributions. This means you can model the distribution of each variable on its own, and then use a copula to describe how they move together.\nThis separation is incredibly powerful. It allows us to model complex dependencies, like the tendency of assets to crash together in a financial crisis (tail dependence), without being constrained by assumptions like normality."
  },
  {
    "objectID": "posts/29-07-2025_copulas/index.html#sklars-theorem-the-core-idea",
    "href": "posts/29-07-2025_copulas/index.html#sklars-theorem-the-core-idea",
    "title": "A Visual Introduction to Copulas",
    "section": "2 Sklar’s Theorem: The Core Idea",
    "text": "2 Sklar’s Theorem: The Core Idea\nThe magic behind copulas is formalized by Sklar’s Theorem. In simple terms, the theorem states that any multivariate distribution can be broken down into two parts:\n\nThe individual marginal distributions of each variable.\nA copula function that describes the dependence structure between them.\n\nFor a two-variable case, if you have a joint distribution \\(F(x_1, x_2)\\) with marginals \\(F_1(x_1)\\) and \\(F_2(x_2)\\), Sklar’s theorem says:\n\\[ F(x_1, x_2) = C(F_1(x_1), F_2(x_2)) \\]\nHere, \\(C\\) is the copula. It’s a function that takes the marginal probabilities (which are between 0 and 1) and combines them to give the joint probability.\nThe plot below illustrates this. We start with two variables that have a certain dependence (a Gaussian copula). We can then apply different marginal distributions (Normal, t-distribution, Exponential) to them, and the underlying dependence structure is preserved.\n\n\nCode\nnp.random.seed(42)\nn = 1000\n\n# Generate data with different marginal distributions but same dependence\nrho = 0.7\nZ = np.random.multivariate_normal([0, 0], [[1, rho], [rho, 1]], n)\n\n# Transform to different margins while preserving dependence\nX1 = stats.norm.cdf(Z[:, 0])  # Uniform margins\nX2 = stats.norm.cdf(Z[:, 1])\n\n# Apply different marginal transformations\nY1 = stats.norm.ppf(X1)  # Normal margins (original)\nY2_normal = stats.norm.ppf(X2)\nY2_t = stats.t.ppf(X2, df=3)  # t-distribution margins\nY2_exp = stats.expon.ppf(X2)  # Exponential margins\n\nfig, axes = plt.subplots(2, 2, figsize=(12, 8))\n\n# Original data (bivariate normal)\naxes[0, 0].scatter(Y1, Y2_normal, alpha=0.6, s=20)\naxes[0, 0].set_title('Bivariate Normal')\naxes[0, 0].set_xlabel('X₁ ~ N(0,1)')\naxes[0, 0].set_ylabel('X₂ ~ N(0,1)')\n\n# Same copula, different margins\naxes[0, 1].scatter(Y1, Y2_t, alpha=0.6, s=20, color='orange')\naxes[0, 1].set_title('Normal-t Margins')\naxes[0, 1].set_xlabel('X₁ ~ N(0,1)')\naxes[0, 1].set_ylabel('X₂ ~ t(3)')\n\naxes[1, 0].scatter(Y1, Y2_exp, alpha=0.6, s=20, color='green')\naxes[1, 0].set_title('Normal-Exponential Margins')\naxes[1, 0].set_xlabel('X₁ ~ N(0,1)')\naxes[1, 0].set_ylabel('X₂ ~ Exp(1)')\n\n# Copula data (uniform margins)\naxes[1, 1].scatter(X1, X2, alpha=0.6, s=20, color='red')\naxes[1, 1].set_title('Underlying Copula (Dependence Structure)')\naxes[1, 1].set_xlabel('U₁ ~ U(0,1)')\naxes[1, 1].set_ylabel('U₂ ~ U(0,1)')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1: The same dependence structure (copula) can be combined with different marginal distributions."
  },
  {
    "objectID": "posts/29-07-2025_copulas/index.html#common-copula-families",
    "href": "posts/29-07-2025_copulas/index.html#common-copula-families",
    "title": "A Visual Introduction to Copulas",
    "section": "3 Common Copula Families",
    "text": "3 Common Copula Families\nThere are many different families of copulas, each capturing a different type of dependence. Here are a few common ones.\n\n3.1 Archimedean Copulas\nThese are constructed from a function called a generator. They are popular because they are easy to construct and can model a wide range of dependence patterns.\n\nClayton Copula: Good for modeling lower tail dependence. Think of a financial crisis where different stocks crash together.\nGumbel Copula: Good for modeling upper tail dependence. This could be useful for modeling assets that experience simultaneous extreme positive returns.\nFrank Copula: Models symmetric dependence, but without tail dependence.\n\nThe plot below shows how these three copulas capture different dependence structures.\n\n\nCode\n# Create evaluation grid\nu = np.linspace(0.01, 0.99, 100)\nU1, U2 = np.meshgrid(u, u)\n\n# Define Clayton copula for comparison\ntheta_clayton = 2\nC_clayton = np.maximum((U1**(-theta_clayton) + U2**(-theta_clayton) - 1)**(-1/theta_clayton), 0)\n\n# Define Gumbel copula\ntheta_gumbel = 2\nC_gumbel = np.exp(-((-np.log(U1))**theta_gumbel + (-np.log(U2))**theta_gumbel)**(1/theta_gumbel))\n\n# Define Frank copula\ntheta_frank = 5\nC_frank = -1/theta_frank * np.log(1 + (np.exp(-theta_frank * U1) - 1) * (np.exp(-theta_frank * U2) - 1) / (np.exp(-theta_frank) - 1))\n\nfig, axes = plt.subplots(1, 3, figsize=(15, 5))\nlevels = np.linspace(0, 1, 20)\n\n# Clayton\nim1 = axes[0].contourf(U1, U2, C_clayton, levels=levels, cmap='viridis')\naxes[0].set_title(f'Clayton Copula (θ={theta_clayton})\\n(Lower Tail Dependence)')\naxes[0].set_xlabel('$u_1$')\naxes[0].set_ylabel('$u_2$')\nfig.colorbar(im1, ax=axes[0])\n\n# Gumbel\nim2 = axes[1].contourf(U1, U2, C_gumbel, levels=levels, cmap='viridis')\naxes[1].set_title(f'Gumbel Copula (θ={theta_gumbel})\\n(Upper Tail Dependence)')\naxes[1].set_xlabel('$u_1$')\naxes[1].set_ylabel('$u_2$')\nfig.colorbar(im2, ax=axes[1])\n\n# Frank\nim3 = axes[2].contourf(U1, U2, C_frank, levels=levels, cmap='viridis')\naxes[2].set_title(f'Frank Copula (θ={theta_frank})\\n(Symmetric Dependence)')\naxes[2].set_xlabel('$u_1$')\naxes[2].set_ylabel('$u_2$')\nfig.colorbar(im3, ax=axes[2])\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 2: Comparison of major Archimedean copula families.\n\n\n\n\n\n\n\n3.2 Elliptical Copulas\nThese are derived from elliptical distributions like the Normal and Student’s t distributions.\n\nGaussian Copula: This is the copula of the multivariate normal distribution. It’s defined by the correlation matrix, but it doesn’t have tail dependence. This means it’s not great at modeling extreme events.\nStudent’s t Copula: This copula is derived from the multivariate t-distribution. It has a “degrees of freedom” parameter that allows it to model tail dependence, making it very useful in finance.\n\nThe plot below shows simulated data from a Gaussian and a Student’s t copula. Notice how the t-copula has more points in the corners (the tails), indicating tail dependence.\n\n\nCode\n# Parameters\nrho = 0.7\nnu = 3\nn_sim = 2000\nnp.random.seed(42)\n\n# Gaussian copula simulation\nmean_gauss = [0, 0]\ncov_gauss = [[1, rho], [rho, 1]]\ngauss_samples = np.random.multivariate_normal(mean_gauss, cov_gauss, n_sim)\nu_gauss = stats.norm.cdf(gauss_samples)\n\n# Student's t copula simulation\nt_samples = np.random.multivariate_normal(mean_gauss, cov_gauss, n_sim)\nchi2_samples = np.random.chisquare(nu, n_sim)\nt_samples = t_samples * np.sqrt(nu / chi2_samples[:, np.newaxis])\nu_t = stats.t.cdf(t_samples, nu)\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 6))\n\naxes[0].scatter(u_gauss[:, 0], u_gauss[:, 1], alpha=0.5, s=15)\naxes[0].set_title(f'Gaussian Copula (ρ={rho})')\naxes[0].set_xlabel('$u_1$')\naxes[0].set_ylabel('$u_2$')\naxes[0].set_aspect('equal', adjustable='box')\n\n\naxes[1].scatter(u_t[:, 0], u_t[:, 1], alpha=0.5, s=15)\naxes[1].set_title(f\"Student's t Copula (ρ={rho}, ν={nu})\")\naxes[1].set_xlabel('$u_1$')\naxes[1].set_ylabel('$u_2$')\naxes[1].set_aspect('equal', adjustable='box')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 3: Gaussian vs. Student’s t copula simulations."
  },
  {
    "objectID": "posts/29-07-2025_copulas/index.html#a-quick-look-at-financial-applications",
    "href": "posts/29-07-2025_copulas/index.html#a-quick-look-at-financial-applications",
    "title": "A Visual Introduction to Copulas",
    "section": "4 A Quick Look at Financial Applications",
    "text": "4 A Quick Look at Financial Applications\nOne of the most common uses of copulas is in financial risk management. Let’s say you have a portfolio of assets and you want to calculate its Value-at-Risk (VaR), which is the maximum loss you can expect with a certain confidence level.\nA traditional approach might assume that asset returns are multivariate normal. However, we know this is often not true. With copulas, we can build a more realistic model:\n\nModel the marginal distribution of each asset’s returns individually. We can use a distribution that captures fat tails, like the Student’s t-distribution.\nUse a copula (e.g., a Student’s t copula) to model the dependence between the assets. This will capture the tendency of assets to move together, especially in downturns.\nSimulate thousands of scenarios for the portfolio’s return from this copula-based model.\nCalculate VaR from the simulated returns.\n\nThis approach gives a much more accurate picture of the portfolio’s risk than traditional methods that rely on unrealistic assumptions."
  },
  {
    "objectID": "posts/29-07-2025_copulas/index.html#conclusion",
    "href": "posts/29-07-2025_copulas/index.html#conclusion",
    "title": "A Visual Introduction to Copulas",
    "section": "5 Conclusion",
    "text": "5 Conclusion\nCopulas are a powerful tool for modeling complex dependencies in data. By separating the dependence structure from the marginal distributions, they provide a flexibility that is missing in many classical statistical models. While the mathematics can get complicated, the core idea is simple and intuitive. They are especially useful in finance, where they help us build more realistic models of risk."
  },
  {
    "objectID": "posts/23-11-2025_covariance-shrinkage/index.html",
    "href": "posts/23-11-2025_covariance-shrinkage/index.html",
    "title": "Covariance Shrinkage: From Linear Shrinkage to Random Matrix Theory",
    "section": "",
    "text": "The estimation of the covariance matrix \\(\\Sigma \\in \\mathbb{R}^{N \\times N}\\) is a fundamental problem in multivariate statistics, essential for portfolio optimization, risk management, and dimensionality reduction. The standard estimator, the sample covariance matrix \\(S\\), is unbiased and converges to \\(\\Sigma\\) as the sample size \\(T \\to \\infty\\) while \\(N\\) remains fixed. However, in modern applications (e.g., genomics, finance), we often face the “large \\(N\\), small \\(T\\)” regime, or more generally, the asymptotic regime where both \\(N, T \\to \\infty\\) such that \\(N/T \\to q \\in (0, \\infty)\\).\nIn this regime, \\(S\\) becomes ill-conditioned or singular (if \\(N &gt; T\\)). Even when invertible, its eigenvalues are systematically distorted: small eigenvalues are underestimated, and large eigenvalues are overestimated. This phenomenon is rigorously described by Random Matrix Theory (RMT).\nThis post explores three major approaches to mitigate these issues:\n\nLinear Shrinkage: Pulling the sample covariance towards a structured target (Ledoit & Wolf 2004).\nSpectral Analysis: Understanding the limiting distribution of eigenvalues via the Marchenko-Pastur law.\nNonlinear Shrinkage: Optimally correcting the eigenvalues individually using the “Direct Kernel” method (Ledoit & Wolf 2020).\n\nWe will implement these concepts in Python and validate them through simulation."
  },
  {
    "objectID": "posts/23-11-2025_covariance-shrinkage/index.html#introduction",
    "href": "posts/23-11-2025_covariance-shrinkage/index.html#introduction",
    "title": "Covariance Shrinkage: From Linear Shrinkage to Random Matrix Theory",
    "section": "",
    "text": "The estimation of the covariance matrix \\(\\Sigma \\in \\mathbb{R}^{N \\times N}\\) is a fundamental problem in multivariate statistics, essential for portfolio optimization, risk management, and dimensionality reduction. The standard estimator, the sample covariance matrix \\(S\\), is unbiased and converges to \\(\\Sigma\\) as the sample size \\(T \\to \\infty\\) while \\(N\\) remains fixed. However, in modern applications (e.g., genomics, finance), we often face the “large \\(N\\), small \\(T\\)” regime, or more generally, the asymptotic regime where both \\(N, T \\to \\infty\\) such that \\(N/T \\to q \\in (0, \\infty)\\).\nIn this regime, \\(S\\) becomes ill-conditioned or singular (if \\(N &gt; T\\)). Even when invertible, its eigenvalues are systematically distorted: small eigenvalues are underestimated, and large eigenvalues are overestimated. This phenomenon is rigorously described by Random Matrix Theory (RMT).\nThis post explores three major approaches to mitigate these issues:\n\nLinear Shrinkage: Pulling the sample covariance towards a structured target (Ledoit & Wolf 2004).\nSpectral Analysis: Understanding the limiting distribution of eigenvalues via the Marchenko-Pastur law.\nNonlinear Shrinkage: Optimally correcting the eigenvalues individually using the “Direct Kernel” method (Ledoit & Wolf 2020).\n\nWe will implement these concepts in Python and validate them through simulation."
  },
  {
    "objectID": "posts/23-11-2025_covariance-shrinkage/index.html#setup-and-plotting-theme",
    "href": "posts/23-11-2025_covariance-shrinkage/index.html#setup-and-plotting-theme",
    "title": "Covariance Shrinkage: From Linear Shrinkage to Random Matrix Theory",
    "section": "2 Setup and Plotting Theme",
    "text": "2 Setup and Plotting Theme\nFirst, we define our plotting theme using plotnine to ensure academic-quality visualizations.\n\n\nCode\nimport numpy as np\nimport pandas as pd\nimport plotnine as pn\nfrom scipy import linalg, stats\nfrom plotnine import *\nfrom IPython.display import display\n\n# Set random seed for reproducibility\nnp.random.seed(42)\n\n# Define Academic Theme\nTHEME_ACADEMIC = pn.theme(\n    text=pn.element_text(family=\"monospace\"),\n    plot_title=pn.element_text(weight=\"bold\", size=12, ha=\"center\"),\n    legend_text=pn.element_text(size=10),\n    legend_title=pn.element_text(size=10, hjust = 0.5),\n    panel_background=pn.element_rect(fill=\"white\"),\n    panel_border=pn.element_rect(color=\"grey\", size=0.5),\n    axis_ticks=pn.element_line(color=\"grey\"),\n    panel_grid_major=pn.element_line(color=\"grey\", size=0.1, alpha=0.3),\n    panel_grid_minor=pn.element_line(color=\"grey\", size=0.1, alpha=0.3),\n    legend_background=pn.element_rect(fill=\"white\", color=None),\n    legend_key=pn.element_rect(fill=\"white\", color=None),\n    legend_key_size=18,\n    plot_margin=0.01,\n    figure_size=(5, 3.5),\n    axis_title=element_text(size=12),\n    axis_text=element_text(size=10),\n    panel_spacing=0.05\n)\n\nPALETTE = [\n    \"#8F44FFFF\", \"#00A1D5FF\", \"#B24745FF\", \"#79AF97FF\", \"#6A6599FF\",\n    \"#80796BFF\", \"#FFC107FF\", \"#00C49AFF\", \"#FF7043FF\", \"#003366FF\",\n    \"#66BB6AFF\", \"#BA68C8FF\", \"#8B0000FF\", \"#556B2FFF\", \"#FFD700FF\",\n    \"#40E0D0FF\", \"#E6E6FAFF\", \"#800000FF\", \"#A0522DFF\"\n]"
  },
  {
    "objectID": "posts/23-11-2025_covariance-shrinkage/index.html#linear-shrinkage-estimation",
    "href": "posts/23-11-2025_covariance-shrinkage/index.html#linear-shrinkage-estimation",
    "title": "Covariance Shrinkage: From Linear Shrinkage to Random Matrix Theory",
    "section": "3 Linear Shrinkage Estimation",
    "text": "3 Linear Shrinkage Estimation\n\n3.1 The Bias-Variance Tradeoff\nLet \\(X\\) be a \\(T \\times N\\) matrix of i.i.d. observations with mean zero and covariance \\(\\Sigma\\). The sample covariance matrix is \\(S = \\frac{1}{T} X^\\top X\\). While \\(\\mathbb{E}[S] = \\Sigma\\), the variance of the entries of \\(S\\) can be large when \\(T\\) is not sufficiently larger than \\(N\\).\nLinear shrinkage proposes an estimator \\(\\hat{\\Sigma}_{shrink}\\) that is a convex combination of the sample covariance \\(S\\) and a highly structured target estimator \\(F\\) (e.g., the identity matrix scaled by average variance, or a single-factor model covariance).\n\\[\n\\hat{\\Sigma}_{shrink} = \\delta F + (1 - \\delta) S, \\quad \\delta \\in [0, 1]\n\\]\nHere, \\(\\delta\\) is the shrinkage intensity.\n\n\\(S\\) has low bias (zero) but high variance.\n\\(F\\) has high bias but low variance (it has few parameters).\n\\(\\hat{\\Sigma}_{shrink}\\) balances bias and variance to minimize the Mean Squared Error (MSE).\n\n\n\n3.2 Optimal Shrinkage Intensity\nLedoit and Wolf (2004) derived the optimal \\(\\delta^*\\) that minimizes the expected Frobenius norm of the error:\n\\[\n\\min_{\\delta} \\mathbb{E} \\left[ \\| \\hat{\\Sigma}_{shrink} - \\Sigma \\|_F^2 \\right]\n\\]\nThe analytical solution for the optimal intensity is given by:\n\\[\n\\delta^* = \\frac{\\mathbb{E}[\\| S - \\Sigma \\|_F^2]}{\\mathbb{E}[\\| S - F \\|_F^2]}\n\\]\nIntuitively, this ratio represents the variance of the sample covariance divided by the total mean squared error of the sample covariance relative to the target.\nCrucially, while this formula depends on the unknown true covariance \\(\\Sigma\\), Ledoit and Wolf (2004) derived consistent estimators for the numerator and denominator using only the sample data \\(X\\). By estimating the asymptotic variance of the entries of \\(S\\), we can compute a practical \\(\\hat{\\delta}^*\\) without ever knowing \\(\\Sigma\\).\nLet’s implement a simple linear shrinkage towards the identity matrix (scaled by the average trace).\n\n\n3.3 Practical Implementation\nIn practice, we do not need to implement the estimation of \\(\\delta^*\\) from scratch. The scikit-learn library provides a robust implementation via sklearn.covariance.LedoitWolf. This class automatically handles the estimation of the required asymptotic variances to compute the optimal shrinkage intensity.\nHowever, for educational purposes, we implement a simplified version below to demonstrate the mechanics.\n\n\nCode\ndef ledoit_wolf_shrinkage(X):\n    \"\"\"\n    Computes the Ledoit-Wolf shrinkage estimator towards the identity matrix.\n    \n    Args:\n        X: (T, N) array of observations.\n        \n    Returns:\n        Sigma_shrink: (N, N) shrunk covariance matrix.\n        delta: Calculated shrinkage intensity.\n    \"\"\"\n    T, N = X.shape\n    S = np.cov(X, rowvar=False)\n    \n    # Target F: Identity scaled by average variance\n    mu = np.trace(S) / N\n    F = mu * np.eye(N)\n    \n    # Calculate optimal delta (simplified implementation of LW2004)\n    # We use a simplified proxy for demonstration or use sklearn's implementation logic\n    # For rigorous implementation, one computes pi, rho, gamma terms.\n    \n    # Using a simplified heuristic for demonstration:\n    # delta approx min(1, (1/T * sum(var)) / sum((S - F)^2))\n    # We will use a manual calculation of the LW formula for trace target\n    \n    X_centered = X - X.mean(axis=0)\n    \n    # Calculate pi_hat (sum of asymptotic variances of entries of S)\n    # Y is T x N x N tensor of outer products\n    # This is memory intensive, optimized approach:\n    \n    # Compute sum of squared differences from S for each observation's outer product\n    # \\pi_{ij} = AsyVar(\\sqrt{T} s_{ij})\n    \n    # Efficient calculation of delta usually requires O(N^2) or O(N^3)\n    # Here we use a standard approximation for Gaussian X:\n    # Optimal delta for Gaussian X towards Identity is roughly:\n    # delta = (N + 1) / (T - 1) * ( (sum lambda^2 - tr(S)^2/N) / (tr(S^2) - tr(S)^2/N) ) ... \n    # Actually, let's stick to the conceptual definition for the simulation \n    # and calculate delta empirically or use a fixed range for demonstration, \n    # OR implement the robust estimator.\n    \n    # Let's use a simpler estimator for b2:\n    # b2 = 1/T * (E[tr(S^2)] - tr(Sigma^2)) ...\n    \n    # Implementation of Ledoit-Wolf 2004:\n    n, p = T, N\n    sample = pd.DataFrame(X)\n    cov = sample.cov().values\n    mean = np.trace(cov) / p\n    target = mean * np.eye(p)\n    \n    # Calculate d2\n    d2 = np.sum((cov - target)**2)\n    \n    # Calculate b2\n    # This part is usually the bottleneck. \n    # We use the fact that for centered data X:\n    # b2 = 1/T^2 \\sum_{i=1}^T || x_i x_i' - S ||^2\n    \n    # We can compute this efficiently\n    X_c = X - X.mean(axis=0)\n    \n    # We need sum of squared variances of individual entries\n    # var(s_ij) = 1/T^2 * sum( (x_ki x_kj - s_ij)^2 )\n    \n    # Let's compute b2 term by term for diagonal and off-diagonal\n    # This is O(N^2 T)\n    \n    # Optimization:\n    # b2 = 1/T^2 * sum_k ( sum_ij (x_ki x_kj - s_ij)^2 )\n    #    = 1/T^2 * sum_k ( || x_k x_k' - S ||_F^2 )\n    \n    # We can just loop if N is not too large, or use broadcasting\n    # For the blog post simulation (N=100), a loop is fine.\n    \n    b2 = 0\n    for i in range(T):\n        x_i = X_c[i, :].reshape(-1, 1)\n        diff = x_i @ x_i.T - cov\n        b2 += np.sum(diff**2)\n    \n    b2 = b2 / (T**2)\n    b2 = min(b2, d2)\n    \n    delta = b2 / d2\n    shrunk_cov = delta * target + (1 - delta) * cov\n    \n    return shrunk_cov, delta\n\n\nTo visualize what linear shrinkage actually does, let’s look at a heatmap of the correlation matrices for a small example.\n\n\nCode\n# Generate a small example\nN_small = 10\nT_small = 20\n# Create a structured covariance (block diagonal)\nSigma_small = np.zeros((N_small, N_small))\nfor i in range(N_small):\n    for j in range(N_small):\n        if abs(i-j) &lt; 3:\n            Sigma_small[i, j] = 0.8**abs(i-j)\n            \nX_small = np.random.multivariate_normal(np.zeros(N_small), Sigma_small, T_small)\nS_small = np.cov(X_small, rowvar=False)\nS_lw_small, delta_small = ledoit_wolf_shrinkage(X_small)\n\n# Prepare data for heatmap\ndef melt_matrix(M, name):\n    df = pd.DataFrame(M)\n    df['Row'] = range(M.shape[0])\n    df = df.melt(id_vars='Row', var_name='Col', value_name='Value')\n    df['Type'] = name\n    return df\n\ndf_heat = pd.concat([\n    melt_matrix(S_small, \"Sample\"),\n    melt_matrix(S_lw_small, f\"Shrunk (δ={delta_small:.2f})\")\n])\n\nplot_heat = (\n    ggplot(df_heat, aes(x='Col', y='Row', fill='Value'))\n    + geom_tile()\n    + facet_wrap('~Type')\n    + scale_fill_cmap(name='viridis')\n    + scale_y_reverse()\n    + labs(title=\"Linear Shrinkage Effect\")\n    + THEME_ACADEMIC\n    + theme(figure_size=(5, 2.5))\n)\n\ndisplay(plot_heat)\n\n\n/tmp/ipykernel_826249/463712102.py:11: RuntimeWarning: covariance is not symmetric positive-semidefinite.\n\n\n\n\n\nHeatmap comparison: The sample covariance (left) exhibits noisy off-diagonal elements. The linearly shrunk covariance (right) dampens this noise, preserving the underlying block-diagonal structure."
  },
  {
    "objectID": "posts/23-11-2025_covariance-shrinkage/index.html#random-matrix-theory-the-marchenko-pastur-law",
    "href": "posts/23-11-2025_covariance-shrinkage/index.html#random-matrix-theory-the-marchenko-pastur-law",
    "title": "Covariance Shrinkage: From Linear Shrinkage to Random Matrix Theory",
    "section": "4 Random Matrix Theory: The Marchenko-Pastur Law",
    "text": "4 Random Matrix Theory: The Marchenko-Pastur Law\nWhen \\(N\\) and \\(T\\) are large, the eigenvalues of the sample covariance matrix \\(S\\) of a random matrix \\(X\\) (with i.i.d. entries with mean 0 and variance \\(\\sigma^2\\)) are not concentrated around \\(\\sigma^2\\). Instead, they spread out according to a deterministic probability density function known as the Marchenko-Pastur (MP) law.\nLet \\(q = T/N\\). If \\(q \\ge 1\\), the eigenvalues \\(\\lambda\\) of \\(S\\) are distributed on the interval \\([\\lambda_-, \\lambda_+]\\) with density:\n\\[\nf(\\lambda) = \\frac{T}{N} \\frac{\\sqrt{(\\lambda_+ - \\lambda)(\\lambda - \\lambda_-)}}{2\\pi \\sigma^2 \\lambda} \\mathbb{1}_{[\\lambda_-, \\lambda_+]}\n\\]\nwhere the spectral bounds are: \\[\n\\lambda_{\\pm} = \\sigma^2 \\left( 1 \\pm \\sqrt{\\frac{N}{T}} \\right)^2\n\\]\nIf \\(N &gt; T\\) (\\(q &lt; 1\\)), there is an additional point mass at zero of weight \\(1 - T/N\\).\nThis distribution explains why sample covariance matrices appear to have “structure” (large leading eigenvalues) even when the data is pure noise.\n\n4.1 Intuition: Why do eigenvalues spread out?\nThe sample covariance matrix \\(S\\) is constructed to “fit” the data \\(X\\). Even if \\(X\\) is pure noise, there will always be some random directions in the high-dimensional space along which the variance of the projected data is larger than average, and others where it is smaller. The eigendecomposition identifies these directions of maximum variance.\nWhen \\(N\\) is large relative to \\(T\\), the optimizer (eigendecomposition) has many degrees of freedom to find these spurious correlations. Consequently, the largest sample eigenvalues systematically overestimate the true variance (they capture noise as signal), and the smallest eigenvalues underestimate it. This results in the “smearing” of the spectral density observed in the Marchenko-Pastur law.\n\n\n4.2 Implementation of MP Density\n\n\nCode\ndef marchenko_pastur_pdf(var, q, pts=1000):\n    \"\"\"\n    Generates the Marchenko-Pastur PDF.\n    \n    Args:\n        var: Variance of the underlying i.i.d. process (sigma^2).\n        q: Ratio T/N.\n        pts: Number of points for the curve.\n        \n    Returns:\n        pd.DataFrame with 'x' and 'y' columns.\n    \"\"\"\n    # q = T/N in the text, but standard MP notation often uses Q = T/N or q = N/T.\n    # Let's stick to the formula: lambda_pm = sigma^2 * (1 +/- sqrt(N/T))^2\n    # Let ratio = N/T\n    ratio = 1/q \n    \n    lambda_min = var * (1 - np.sqrt(ratio))**2\n    lambda_max = var * (1 + np.sqrt(ratio))**2\n    \n    x = np.linspace(lambda_min, lambda_max, pts)\n    \n    # f(lambda) = (1 / (2*pi*var*ratio*x)) * sqrt((max-x)(x-min))\n    # Note: The pre-factor depends on definition. \n    # Standard form for density of eigenvalues of S = 1/T X'X where X is T x N\n    # If we look at density of eigenvalues, the integral should be 1.\n    \n    def mp_density(l):\n        return (1 / (2 * np.pi * var * ratio * l)) * np.sqrt((lambda_max - l) * (l - lambda_min))\n    \n    y = mp_density(x)\n    # Handle numerical issues at boundaries\n    y = np.nan_to_num(y)\n    \n    return pd.DataFrame({'x': x, 'y': y})"
  },
  {
    "objectID": "posts/23-11-2025_covariance-shrinkage/index.html#nonlinear-shrinkage-estimation",
    "href": "posts/23-11-2025_covariance-shrinkage/index.html#nonlinear-shrinkage-estimation",
    "title": "Covariance Shrinkage: From Linear Shrinkage to Random Matrix Theory",
    "section": "5 Nonlinear Shrinkage Estimation",
    "text": "5 Nonlinear Shrinkage Estimation\nLinear shrinkage is limited because it applies the same shrinkage intensity to all eigenvalues (pulling them towards the mean). However, RMT tells us that small sample eigenvalues are biased downwards and large ones upwards. A more optimal approach would be to apply a non-linear transformation \\(\\phi(\\lambda_i)\\) to each sample eigenvalue \\(\\lambda_i\\).\n\n5.1 The QuEST Function and Direct Kernel Method\nLedoit and Wolf (2012, 2020) developed a method to estimate the optimal non-linear shrinkage formula. The key quantity is the Stieltjes transform \\(m(z)\\) of the limiting spectral distribution of the sample covariance matrix.\nFor a complex number \\(z \\in \\mathbb{C}^+\\), the Stieltjes transform is defined as: \\[\nm(z) = \\int \\frac{1}{\\lambda - z} dF(\\lambda)\n\\]\nThe optimal non-linear shrinkage formula for the eigenvalues is given by: \\[\nd_i^* = \\frac{\\lambda_i}{|1 - q^{-1} - q^{-1} \\lambda_i \\breve{m}(\\lambda_i)|^2}\n\\] where \\(\\breve{m}(\\lambda)\\) is the limit of the Stieltjes transform as \\(z\\) approaches the real axis from above: \\(\\breve{m}(\\lambda) = \\lim_{\\eta \\to 0^+} m(\\lambda + i\\eta)\\).\nIn the Direct Kernel method (2020), we estimate \\(\\breve{m}(\\lambda)\\) directly from the sample eigenvalues using a kernel density estimator, avoiding numerical inversion of the QuEST function.\n\n\n5.2 The Direct Kernel Workflow\nThe practical implementation of Nonlinear Shrinkage involves the following steps:\n\nEigendecomposition: Compute the eigenvalues \\(\\lambda_i\\) and eigenvectors \\(u_i\\) of the sample covariance matrix \\(S\\).\nSpectral Density Estimation: Use a Kernel Density Estimator (KDE) to estimate the limiting spectral density \\(f(\\lambda)\\) from the sample eigenvalues.\nHilbert Transform: Compute the Hilbert transform of the estimated density to obtain the real part of the Stieltjes transform \\(\\breve{m}(\\lambda)\\).\nOptimal Correction: Apply the QuEST formula to map each sample eigenvalue \\(\\lambda_i\\) to its optimal population counterpart \\(d_i^*\\).\nReconstruction: Form the new estimator \\(\\hat{\\Sigma}_{nl} = \\sum_{i=1}^N d_i^* u_i u_i^\\top\\).\n\nThis method is computationally efficient and does not require numerical optimization. In Python, the PyRMT library offers a production-ready implementation.\n\n\n5.3 Implementation\nWe implement a simplified version of the Direct Kernel estimator.\n\n\nCode\ndef nonlinear_shrinkage(X):\n    \"\"\"\n    Computes the Nonlinear Shrinkage estimator using the Direct Kernel method.\n    Reference: Ledoit, O. and Wolf, M. (2020). \"The Power of (Non-)Linear Shrinking\"\n    \n    Args:\n        X: (T, N) array of observations.\n        \n    Returns:\n        Sigma_nonlinear: (N, N) nonlinearly shrunk covariance matrix.\n    \"\"\"\n    T, N = X.shape\n    S = np.cov(X, rowvar=False)\n    evals, evecs = np.linalg.eigh(S)\n    \n    # Sort eigenvalues\n    idx = evals.argsort()\n    evals = evals[idx]\n    evecs = evecs[:, idx]\n    \n    # 1. Estimate the Stieltjes transform m(z)\n    # We use a kernel density estimator for the spectral density f(lambda)\n    # Bandwidth h ~ N^(-1/3) is a common heuristic for this problem\n    h = T**(-0.35) \n    \n    # Discretize the spectrum\n    # We evaluate m(lambda_i) for each sample eigenvalue\n    lambda_i = evals\n    \n    # m(x) = 1/N sum_j 1/(lambda_j - z)\n    # We need m(lambda_i + i*h) approx\n    # The Direct Kernel estimator uses a specific kernel K\n    \n    # Simplified implementation:\n    # m_hat(x) = 1/N \\sum_{j=1}^N \\frac{1}{\\lambda_j - x - i h}\n    # This is equivalent to using a Cauchy kernel\n    \n    z = lambda_i + 1j * h\n    \n    # Vectorized calculation of Stieltjes transform\n    # m[i] = mean( 1 / (evals - z[i]) )\n    # But we need to be careful with dimensions.\n    # We want m evaluated at each z_i corresponding to lambda_i\n    \n    # m_hat = np.zeros(N, dtype=complex)\n    # for k in range(N):\n    #     m_hat[k] = np.mean(1 / (evals - z[k]))\n        \n    # Fully vectorized:\n    # z is (N,), evals is (N,)\n    # We need outer subtraction\n    diff = evals.reshape(1, -1) - z.reshape(-1, 1) # (N, N)\n    m_hat = np.mean(1 / diff, axis=1)\n    \n    # 2. Apply the nonlinear shrinkage formula\n    # d_tilde = lambda / |1 - (T/N)^(-1) - (T/N)^(-1) * lambda * m_hat|^2\n    # Note: Ledoit-Wolf use concentration ratio c = N/T.\n    c = N / T\n    \n    # The formula in LW2020 (Eq 2.5) for the \"quantized\" estimator:\n    # d_i = lambda_i / | 1 - c - c * lambda_i * m_hat(lambda_i) |^2\n    \n    denom = np.abs(1 - c - c * lambda_i * m_hat)**2\n    d_star = lambda_i / denom\n    \n    # 3. Reconstruct the matrix\n    # Sigma_hat = U @ diag(d_star) @ U.T\n    Sigma_nonlinear = evecs @ np.diag(d_star) @ evecs.T\n    \n    return Sigma_nonlinear, d_star\n\n\nThe core of nonlinear shrinkage is the mapping from sample eigenvalues \\(\\lambda_i\\) to population eigenvalues \\(d_i^*\\). Let’s visualize this mapping function.\n\n\nCode\n# Generate data for visualization\nN_viz = 500\nT_viz = 1000 # q = 2\nX_viz = np.random.normal(0, 1, (T_viz, N_viz))\n_, d_star_viz = nonlinear_shrinkage(X_viz)\nS_viz = np.cov(X_viz, rowvar=False)\nevals_viz = np.linalg.eigvalsh(S_viz)\n\ndf_shrinkage = pd.DataFrame({\n    'Sample Eigenvalue': evals_viz,\n    'Shrunk Eigenvalue': d_star_viz\n})\n\n# Theoretical 45-degree line (No Shrinkage)\nline_df = pd.DataFrame({'x': [0, max(evals_viz)], 'y': [0, max(evals_viz)]})\n\nplot_func = (\n    ggplot(df_shrinkage, aes(x='Sample Eigenvalue', y='Shrunk Eigenvalue'))\n    + geom_point(color=PALETTE[0], alpha=0.3, size=0.5)\n    + geom_line(aes(x='x', y='y'), data=line_df, linetype='dashed', color='black', size=1)\n    + labs(\n        title=\"Nonlinear Shrinkage Function\",\n        x=\"Sample Eigenvalue\",\n        y=\"Shrunk Eigenvalue\"\n    )\n    + THEME_ACADEMIC\n)\n\ndisplay(plot_func)\n\n\n\n\n\nMapping from sample eigenvalues to optimal population eigenvalues (N=500, T=1000).\n\n\n\n\nThis plot reveals the “S-shape” characteristic of optimal shrinkage: 1. Small eigenvalues (left) are pulled up (above the dashed line). 2. Large eigenvalues (right) are pulled down (below the dashed line). 3. This counteracts the “repulsion” effect predicted by Random Matrix Theory."
  },
  {
    "objectID": "posts/23-11-2025_covariance-shrinkage/index.html#simulation-study",
    "href": "posts/23-11-2025_covariance-shrinkage/index.html#simulation-study",
    "title": "Covariance Shrinkage: From Linear Shrinkage to Random Matrix Theory",
    "section": "6 Simulation Study",
    "text": "6 Simulation Study\nWe will now simulate a scenario to demonstrate:\n\nThe fit of the sample covariance eigenvalues to the MP distribution (for pure noise).\nThe recovery of a true covariance structure using both Linear and Nonlinear shrinkage.\nThe specific adjustment of eigenvalues performed by the nonlinear method.\n\n\n6.1 Scenario 1: Pure Noise (Null Hypothesis)\nWe generate a random matrix \\(X \\in \\mathbb{R}^{T \\times N}\\) with \\(N=200, T=1000\\) (so \\(q=5\\)) from \\(\\mathcal{N}(0, I)\\). The true eigenvalues are all 1.\n\n\nCode\n# Define MP PDF function here to ensure it is available for plotting\ndef marchenko_pastur_pdf(var, q, pts=1000):\n    ratio = 1/q \n    lambda_min = var * (1 - np.sqrt(ratio))**2\n    lambda_max = var * (1 + np.sqrt(ratio))**2\n    x = np.linspace(lambda_min, lambda_max, pts)\n    def mp_density(l):\n        return (1 / (2 * np.pi * var * ratio * l)) * np.sqrt((lambda_max - l) * (l - lambda_min))\n    y = mp_density(x)\n    y = np.nan_to_num(y)\n    return pd.DataFrame({'x': x, 'y': y})\n\nN = 200\nT = 1000\nsigma_sq = 1.0\n\n# Generate random data\nX_noise = np.random.normal(0, np.sqrt(sigma_sq), (T, N))\n\n# Sample Covariance\nS_noise = np.cov(X_noise, rowvar=False)\nevals_noise = np.linalg.eigvalsh(S_noise)\n\n# Theoretical MP PDF\nmp_dist = marchenko_pastur_pdf(sigma_sq, q=T/N)\n\n# Plotting\ndf_evals = pd.DataFrame({'eigenvalue': evals_noise})\n\nplot_mp = (\n    ggplot()\n    + geom_histogram(\n        aes(x='eigenvalue', y='stat(density)'), \n        data=df_evals, \n        bins=30, \n        fill=PALETTE[1], \n        alpha=0.7,\n        color=\"white\"\n    )\n    + geom_line(\n        aes(x='x', y='y'), \n        data=mp_dist, \n        color=PALETTE[2], \n        size=1.5\n    )\n    + labs(\n        title=\"Eigenvalues vs Marchenko-Pastur\",\n        x=\"Eigenvalue\",\n        y=\"Density\"\n    )\n    + THEME_ACADEMIC\n)\n\ndisplay(plot_mp)\n\n\n\n\n\nHistogram of sample eigenvalues (N=200, T=1000) vs theoretical Marchenko-Pastur density.\n\n\n\n\nThe histogram of sample eigenvalues perfectly matches the theoretical Marchenko-Pastur curve. Note that while the true eigenvalues are all exactly 1.0, the sample eigenvalues range from \\(\\approx 0.6\\) to \\(\\approx 1.5\\). This “smearing” of the spectrum is the noise dressing effect.\n\n\n6.2 Scenario 2: Signal + Noise and Shrinkage Performance\nNow consider a case where the true covariance matrix \\(\\Sigma\\) has some structure (Signal) plus noise. We will compare the Sample Covariance, Ledoit-Wolf Linear Shrinkage, and Nonlinear Shrinkage in terms of their ability to recover the true matrix.\nWe define the Normalized Frobenius Loss as: \\[\n\\text{Loss}(\\hat{\\Sigma}, \\Sigma) = \\frac{\\| \\hat{\\Sigma} - \\Sigma \\|_F}{\\| \\Sigma \\|_F}\n\\]\nWe will vary the sample size \\(T\\) while keeping \\(N\\) fixed to see how the estimators converge.\n\n\nCode\ndef generate_structured_covariance(N, rho=0.7):\n    \"\"\"Generates a Toeplitz covariance matrix (AR(1) process).\"\"\"\n    Sigma = np.zeros((N, N))\n    for i in range(N):\n        for j in range(N):\n            Sigma[i, j] = rho**(abs(i - j))\n    return Sigma\n\nN = 100\nT_values = [50, 100, 200, 500, 1000]\nrho = 0.5\nSigma_true = generate_structured_covariance(N, rho)\n\nresults = []\n\nfor t in T_values:\n    # Run multiple trials to smooth results\n    for trial in range(20):\n        # Generate Data X ~ N(0, Sigma)\n        # X = Z * chol(Sigma)\n        Z = np.random.normal(0, 1, (t, N))\n        L = np.linalg.cholesky(Sigma_true)\n        X = Z @ L.T\n        \n        # 1. Sample Covariance\n        S = np.cov(X, rowvar=False)\n        loss_sample = np.linalg.norm(S - Sigma_true, 'fro') / np.linalg.norm(Sigma_true, 'fro')\n        \n        # 2. Linear Shrinkage (Ledoit-Wolf)\n        S_lw, delta = ledoit_wolf_shrinkage(X)\n        loss_lw = np.linalg.norm(S_lw - Sigma_true, 'fro') / np.linalg.norm(Sigma_true, 'fro')\n        \n        # 3. Nonlinear Shrinkage\n        S_nl, _ = nonlinear_shrinkage(X)\n        loss_nl = np.linalg.norm(S_nl - Sigma_true, 'fro') / np.linalg.norm(Sigma_true, 'fro')\n        \n        results.append({'T': t, 'Method': 'Sample Covariance', 'Loss': loss_sample})\n        results.append({'T': t, 'Method': 'Linear Shrinkage', 'Loss': loss_lw})\n        results.append({'T': t, 'Method': 'Nonlinear Shrinkage', 'Loss': loss_nl})\n\ndf_results = pd.DataFrame(results)\n\n# Aggregate for plotting\ndf_summary = df_results.groupby(['T', 'Method'])['Loss'].mean().reset_index()\n\nplot_loss = (\n    ggplot(df_summary, aes(x='T', y='Loss', color='Method', group='Method'))\n    + geom_line(size=1.5)\n    + geom_point(size=3, fill=\"white\", stroke=1.5)\n    + scale_color_manual(values=[PALETTE[0], PALETTE[2], PALETTE[7]])\n    + scale_y_log10()\n    + labs(\n        title=\"Estimator Convergence\",\n        x=\"Sample Size (T)\",\n        y=\"Loss (Log Scale)\"\n    )\n    + THEME_ACADEMIC\n)\n\ndisplay(plot_loss)\n\n\n\n\n\nNormalized Frobenius loss of covariance estimators as sample size T increases (N=100 fixed).\n\n\n\n\n\n\n6.3 Scenario 3: Eigenvalue Adjustment\nTo visualize how Nonlinear Shrinkage works, let’s look at the eigenvalues directly. We use a “Spiked Covariance” model where a few eigenvalues are large (signal) and the rest are 1 (noise).\n\n\nCode\n# Spiked Covariance Model\nN = 200\nT = 400 # q = 2\nn_spikes = 10\nspike_val = 10.0\n\nSigma_spiked = np.eye(N)\nSigma_spiked[:n_spikes, :n_spikes] = spike_val * np.eye(n_spikes)\n\n# Generate Data\nZ = np.random.normal(0, 1, (T, N))\nL = np.linalg.cholesky(Sigma_spiked)\nX_spiked = Z @ L.T\n\n# Compute Estimators\nS_spiked = np.cov(X_spiked, rowvar=False)\nS_nl_spiked, evals_nl = nonlinear_shrinkage(X_spiked)\n\n# Extract Eigenvalues\nevals_sample = np.linalg.eigvalsh(S_spiked)\nevals_true = np.linalg.eigvalsh(Sigma_spiked)\n# Sort descending\nevals_sample = np.sort(evals_sample)[::-1]\nevals_true = np.sort(evals_true)[::-1]\nevals_nl = np.sort(evals_nl)[::-1]\n\n# Create DataFrame for plotting\ndf_scree = pd.DataFrame({\n    'Rank': np.tile(np.arange(1, N+1), 3),\n    'Eigenvalue': np.concatenate([evals_true, evals_sample, evals_nl]),\n    'Type': ['True Population'] * N + ['Sample (Noisy)'] * N + ['Nonlinear Shrinkage'] * N\n})\n\nplot_scree = (\n    ggplot(df_scree, aes(x='Rank', y='Eigenvalue', color='Type'))\n    + geom_line(size=1.2)\n    + scale_y_log10()\n    + scale_color_manual(values=[PALETTE[7], PALETTE[0], PALETTE[2]])\n    + labs(\n        title=\"Scree Plot\",\n        x=\"Rank\",\n        y=\"Eigenvalue (Log)\"\n    )\n    + THEME_ACADEMIC\n)\n\ndisplay(plot_scree)\n\n\n\n\n\nScree plot comparing true population eigenvalues (spiked model), sample eigenvalues, and nonlinearly shrunk eigenvalues.\n\n\n\n\n\n\n6.4 Interpretation\n\nConvergence Plot: Nonlinear shrinkage consistently outperforms the sample covariance. In many regimes, especially where \\(N/T\\) is large, it can also outperform linear shrinkage because it adapts to the specific shape of the spectrum rather than just shrinking everything towards a single point.\nScree Plot: The sample eigenvalues (purple) overestimate the signal spikes and underestimate the noise floor (the “smearing” effect). The nonlinear shrinkage (teal) successfully pulls the large eigenvalues down and the small eigenvalues up, much closer to the true population spectrum (red)."
  },
  {
    "objectID": "posts/23-11-2025_covariance-shrinkage/index.html#conclusion",
    "href": "posts/23-11-2025_covariance-shrinkage/index.html#conclusion",
    "title": "Covariance Shrinkage: From Linear Shrinkage to Random Matrix Theory",
    "section": "7 Conclusion",
    "text": "7 Conclusion\nIn high-dimensional statistics, the sample covariance matrix is untrustworthy due to the “curse of dimensionality,” manifesting as a deterministic spreading of eigenvalues described by the Marchenko-Pastur law.\n\nLinear shrinkage (Ledoit-Wolf) offers a robust improvement by pulling the matrix towards a stable target, effectively reducing variance at the cost of some bias.\nNonlinear shrinkage takes this a step further by using Random Matrix Theory to optimally correct individual eigenvalues. It effectively “inverts” the Marchenko-Pastur equation to recover the population spectrum.\n\nFor practitioners, implementing nonlinear shrinkage (or using libraries like PyRMT) is a powerful way to clean covariance matrices before feeding them into sensitive algorithms like Mean-Variance Optimization.\n\n7.1 Practitioner’s Guide: When to use what?\n\nSmall \\(N/T\\) (e.g., &lt; 0.1): The sample covariance matrix is generally sufficient and well-conditioned.\nModerate \\(N/T\\): Linear shrinkage (Ledoit-Wolf) is a robust, low-variance estimator that is easy to implement and interpret. It is the standard baseline in finance.\nLarge \\(N/T\\) (but &lt; 1): Nonlinear shrinkage provides significant gains over linear shrinkage by correcting the specific spectral distortion predicted by RMT. It is ideal for high-dimensional portfolios.\n\\(N &gt; T\\) (Singular Regime): The sample covariance is singular. Shrinkage is strictly necessary.\n\nIf \\(T\\) is reasonably large (e.g., \\(T &gt; 100\\)), Nonlinear Shrinkage is preferred as it can still recover the spectrum effectively.\nIf \\(T\\) is very small (Extreme Scarcity), Linear Shrinkage is often safer. The estimation of the spectral density required for nonlinear shrinkage becomes noisy, whereas linear shrinkage relies on a stable, structured target (like the identity or a factor model) to regularize the solution heavily."
  },
  {
    "objectID": "posts/23-11-2025_covariance-shrinkage/index.html#references",
    "href": "posts/23-11-2025_covariance-shrinkage/index.html#references",
    "title": "Covariance Shrinkage: From Linear Shrinkage to Random Matrix Theory",
    "section": "8 References",
    "text": "8 References\n\nLedoit, O., & Wolf, M. (2004). A well-conditioned estimator for large-dimensional covariance matrices. Journal of Multivariate Analysis.\nLedoit, O., & Wolf, M. (2020). The Power of (Non-)Linear Shrinking: A Review and Guide to Covariance Matrix Estimation. Journal of Financial Econometrics.\nMarchenko, V. A., & Pastur, L. A. (1967). Distribution of eigenvalues for some sets of random matrices. Matematicheskii Sbornik.\nPotters, M., & Bouchaud, J. P. (2020). A First Course in Random Matrix Theory: For Physicists, Engineers and Data Scientists. Cambridge University Press."
  },
  {
    "objectID": "posts/07-02-2025_portfolio-var/index.html",
    "href": "posts/07-02-2025_portfolio-var/index.html",
    "title": "Comparing Univariate and Multivariate Models for Value at Risk Forecasting",
    "section": "",
    "text": "Value at Risk (VaR) is a crucial metric in modern financial risk management"
  },
  {
    "objectID": "posts/07-02-2025_portfolio-var/index.html#sec-introduction",
    "href": "posts/07-02-2025_portfolio-var/index.html#sec-introduction",
    "title": "Comparing Univariate and Multivariate Models for Value at Risk Forecasting",
    "section": "1 Introduction",
    "text": "1 Introduction\nThe past four decades have been shaped by extreme events in financial markets, such as the Black Monday crash, the dot-com bubble, and the 2008 global financial crisis. These supposedly rare events highlighted that reducing systemic risk is crucial for financial stability (Embrechts et al. 2014). This led to the introduction and tightening of the Basel Accords, which use risk measures to determine appropriate risk capital requirements for financial institutions.\nValue at Risk (VaR) remains the most popular measure for downside market risk, despite a shift towards the severity-based expected shortfall (ES) (Embrechts et al. 2014). For a long equity portfolio, the \\(p\\)% VaR for period \\(t\\) forecasted at time \\(t-1\\) is defined as the negative \\(p\\)-quantile of the conditional portfolio return distribution:\n\\[\n\\text{VaR}_t^p=-Q_p(r_{\\text{PF},t}|\\mathcal{F}_{t-1})=-\\inf_x\\{x\\in\\mathbb{R}:\\mathbb{P}(r_{\\text{PF},t}\\leq x|\\mathcal{F}_{t-1})\\geq p\\},\\quad p\\in(0,1).\n\\tag{1}\\]\nHere, \\(Q_p(\\cdot)\\) denotes the quantile function and \\(\\mathcal{F}_{t-1}\\) represents all information available at time \\(t-1\\). The parameter \\(p\\) indicates that with target probability \\(p\\), the portfolio losses will exceed the VaR (Marc S. Paolella, Kuester, and Mittnik 2006).\nDue to the practical relevance of VaR, it is essential to determine estimation methods that neither severely underestimate nor overestimate future losses. Many models use the generalized autoregressive conditional heteroskedasticity (GARCH) framework (Bollerslev 1986) or extensions to account for volatility clustering and the “leverage effect” in financial time series.\nA fundamental question in VaR modeling is whether more complex multivariate models outperform simpler univariate alternatives. Santos, Nogales, and Ruiz (2013) found that multivariate models significantly outperform univariate counterparts for large portfolios, while Kole et al. (2017) found that multivariate models have greater predictive ability, though differences are often not significant. They also found that data frequency is more important than model choice.\nThis study compares factor copula-DCC-NGARCH models introduced by Fortin, Simonato, and Dionne (2022) with established models like the diagonal MixN(k)-GARCH (Haas, Mittnik, and Paolella 2004) and the COMFORT model class (Marc S. Paolella and Polak 2015). We show that multivariate models display desirable VaR properties in terms of correct unconditional coverage and independence of violations, though we don’t find sufficient evidence to claim that multivariate approaches outperform univariate procedures in terms of forecast ability, or vice versa."
  },
  {
    "objectID": "posts/07-02-2025_portfolio-var/index.html#sec-methodology",
    "href": "posts/07-02-2025_portfolio-var/index.html#sec-methodology",
    "title": "Comparing Univariate and Multivariate Models for Value at Risk Forecasting",
    "section": "2 Methodology",
    "text": "2 Methodology\n\n2.1 Univariate Models\nFor univariate models, we assume the following portfolio return dynamics:\n\\[\nr_{\\text{PF},t} = \\mu + \\epsilon_t\n\\]\nwhere\n\\[\n\\epsilon_t = \\sigma_t z_t, \\quad z_t \\stackrel{iid}{\\sim} F(0,1)\n\\]\nHere, \\(F(0,1)\\) is a standardized distribution, \\(\\mu\\) is the unconditional location, and \\(\\sigma_t\\) is the scale parameter. The conditional variance \\(\\sigma_t^2 = \\mathbb{V}[r_{\\text{PF},t}|\\mathcal{F}_{t-1}]\\) is modeled as non-constant.\n\n2.1.1 GARCH and Extensions\nThe standard GARCH(1,1) model (Bollerslev 1986) is formulated as:\n\\[\n\\sigma_t^2 = \\omega + \\alpha\\epsilon_{t-1}^2 + \\beta\\sigma_{t-1}^2\n\\tag{2}\\]\nwhere \\(\\omega &gt; 0, \\alpha \\geq 0\\), and \\(\\beta \\geq 0\\). For covariance stationarity, the parameters must satisfy \\(\\alpha + \\beta &lt; 1\\).\nA special case is the exponentially weighted moving average (EWMA):\n\\[\n\\sigma^2_t = \\lambda\\sigma^2_{t-1} + (1-\\lambda)\\epsilon_t^2, \\quad \\lambda \\in (0,1)\n\\tag{3}\\]\nThis formulation puts more weight on recent observations, but is not covariance stationary since \\(\\lambda + (1-\\lambda) = 1\\).\nTo account for the “leverage effect” (negative news increasing volatility more than positive news of equal magnitude), we include the GJR-GARCH(1,1) model (Glosten, Jagannathan, and Runkle 1993):\n\\[\n\\sigma_t^2 = \\omega + (\\alpha + \\gamma I_{t-1})\\epsilon_{t-1}^2 + \\beta\\sigma_{t-1}^2\n\\tag{4}\\]\nwhere \\(I_{t-1} = \\mathbb{I}_{\\{\\epsilon_{t-1} &lt; 0\\}}\\) is an indicator function.\nAnother asymmetric model is the NGARCH(1,1) (R. F. Engle and Ng 1993):\n\\[\n\\sigma_t^2 = \\omega + \\alpha\\sigma_{t-1}^2(\\epsilon_{t-1} - \\theta)^2 + \\beta\\sigma_{t-1}^2\n\\]\nFor \\(\\theta &gt; 0\\), negative innovations have a larger impact on conditional variance than positive errors of the same magnitude.\n\n\n2.1.2 Mixed Normal GARCH\nWe also include the k-component mixed normal GARCH(1,1) (MixN(k)-GARCH) (Haas, Mittnik, and Paolella 2004), where the conditional distribution of the error term \\(\\epsilon_t\\) is assumed to be mixed normal with zero mean:\n\\[\n\\epsilon_t|\\mathcal{F}_{t-1} \\sim \\text{Mix}_k\\text{N}(p_1,...,p_k, \\mu_1,...,\\mu_k, \\sigma_{1,t}^2,...,\\sigma_{k,t}^2), \\quad \\sum_{i=1}^k p_i\\mu_i = 0\n\\]\nThe associated conditional variances follow GARCH processes:\n\\[\n\\sigma_{i,t}^2 = \\omega_i + \\alpha_i\\epsilon_{i,t-1}^2 + \\beta_i\\sigma_{i,t-1}^2, \\quad i=1,...,k\n\\]\n\n\n\n2.2 Multivariate Models\n\n2.2.1 Factor Copula-DCC-GARCH Model\nThe factor copula model proposed by Fortin, Simonato, and Dionne (2022) uses equity factors to capture the main risks of stock returns. It utilizes the Carhart four-factor model (Carhart 1997), which adds a momentum factor to the Fama-French three-factor model (Fama and French 1993):\n\\[\nr_{k,t} - r_{f,t} = \\alpha_{k,t} + \\beta_{k, \\text{RMRF}}\\text{RMRF}_t + \\beta_{k,\\text{SMB}}\\text{SMB}_t + \\beta_{k,\\text{HML}}\\text{HML}_t + \\beta_{k, \\text{MOM}}\\text{MOM}_t + \\varepsilon_{k,t}\n\\tag{5}\\]\nor in vector form:\n\\[\nr_{k,t} - r_{f,t} = \\alpha_{k,t} + \\mathbf{\\beta}_k'\\mathbf{r}_{\\text{F},t} + \\varepsilon_{k,t}\n\\tag{6}\\]\nThis reduces dimensionality by modeling only four factors instead of all portfolio constituents.\nFor the factor dynamics, we use the Dynamic Conditional Correlation (DCC) structure (R. Engle 2002), which decomposes the conditional covariance matrix into standard deviations and correlations:\n\\[\n\\mathbf{Y}_{t}|\\mathcal{F}_{t-1} \\sim \\mathcal{N}_n(\\mathbf{\\mu}, \\mathbf{\\Sigma_t}), \\quad \\mathbf{\\Sigma_t} = \\mathbf{D_t}\\mathbf{\\Gamma_t}\\mathbf{D_t}\n\\tag{7}\\]\nwhere \\(\\mathbf{D_t} = \\text{diag}(\\sigma_{1,t},\\sigma_{2,t},...,\\sigma_{n,t})\\) contains the conditional standard deviations.\nTo account for non-normality, we use copulas to model the joint conditional distribution of factor returns. Copulas allow modeling marginals independently of the multivariate distribution. By Sklar’s theorem:\n\\[\n\\mathbf{F_t}(\\mathbf{z_t}) = \\mathbf{C_t}(F_{1,t}(z_{1,t}),...,F_{n,t}(z_{n,t}))\n\\tag{8}\\]\nwhere \\(\\mathbf{F_t}(\\mathbf{z_t})\\) is the joint conditional distribution, \\(F_{i,t}(\\cdot)\\) are the conditional marginals, and \\(\\mathbf{C_t}:[0,1]^n \\rightarrow [0,1]\\) is the conditional copula.\n\n\n2.2.2 COMFORT Model\nThe Common Market Factor Non-Gaussian Returns (COMFORT) model (Marc S. Paolella and Polak 2015) uses a multivariate generalized hyperbolic (MGHyp) distribution with a CCC or DCC structure for the covariance matrix. This model can be expressed as a continuous normal mixture:\n\\[\n\\mathbf{Y_t} = \\mathbf{\\mu} + \\mathbf{\\gamma} G_t + \\mathbf{\\varepsilon_t}, \\quad \\mathbf{\\varepsilon_t} = \\mathbf{\\Sigma_t}^{1/2}\\sqrt{G_t}\\mathbf{Z_t}\n\\tag{9}\\]\nwhere \\(\\mathbf{Z_t} \\stackrel{iid}{\\sim} \\mathcal{N}_n(\\mathbf{0},\\mathbf{I_n})\\) and the mixing random variables \\(G_t|\\mathcal{F}_{t-1} \\sim \\text{GIG}(\\lambda_t,\\chi_t,\\psi_t)\\) follow a generalized inverse Gaussian distribution.\nAn important property of the MGHyp distribution is that it is closed under linear operations. Therefore, portfolio returns \\(r_{\\text{PF},t} = \\mathbf{w}'\\mathbf{Y_t}\\) are univariate GHyp distributed:\n\\[\nr_{\\text{PF},t}|\\mathcal{F}_{t-1} \\sim \\text{GHyp}(\\mathbf{w}'\\mathbf{\\mu},\\mathbf{w}'\\mathbf{\\gamma},\\mathbf{w}'\\mathbf{\\Sigma_t}\\mathbf{w},\\lambda_t,\\chi_t, \\psi_t)\n\\tag{10}\\]\n\n\n\n2.3 Data\nWe use an equally weighted portfolio of ten large-cap stocks (identical to those used by Fortin, Simonato, and Dionne (2022)): Boeing, Caterpillar, Chevron, Coca-Cola, Exxon, GE, IBM, Merck, P&G, and UTC. However, we analyze 2,767 daily returns from January 2, 2001, to December 30, 2011, rather than weekly returns.\nThe return data shows that most factors and stocks have means close to zero, with the median larger than the mean in most cases. The mean absolute deviation (MAD) is considerably smaller than the standard deviation, indicating the presence of outliers. Most returns are left-skewed with leptokurtic behavior, and all return distributions reject the assumption of normality based on Jarque-Bera statistics.\n\n\n\n\n\n\n\n\nFigure 1: ACF Plots of the Fama-French-Carhart Factors\n\n\n\n\n\nFigure Figure 1 shows autocorrelation function (ACF) plots for the factors. It is evident that the factors exhibit stronger autocorrelation in absolute returns than in the returns themselves, justifying the use of volatility models.\n\n\n\n\n\n\n\n\nFigure 2: Chi-Square Q-Q Plots of the Stock and Factor Returns\n\n\n\n\n\nFigure Figure 2 shows Q-Q plots of the robust squared Mahalanobis distances against \\(\\chi^2\\) distributions. The non-linear relationship indicates large multivariate outliers and multivariate non-normality.\n\n\n\n\n\n\n\n\nFigure 3: Portfolio Returns\n\n\n\n\n\nFigure Figure 3 demonstrates blatant volatility clustering (Panel A) and that the portfolio returns are not normally distributed (Panel B).\n\n\n2.4 Value at Risk Forecasts\nFor all models, we assume a constant conditional mean over time. Forecasting uses a rolling window approach with the previous 1,000 observations to predict the one-step-ahead VaR.\nFor univariate GARCH models (except MixN(k)-GARCH), we use the analytical formula:\n\\[\n\\widehat{\\text{VaR}_t^p} = -\\mu_{\\text{PF}} - \\sigma_{\\text{PF}, t} Q_p(z_t|\\mathcal{F}_{t-1})\n\\tag{11}\\]\nwhere \\(\\sigma_{\\text{PF}, t}\\) is the conditional standard deviation and \\(Q_p(z_t)\\) is the p-quantile of the standardized returns.\nFor the factor copula-DCC-(N)GARCH models, we simulate factor returns, apply the Carhart model to generate single stock returns, and calculate the portfolio return. The VaR estimate is then the negative p-quantile of the simulated portfolio returns.\nFor the COMFORT model, we use the p-quantile function of the corresponding conditional univariate GHyp distribution:\n\\[\n\\widehat{\\text{VaR}_t^p} = -Q_p(r_{\\text{PF},t}|\\mathcal{F}_{t-1})\n\\tag{12}\\]\n\n\n2.5 Backtesting\nBacktesting checks whether the forecasts exhibit desirable properties. Following Christoffersen (1998), we use three likelihood-ratio tests.\nLet \\(I_t\\) be the indicator variable for a \\(\\text{VaR}_t^p\\) forecast:\n\\[\nI_t = \\mathbb{I}_{\\{r_{\\text{PF},t} &lt; -\\text{VaR}_t^p\\}} =\n\\begin{cases}\n1 & \\text{if } r_{\\text{PF},t} &lt; -\\text{VaR}_t^p \\\\\n0 & \\text{otherwise}\n\\end{cases}\n\\]\nA sequence of VaR forecasts is efficient with respect to \\(\\mathcal{F}_{t-1}\\) if:\n\\[\n\\mathbb{E}[I_t|\\mathcal{F}_{t-1}] = \\mathbb{E}[I_t|I_{t-1},I_{t-2},...,I_1] = p, \\quad t=1,2,...,T\n\\tag{13}\\]\nThis is equivalent to testing that \\(\\{I_t\\}_{t=1}^T \\overset{\\text{iid}}{\\sim} \\text{Bernoulli}(p)\\).\n\n2.5.1 Unconditional Coverage Test\nThis tests whether the expected value of \\(I_t\\) equals \\(p\\):\n\\[\nH_0: \\mathbb{E}[I_t] = p \\quad \\text{versus} \\quad H_A: \\mathbb{E}[I_t] \\neq p\n\\]\nThe likelihood-ratio test statistic is:\n\\[\nLR_{uc} = -2\\log\\left(\\frac{L(p;I_1,I_2,...,I_T)}{L(\\hat{p};I_1,I_2,...,I_T)}\\right) \\overset{\\text{asy}}{\\sim} \\chi_1^2\n\\tag{14}\\]\nwhere \\(\\hat{p} = \\frac{n_1}{n_0+n_1}\\) is the maximum likelihood estimate of \\(p\\).\n\n\n2.5.2 Independence Test\nThis tests whether the indicator sequence is independently distributed, against a first-order Markov chain alternative:\n\\[\nLR_{ind} = -2\\log\\left(\\frac{L(\\hat{\\Pi}_2;I_2,...,I_T|I_1)}{L(\\hat{\\Pi}_1;I_2,...,I_T|I_1)}\\right) \\overset{\\text{asy}}{\\sim} \\chi_1^2\n\\tag{15}\\]\nwhere \\(\\hat{\\Pi}_1\\) and \\(\\hat{\\Pi}_2\\) are the estimated transition probability matrices under the alternative and null hypotheses.\n\n\n2.5.3 Conditional Coverage Test\nThis combines the unconditional coverage and independence tests:\n\\[\nLR_{cc} = -2\\log\\left(\\frac{L(p;I_2,...,I_T|I_1)}{L(\\hat{\\Pi}_1;I_2,...,I_T|I_1)}\\right) \\overset{\\text{asy}}{\\sim} \\chi_2^2\n\\tag{16}\\]\nIt can also be calculated as:\n\\[\nLR_{cc} = LR_{uc} + LR_{ind}\n\\]\n\n\n\n2.6 Comparison of Predictive Ability\nTo rank VaR estimates, we use the “tick” loss function:\n\\[\nL_V(\\theta_t, r_{\\text{PF},t}) = (r_{\\text{PF},t} + \\theta_t)(p - \\mathbb{I}_{\\{r_{\\text{PF},t} &lt; -\\theta_t\\}})\n\\]\nThis loss function has the property that:\n\\[\nQ_p(r_{\\text{PF},t}|\\mathcal{F}_{t-1}) = -\\text{VaR}_t^p = \\arg\\min_{\\theta_t} \\mathbb{E}[L_V(\\theta_t, r_{\\text{PF},t})]\n\\tag{17}\\]\nFor statistical inference, we use the conditional predictive ability (CPA) test (Giacomini and White 2006). The null hypothesis of equal conditional predictive ability is:\n\\[\nH_0: \\mathbb{E}[\\Delta L_{i,j,t}|\\mathcal{F}_{t-1}] = 0 \\quad \\text{almost surely } \\forall t\n\\]\nwhere \\(\\Delta L_{i,j,t} = L_{V_{i,t}} - L_{V_{j,t}}\\) is the loss differential between models i and j.\nThe test statistic is:\n\\[\nGW_{i,j} = T\\bar{Z}'\\hat{\\Omega}\\bar{Z} \\overset{d}{\\rightarrow} \\chi^2_q \\quad \\text{as } T \\rightarrow \\infty\n\\]\nwhere \\(Z_t = h_{t-1}\\Delta L_{i,j,t}\\), \\(\\bar{Z} = \\frac{1}{T}\\sum_{t=2}^T Z_t\\), and \\(\\hat{\\Omega} = \\frac{1}{T}\\sum_{t=2}^T Z_t Z_t'\\)."
  },
  {
    "objectID": "posts/07-02-2025_portfolio-var/index.html#sec-results",
    "href": "posts/07-02-2025_portfolio-var/index.html#sec-results",
    "title": "Comparing Univariate and Multivariate Models for Value at Risk Forecasting",
    "section": "3 Results",
    "text": "3 Results\n\n3.1 Value at Risk Backtests\n\n\n\n\n\n\n\n\nFigure 4: Chi-Square Q-Q Plot of the Carhart OLS Residuals\n\n\n\n\n\nFigure Figure 4 shows the Q-Q plot of OLS residuals, clearly indicating their non-normality.\nTable 1 shows that while all univariate models passed the likelihood ratio test of independence, only a few showed adequate conditional or unconditional coverage. In particular, only the skewed-t GJR-GARCH passed the test of conditional coverage for both VaR levels. In contrast, most multivariate models passed all likelihood ratio tests, with the exception of the multivariate normal (MN)-DCC-GARCH.\nIt’s notable that using skewed-t NGARCH marginals in the factor copula framework leads to a very low percentage of violations compared to other models. Surprisingly, even using a normal copula with normal GARCH marginals for factor returns produces sound VaR estimates, possibly because much of the multivariate non-normality of stock returns might be captured in the bootstrapped OLS residuals.\nModels assuming normality of returns (GARCH, EWMA, and MN-DCC-GARCH) consistently show too many violations, with none displaying adequate conditional or unconditional coverage. For these models, the percentage of violations is higher than the corresponding VaR level. For the COMFORT and factor copula models, however, we observe fewer violations than expected.\nThe most adequate coverage is achieved by the factor copula-DCC models with GARCH marginals for the 1% VaR level and by the COMFORT models for the 5% level. The factor skewed-t copula with GARCH marginals belongs to the three models with the most appropriate coverage for both VaR percentiles.\nNearly all exceedances for the COMFORT models occurred during or after the 2008 financial crisis, despite passing the independence test. At the 1% VaR level, Gaussian models without leverage effects have approximately three times as many exceedances as expected. At the 5% VaR level, this discrepancy is smaller.\n\n\n3.2 Conditional Predictive Ability Tests\nIn terms of average tick loss, univariate models perform well despite their suboptimal backtesting results. The skewed-t GJR model had the lowest and the MN-DCC-GARCH the highest average loss for both VaR levels. Multivariate models achieve better ranks at the 1% level than at the 5% level, with factor copula-based models showing lower average loss than COMFORT models at both levels.\nWithin the factor copula-DCC models, GARCH marginals achieved lower mean losses than skewed-t NGARCH marginals, reinforcing the hypothesis that bootstrapped OLS residuals account for much of the non-normality in stock returns.\nThe CPA test results show that the MN-DCC-GARCH is significantly outperformed by every other model. Most rejections occur in univariate vs. univariate or multivariate vs. multivariate comparisons. For multivariate models, factor copula-DCC models using skewed-t NGARCH marginals have significantly higher predictive ability than their counterparts with normal GARCH marginals. The normal copula is superior for skewed-t NGARCH marginals, but for normal GARCH marginals, the t and skewed-t copula versions significantly outperform the normal copula.\nAt the 5% VaR level, in addition to MN-DCC-GARCH, the MixN(3)-GARCH is also significantly outperformed by all other models. The Student t GJR-GARCH, skewed-t GJR-GARCH, and MixN(2)-GARCH all display significantly higher predictive ability than the COMFORT models.\nInterestingly, the skewed-t GJR-GARCH, which significantly outperformed every other univariate model, did not achieve significantly better VaR forecasts than the factor copula-DCC-(N)GARCH models."
  },
  {
    "objectID": "posts/07-02-2025_portfolio-var/index.html#sec-conclusion",
    "href": "posts/07-02-2025_portfolio-var/index.html#sec-conclusion",
    "title": "Comparing Univariate and Multivariate Models for Value at Risk Forecasting",
    "section": "4 Conclusion",
    "text": "4 Conclusion\nOur study assessed various univariate and multivariate models for VaR forecasting. Most univariate models produced inadequate VaR estimates with too many violations, while most multivariate models displayed adequate coverage with independently occurring VaR exceedances.\nThe CPA tests revealed that the MN-DCC-GARCH model is significantly outperformed by all other models, which is expected given the evident multivariate non-normality of stock returns. However, we found no general, significant outperformance of multivariate models over univariate ones, or vice versa, at either VaR level.\nOne important finding is that using daily returns (higher frequency data) makes the factor copula-DCC-NGARCH models feasible for VaR forecasting, consistent with Kole et al. (2017) who found that data frequency is more important than model choice for VaR forecasts.\nWe also found that replacing skewed-t NGARCH marginals with normal GARCH marginals for factor returns increased predictive accuracy and yielded better unconditional coverage. This may be because OLS residuals from the Carhart model capture most of the multivariate non-normality in stock returns.\nFor future research, it would be interesting to examine how the factor copula-DCC-GARCH model performs with larger portfolios, which would highlight the advantage of its dimensionality reduction. The only computationally expensive parts—fitting the DCC-GARCH structure and the copula—depend only on the number of factors, not the portfolio size."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Jan Schlegel",
    "section": "",
    "text": "Hi there! I’m Jan, a statistician and product manager based in Zurich. I recently completed my Master’s in Statistics at ETH Zurich, specializing in probabilistic AI, high-dimensional statistics, and causality. My work focuses on understanding and improving how machine learning systems make decisions—from interpreting generative models to building robust methods for high-stakes applications like climate forecasting and reinsurance.\nWhen I’m not working on difficult (for me) problems, you’ll find me running around Zurich, building PCs, or getting lost (intentionally) in GeoGuessr."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "Jan Schlegel",
    "section": "Education",
    "text": "Education\n\n\n🎓 Master of Science (M.Sc. ETH) in Statistics\n\n🏛️ ETH Zurich | 📍 Zurich, Switzerland | 📅 Sep 2023 - Sep 2025\n\n\nGPA: 5.99 / 6.00\n\n\nFocus: (Probabilistic) Machine Learning, Statistical Learning Theory, Computational Statistics, Causality\nThesis: Mechanistic Interpretability in Text-to-Image Diffusion Models (Grade: 6.00/6.00)\nSemester Paper: Extrapolation and Distributional Robustness for Climate Downscaling\n\n\n\n🎓 Bachelor of Arts in Business and Economics\n\n🏛️ University of Zurich | 📍 Zurich, Switzerland | 📅 Sep 2019 - Feb 2023\n\n\nGPA: 5.87 / 6.00 (Class Rank 1)\n\n\nMajor: Banking and Finance; Minor: Statistics\nThesis: Portfolio Value at Risk Forecasting with Copula-GARCH Models (Grade: 6.00/6.00)\nCompleted 215 ECTS (vs. standard 180) with a strong focus on quantitative finance, statistics, and computing"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "Jan Schlegel",
    "section": "Experience",
    "text": "Experience\n\n\n💼 Product Manager\n\n🏛️ Swiss Re | 📍 Zurich, Switzerland | 📅 Feb 2026 - Present\n\n\nDrive portfolio robust portfolio optimization initiatives across multiple product lines\nApply causal machine learning techniques to enhance risk assessment and decision-making processes\nTransitioned to full-time role following successful quantitative internship\n\n\n\n💼 Quantitative Intern\n\n🏛️ Swiss Re | 📍 Zurich, Switzerland | 📅 Oct 2025 - Jan 2026\n\n\nDeveloped robust high-dimensional covariance estimation methods applicable to multiple reinsurance contexts\nDesigned robust portfolio optimization techniques tailored to reinsurance, providing actionable steering insights\n\n\n\n💼 Biostatistics Research Assistant\n\n🏛️ University of Zurich (EBPI) | 📍 Zurich, Switzerland | 📅 Feb 2022 - Aug 2023\n\n\nContributed to data and code management and reproducible statistical workflows for a COVID-19 cohort study published in Nature Communications\nApplied statistical modelling techniques to complex longitudinal datasets and presented the results to principal investigators and the research team\n\n\n\n💼 Accountant (Military Service)\n\n🏛️ Swiss Armed Forces | 📍 Kloten, Switzerland | 📅 Jul 2021 - Nov 2021\n\n\nSuccessfully balanced full-time university studies with mandatory military service obligations\nManaged the complete accounting for a 150-person military unit\n\n\n\n💼 Teaching Assistant Mathematics\n\n🏛️ University of Zurich | 📍 Zurich, Switzerland | 📅 Sep 2020 - Jul 2021\n\n\nLed twice-weekly tutorials covering Analysis and Linear Algebra for groups of up to 30 students"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nData-Driven Tactics: Analyzing Spain’s Playing Style in Euro 2024 Qualifiers\n\n\n\n\n\n\nPython\n\n\nData Science\n\n\nData Analysis\n\n\nVisualization\n\n\nSports Analytics\n\n\n\nThis post presents a comprehensive data-driven analysis of Spain’s tactical approach during the Euro 2024 qualifiers using Wyscout and Skillcorner tracking data. We examine Spain’s characteristic ‘Tiki-Taka’ playing style through multiple analytical lenses: offside patterns, passing networks, set-piece execution, formation dynamics, and defensive line positioning. Our analysis reveals how Spain maintains possession through short passing sequences involving defenders, utilizes full pitch width when in possession, and employs a high defensive line that reflects their controlling philosophy. We also identify tactical vulnerabilities, particularly Spain’s susceptibility to offsides and counter-attacks, providing actionable insights for opposition teams.\n\n\n\n\n\nFeb 14, 2026\n\n\nJan Schlegel\n\n\n\n\n\n\n\n\n\n\n\n\nCovariance Shrinkage: From Linear Shrinkage to Random Matrix Theory\n\n\n\n\n\n\nQuantitative Finance\n\n\nPython\n\n\nHigh-Dimensional Statistics\n\n\n\nIn high-dimensional regimes where the number of variables \\(N\\) is comparable to the sample size \\(T\\), the sample covariance matrix is known to be an ill-conditioned and noisy estimator of the population covariance. This post provides a rigorous mathematical treatment of covariance shrinkage, exploring the bias-variance tradeoff inherent in linear shrinkage estimators (Ledoit-Wolf). We further ground these methods in Random Matrix Theory, specifically the Marchenko-Pastur law, to characterize the asymptotic behavior of eigenvalues. Finally, we introduce and implement Nonlinear Shrinkage (Ledoit-Wolf 2020), which applies a non-linear transformation to the sample eigenvalues based on the estimation of the Stieltjes transform. Simulation studies demonstrate the efficacy of these methods in recovering true spectral properties.\n\n\n\n\n\nNov 23, 2025\n\n\nJan Schlegel\n\n\n\n\n\n\n\n\n\n\n\n\nA Visual Introduction to Copulas\n\n\n\n\n\n\nStatistics\n\n\nFinance\n\n\nPython\n\n\n\nThis post offers a concise and intuitive introduction to copula theory, explaining what copulas are, why they are useful, and how they are applied in finance. We’ll skip the heavy math and focus on the core ideas.\n\n\n\n\n\nJul 29, 2025\n\n\nJan Schlegel\n\n\n\n\n\n\n\n\n\n\n\n\nA Guide to Portfolio Optimization\n\n\n\n\n\n\nFinance\n\n\nPython\n\n\nOptimization\n\n\n\nThis post provides a practical introduction to portfolio optimization, focusing on the foundational Mean-Variance framework by Harry Markowitz. We’ll explore the concepts of risk, return, the efficient frontier, and show how to implement it in Python.\n\n\n\n\n\nJul 26, 2025\n\n\nJan Schlegel\n\n\n\n\n\n\n\n\n\n\n\n\nAn Introduction to Stochastic Differential Equations\n\n\n\n\n\n\nMathematics\n\n\nFinance\n\n\nPython\n\n\n\nThis post provides an intuitive introduction to Stochastic Differential Equations (SDEs), the mathematical tool for modeling systems that evolve randomly over time. We’ll cover the basics of Brownian motion, Itô calculus, and how SDEs are used in finance.\n\n\n\n\n\nApr 3, 2025\n\n\nJan Schlegel\n\n\n\n\n\n\n\n\n\n\n\n\nComparing Univariate and Multivariate Models for Value at Risk Forecasting\n\n\n\n\n\n\nSimulation\n\n\nR\n\n\n\nThis post explores the effectiveness of univariate and multivariate GARCH-based models in forecasting Value at Risk (VaR) for a long equity portfolio. While multivariate models generally perform better in backtests, univariate models often fall short. However, neither model type consistently outperforms the other in predictive accuracy, highlighting the trade-offs between simplicity and complexity in risk forecasting.\n\n\n\n\n\nFeb 7, 2025\n\n\nJan Schlegel\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/14-02-2026_soccer-analytics/index.html#introduction",
    "href": "posts/14-02-2026_soccer-analytics/index.html#introduction",
    "title": "Data-Driven Tactics: Analyzing Spain’s Playing Style in Euro 2024 Qualifiers",
    "section": "1 Introduction",
    "text": "1 Introduction\nModern football analytics has transformed how we understand team tactics and playing styles. By leveraging detailed match event and tracking data, we can quantify patterns that were previously only observable through subjective analysis. This post examines Spain’s playing dynamics during the Euro 2024 qualifiers, combining Wyscout event data with Skillcorner tracking data to provide a multi-faceted tactical analysis.\nSpain’s national team has long been synonymous with possession-based football and their distinctive ‘Tiki-Taka’ style—characterized by short passing sequences, high technical skill, and positional fluidity. However, this approach comes with inherent tactical trade-offs. Through systematic data analysis, we can identify not only the strengths of this philosophy but also potential weaknesses that opposition teams might exploit.\nThe full code for this analysis is available on  GitHub. Note that the underlying data is confidential and therefore not included in the repository.\n\n1.1 Offside Patterns\nBased on our viewing experience we expected that Spain would have a relatively high number of offsides compared to other teams. A first glance at the data later confirmed that Spain was indeed among the teams with the most offsides in the Euro 2024 qualifiers. This is also displayed in the table below which is based on all Wyscout data of all matches after removing all of the non-European teams. Interestingly, Albania is also among the top ten teams with the highest number of offsides per game.\nOne player particularly caught our eye: Álvaro Morata who was caught offside eight times across his six game appearances. However, as nominal data can be misleading in football, we decided to additionally have a look at the normalized offside calls per player. In the below plot we can see that albeit Álvaro Morata being flagged offside more frequently than his teammates he is not the player with the highest offside rate due to his high playing time (461 played minutes). Instead, the first place goes to Ansu Fati who, despite being caught offside only once, had the highest offside rate due to only playing for 45 minutes.\n\nMoreover, most of the offsides by the Spanish team occured after a forward pass attempt (most frequently by Dani Carvajal) into the final third of the pitch. The animations below show four examples of Spanish offside positions captured from different qualifying matches.\n\n\n\n\n\n\nCross from Dani Carvajal to Álvaro Morata (Spain vs Scotland)\n\n\n\n\n\nThrough ball from Dani Carvajal to Gavi (Spain vs Georgia)\n\n\n\n\n\n\n\nThrough ball from Pedro Porro to Álvaro Morata (Spain vs Scotland)\n\n\n\n\n\nThrough ball from Dani Carvajal to Álvaro Morata (Spain vs Scotland)\n\n\n\n\n\n1.2 Passing Patterns and Accuracy\nAdditionally, we investigated the relationship between passing accuracy and number of passes when normalizing the number of passes by the minutes played in the left plot below. It is apparent that center backs tend to have the highest number of passes and the highest accuracy whilst forwards usually have the lowest passing completion rate with few passes per minute. This is in line with the typical Spanish “Tiki-Taka” playstyle where risky passes are often avoided and instead the ball is circulated around the pitch frequently involving defenders in the build up. Moreover, when stratifying the accuracy by whether or not the player was under pressure at the time of the pass, we observe that the accuracy of the passes under pressure tends to be lower than the passes without pressure. This is displayed in the right plot below where the forwards again are in the bottom left corner and the center back in the top right corner. Our explanation for this is that the forwards often will be pressured by multiple defenders yielding a much lower accuracy when under pressure compared to under no pressure. Interestingly, the pass completion percentage of the Goalkeeper Unai Simón is much lower when under pressure probably because he just clears the ball away whenever under pressure. Finally, be aware that contains only relatively few passes under pressure and thus we had to restrict ourselves to players with a minimum of 135 minutes (equivalent to 1.5 full games) played to not overcrowd the plot with players that have made no or only few passes under pressure.\n\n\n\n\n\n\n\n\n\n\nThis “false nine” role is further emphasized in the passing sonars below with the central forward only involved in few passes. Judging from the color fill of the sonars it appears that apart from the goalkeeper and the central midfielders, the players generally tend to avoid long passes. Again, we can see that forwards often pass backwards to keep possession, while the defenders often pass the ball back and forth to each other, and the central midfielders distribute it and play out wide. These patterns demonstrate that the Spanish team remains faithful to their beloved “Tiki-Taka” style of play."
  },
  {
    "objectID": "posts/14-02-2026_soccer-analytics/index.html#set-piece-analysis",
    "href": "posts/14-02-2026_soccer-analytics/index.html#set-piece-analysis",
    "title": "Data-Driven Tactics: Analyzing Spain’s Playing Style in Euro 2024 Qualifiers",
    "section": "2 Set Piece Analysis",
    "text": "2 Set Piece Analysis\nIn the following subsections, we will examine different set pieces, how they are executed by the Spanish team and how they change the game dynamics and outcomes.\n\n2.1 Throw-ins\nThe plots below show the throw-in sonars (left) and trajectories (right) for the Spanish team across all eight qualifying matches and are based on Wyscout data. The throw-in sonars show the angle of the throw-ins, with the length of the sonar indicating the frequency of throw-ins in that direction and the color specifying the length of the throw-in in meters. The plot on the right shows the trajectory from the beginning to the end location of the throw-ins colored by whether the throw-in was accurate or not. In the plot on the right, Spain attacks from the bottom to the top of the plot.\n\n\n\n\n\n\n\n\n\n\nIt is apparent from the throw-in trajectories on the right that most of the throw-ins for the Spanish team take place in the middle and attacking thirds of the pitch. Moreover, there does not appear to be a systematic relationship between throw-in accuracy and the different thirds. In general, there are only few inaccurate throw-ins despite the average throw-in distance being almost 20 meters. This can be explained by the throw-in sonars from which it is evident that most of the throw-ins and directed backwards, especially in the attacking third. Thus, the Spanish team does not rely on throw-ins to create scoring opportunities in the attacking third but instead utilize them to maintain possession and stabilize their play.\n\n\n2.2 Corners\nThe plot below shows the corner kick trajectories for the Spanish team colored by accuracy, where a corner is considered accurate if a Spanish player successfully receives the ball. Overall, Spain’s corner accuracy is striking, especially for deliveries going directly into the box. We can also see that many corners are played short and backwards, likely to retain possession and create a better crossing angle.\nInterestingly, there is a notable asymmetry between the two sides: corners from the left side are overwhelmingly accurate, even when delivered into the middle of the box. In contrast, corners from the right side that target the area close to the goal are frequently inaccurate, suggesting that the in-swinging deliveries from the left are more effective than the out-swinging ones from the right for Spain’s set-piece setup."
  },
  {
    "objectID": "posts/14-02-2026_soccer-analytics/index.html#formation-and-positioning-analysis",
    "href": "posts/14-02-2026_soccer-analytics/index.html#formation-and-positioning-analysis",
    "title": "Data-Driven Tactics: Analyzing Spain’s Playing Style in Euro 2024 Qualifiers",
    "section": "3 Formation and Positioning Analysis",
    "text": "3 Formation and Positioning Analysis\n\n3.1 Formation Convex Hulls\nThe plots below show the formation at two random time points during the first half and two random time points in the second half for all games for which we have Skillcorner data. As in Shaw and Glickman (2019), the shaded regions indicate the convex hull of the players with the blue arrow pointing to the center of mass of this convex hull. This allows us to compare the relative positioning of the Spanish players across randomly selected time points stratified by possession type. The distinction between in possession and out of possession is made only when the team has been in or out of possession for at least 10 seconds, ensuring that only stable formations are included in the analysis. Finally, Spain attacks from the bottom to the top in all of the plots.\n\n\n\nIn Possession\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOut of Possession\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIt is evident, that whenever Spain is in possession, the team tries utilizing the full width of the pitch. This creates space and ensures that there are always passing options available for Spains infamous short passing game. Formation-wise, the 4-3-3 formation of Spain tends to persist whenever Spain is in possession. The midfielders often form a triangle to provide multiple passing options. This structure is crucial for maintaining possession and slowly advancing the ball up the pitch. In contrast, when Spain is out of possession, the team tends to adopt a more narrow and compact formation. The formation still resembles a 4-3-3, but the midfielder drop back which leads to the players being closer together. This limits the space available for the opposition allows Spain to press more effectively in the midfield. Additionally, this compact formation often forces the opposition to play on the sides of the pitch instead of through the densely-populated middle.\n\n\n3.2 Defensive Line Positioning\nThe heatmaps below display Spain’s defensive line positioning both in possession and out of possession across all matches for which we have access to Skillcorner data. .Note that contrary to above formation plots, these heatmaps include all data points for completeness i.e. there is no minimum amount of time in/ out of possession required. Again, Spain attacks from the bottom to the top in all of the plots.\n\n\n\nIn Possession\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOut of Possession\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe heatmaps show that the defensive line tends to be slightly more offensive when in possession but the difference between in and out of possession is not striking. In general, the defensive line is always relatively high up the pitch, with the most frequent positions being right in front of the middle line. This is in line with Spain’s controlling play style when in possession and high pressing when out of possession. Additionally, the defensive line tends to be higher when playing against weaker teams.\nMoreover, both wing backs tend to be positioned further forward than the center backs, as is typical in the 4-3-3 formation that Spain loves to run. This allows the wing backs to provide width and support when attacking whilst the more defensively positioned center-backs provide stability and try to always be available for a back pass when the team is under pressure or wants stabilize the game."
  },
  {
    "objectID": "posts/14-02-2026_soccer-analytics/index.html#tactical-recommendations-for-opposition-teams",
    "href": "posts/14-02-2026_soccer-analytics/index.html#tactical-recommendations-for-opposition-teams",
    "title": "Data-Driven Tactics: Analyzing Spain’s Playing Style in Euro 2024 Qualifiers",
    "section": "4 Tactical Recommendations for Opposition Teams",
    "text": "4 Tactical Recommendations for Opposition Teams\nBased on our comprehensive analysis of Spain’s playing style, we can identify several tactical vulnerabilities that opposition teams might exploit:\n\n4.1 Exploiting the Offside Trap\nAs was detailed in the offside analysis section, Spanish players frequently get caught offside. Hence, Albania should maintain a well-organized defensive line that moves up as a unit to catch Spanish players offside. Particularly, Albania could try to exploit the fact that Carvajal’s through ball attempts to Álvaro Morata often result in offside positions by tracking Morata and stepping up as a unit when Carvajal is about to play the ball, effectively creating an offside trap. The resulting free-kick could then be used to quickly launch a counter-attack exploiting Spain’s high positioning.\n\n\n4.2 Pressing the Forwards\nThe passing analysis showed us that the forwards are particularly susceptible to making inaccurate passes when under pressure. Moreover, we observed that in Spain’s game development style, the strikers often drop back to receive the ball and then distribute it back to the midfield or to the flanks. This suggests pressuring the forwards whenever possible, without compromising our own defensive line too much, to provoke inaccurate passes. Albania could implement this by having one of the center backs remain as attentive as possible while maintaining close one-to-one marking of the central forward.\n\n\n4.3 Exploiting the High Defensive Line\nAs seen in our defensive line analysis, Spain employs a high defensive line as a consequence of their possession-based playstyle, which renders them vulnerable to quick counter-attacks. Hence, Albania should occasionally try to exploit this high defensive line by attempting long balls behind the Spanish defense, even if this might cost Albania possession more often than not."
  },
  {
    "objectID": "posts/03-04-2025_intro_to_sde/index.html",
    "href": "posts/03-04-2025_intro_to_sde/index.html",
    "title": "Stochastic Differential Equations: From Mathematical Foundations to Modern Applications",
    "section": "",
    "text": "Stochastic differential equations provide the mathematical framework for modeling continuous-time random processes, with applications spanning from option pricing to generative AI models"
  },
  {
    "objectID": "posts/03-04-2025_intro_to_sde/index.html#sec-introduction",
    "href": "posts/03-04-2025_intro_to_sde/index.html#sec-introduction",
    "title": "Stochastic Differential Equations: From Mathematical Foundations to Modern Applications",
    "section": "1 Introduction",
    "text": "1 Introduction\nStochastic differential equations (SDEs) represent one of the most profound and mathematically elegant frameworks in modern probability theory and applied mathematics. These equations describe the evolution of random processes in continuous time, providing the mathematical foundation for modeling phenomena characterized by both deterministic trends and random fluctuations [@oksendal2003; @karatzas1991].\nThe theoretical development of SDE theory emerged from the intersection of probability theory, differential equations, and mathematical finance, culminating in the revolutionary work of Kiyoshi Itô in the 1940s. Itô’s groundbreaking construction of stochastic integration transformed our understanding of random processes and established the mathematical framework that now underpins modern quantitative finance, statistical physics, and machine learning [@ito1951; @mckean1969].\n\n1.1 Historical Development and Motivation\nThe genesis of stochastic differential equations can be traced to Louis Bachelier’s pioneering 1900 thesis on option pricing, where he first applied Brownian motion to financial markets [@bachelier1900]. However, it was not until Norbert Wiener’s rigorous mathematical construction of Brownian motion in the 1920s that the field gained its theoretical foundation [@wiener1923].\nThe transformative breakthrough came with Itô’s development of stochastic calculus in the 1940s and 1950s. Itô recognized that classical calculus was inadequate for handling functions of Brownian motion due to their non-differentiable nature, leading to his construction of stochastic integration and the famous Itô’s lemma [@ito1951]. This work established the mathematical machinery necessary for:\n\nRigorous treatment of random processes: Moving beyond heuristic arguments to mathematically precise formulations\nFinancial modeling: Providing the foundation for modern option pricing theory through the Black-Scholes model\nEngineering applications: Enabling analysis of systems subject to random disturbances\nMachine learning: Supporting modern developments in neural differential equations and diffusion models\n\n\n\n1.2 Contemporary Relevance and Applications\nIn the 21st century, SDEs have experienced a renaissance driven by advances in computational methods and emerging applications in machine learning. Key contemporary developments include:\nMathematical Finance: SDEs form the backbone of modern derivatives pricing, risk management, and portfolio optimization. Models like the Heston stochastic volatility model and interest rate models (Vasicek, Cox-Ingersoll-Ross) are built on SDE foundations [@heston1993; @cox1985].\nMachine Learning and AI: Recent breakthroughs in generative modeling, particularly diffusion models for image generation, rely heavily on SDE theory. Neural ordinary differential equations (NODEs) and neural SDEs represent cutting-edge applications of stochastic analysis to deep learning [@chen2018; @song2021].\nScientific Computing: SDEs provide essential tools for modeling complex systems in physics, biology, and engineering where random effects play a crucial role [@gardiner2009].\n\n\n1.3 Scope and Mathematical Prerequisites\nThis treatise provides a comprehensive, PhD-level treatment of stochastic differential equation theory and applications. We assume familiarity with:\n\nReal analysis: Measure theory, Lebesgue integration, and functional analysis\nProbability theory: Probability spaces, random variables, and basic stochastic processes\nDifferential equations: Ordinary differential equations and partial differential equations\nLinear algebra: Matrix theory and spectral analysis\n\nOur systematic development progresses through:\nTheoretical Foundations (Sections 2-4): We establish the mathematical framework, beginning with Brownian motion and filtrations, developing Itô calculus, and proving fundamental existence and uniqueness theorems.\nNumerical Methods (Section 5): We examine computational approaches including Euler-Maruyama and Milstein schemes, analyzing convergence properties and implementation considerations.\nFinancial Applications (Section 6): We explore classical applications in option pricing, interest rate modeling, and risk management, providing complete derivations and implementations.\nModern Machine Learning Applications (Sections 7-8): We investigate contemporary applications in neural differential equations, diffusion models, and Gaussian processes, connecting classical theory to cutting-edge developments.\nAdvanced Topics (Section 9): We cover jump-diffusion processes, stochastic volatility models, and path-dependent derivatives.\nThroughout, we provide rigorous mathematical proofs, comprehensive Python implementations optimized with modern computational libraries, and publication-quality visualizations that illuminate key concepts and facilitate practical application."
  },
  {
    "objectID": "posts/03-04-2025_intro_to_sde/index.html#sec-foundations",
    "href": "posts/03-04-2025_intro_to_sde/index.html#sec-foundations",
    "title": "Stochastic Differential Equations: From Mathematical Foundations to Modern Applications",
    "section": "2 Mathematical Foundations",
    "text": "2 Mathematical Foundations\n\n2.1 Probability Spaces and Filtrations\nThe rigorous development of stochastic differential equation theory requires careful construction of the underlying probability framework. We begin with the fundamental mathematical structures that support stochastic analysis.\nDefinition 2.1 (Probability Space): A probability space is a triple \\((\\Omega, \\mathcal{F}, \\mathbb{P})\\) where: - \\(\\Omega\\) is the sample space representing all possible outcomes - \\(\\mathcal{F}\\) is a \\(\\sigma\\)-algebra on \\(\\Omega\\) representing measurable events - \\(\\mathbb{P}: \\mathcal{F} \\to [0,1]\\) is a probability measure satisfying \\(\\mathbb{P}(\\Omega) = 1\\)\nDefinition 2.2 (Filtration): A filtration \\(\\{\\mathcal{F}_t\\}_{t \\geq 0}\\) is an increasing family of sub-\\(\\sigma\\)-algebras of \\(\\mathcal{F}\\): \\[\\mathcal{F}_s \\subseteq \\mathcal{F}_t \\subseteq \\mathcal{F} \\quad \\text{for all } 0 \\leq s \\leq t\\]\nThe filtration represents the evolution of information over time, where \\(\\mathcal{F}_t\\) contains all events observable up to time \\(t\\).\n\n\n2.2 Brownian Motion and the Wiener Process\nBrownian motion forms the cornerstone of stochastic calculus, providing the fundamental building block for constructing more complex stochastic processes.\nDefinition 2.3 (Standard Brownian Motion): A stochastic process \\(\\{W_t\\}_{t \\geq 0}\\) defined on \\((\\Omega, \\mathcal{F}, \\mathbb{P})\\) is called standard Brownian motion if:\n\nInitial condition: \\(W_0 = 0\\) almost surely\nIndependent increments: For any \\(0 \\leq t_1 &lt; t_2 &lt; \\cdots &lt; t_n\\), the increments \\(W_{t_2} - W_{t_1}, W_{t_3} - W_{t_2}, \\ldots, W_{t_n} - W_{t_{n-1}}\\) are independent\nGaussian increments: For any \\(s &lt; t\\), \\(W_t - W_s \\sim \\mathcal{N}(0, t-s)\\)\nContinuous paths: \\(t \\mapsto W_t(\\omega)\\) is continuous for almost all \\(\\omega \\in \\Omega\\)\n\n\n\nCode\n@njit\ndef simulate_brownian_motion(T, N, n_paths=5):\n    \"\"\"Efficiently simulate Brownian motion paths using Numba acceleration.\"\"\"\n    dt = T / N\n    sqrt_dt = np.sqrt(dt)\n    \n    paths = np.zeros((n_paths, N + 1))\n    \n    for i in range(n_paths):\n        for j in range(1, N + 1):\n            paths[i, j] = paths[i, j-1] + sqrt_dt * np.random.randn()\n    \n    return paths\n\n# Simulation parameters\nT = 1.0  # Time horizon\nN = 500  # Number of time steps (reduced for faster rendering)\nn_paths = 50  # Reduced number of paths\ndt = T / N\nt = np.linspace(0, T, N + 1)\n\n# Generate multiple Brownian motion paths\nnp.random.seed(42)\npaths = simulate_brownian_motion(T, N, n_paths)\n\nfig, axes = plt.subplots(2, 3, figsize=(18, 12))\n\n# Sample paths\naxes[0, 0].plot(t, paths[:10].T, alpha=0.6, linewidth=0.8)\naxes[0, 0].plot(t, paths[0], 'r-', linewidth=2, label='Sample path')\naxes[0, 0].set_title('Sample Paths of Brownian Motion')\naxes[0, 0].set_xlabel('Time t')\naxes[0, 0].set_ylabel('W(t)')\naxes[0, 0].legend()\naxes[0, 0].grid(True, alpha=0.3)\n\n# Distribution at fixed time\nt_fixed = 0.5\nW_fixed = paths[:, int(t_fixed * N)]\naxes[0, 1].hist(W_fixed, bins=30, density=True, alpha=0.7, color='skyblue')\nx_range = np.linspace(W_fixed.min(), W_fixed.max(), 100)\ntheoretical_pdf = stats.norm.pdf(x_range, 0, np.sqrt(t_fixed))\naxes[0, 1].plot(x_range, theoretical_pdf, 'r-', linewidth=2, label=f'N(0, {t_fixed})')\naxes[0, 1].set_title(f'Distribution of W({t_fixed})')\naxes[0, 1].set_xlabel('Value')\naxes[0, 1].set_ylabel('Density')\naxes[0, 1].legend()\n\n# Increment distribution\nincrements = np.diff(paths[0])\naxes[0, 2].hist(increments, bins=40, density=True, alpha=0.7, color='lightcoral')\nx_inc = np.linspace(increments.min(), increments.max(), 100)\ntheoretical_inc = stats.norm.pdf(x_inc, 0, np.sqrt(dt))\naxes[0, 2].plot(x_inc, theoretical_inc, 'k-', linewidth=2, label=f'N(0, {dt:.3f})')\naxes[0, 2].set_title('Increment Distribution')\naxes[0, 2].set_xlabel('Increment Value')\naxes[0, 2].set_ylabel('Density')\naxes[0, 2].legend()\n\n# Quadratic variation approximation\ndef quadratic_variation(path, dt):\n    \"\"\"Compute empirical quadratic variation.\"\"\"\n    increments = np.diff(path)\n    return np.cumsum(increments**2)\n\nqv = quadratic_variation(paths[0], dt)\naxes[1, 0].plot(t[1:], qv, 'b-', linewidth=2, label='Empirical [W,W]_t')\naxes[1, 0].plot(t, t, 'r--', linewidth=2, label='Theoretical t')\naxes[1, 0].set_title('Quadratic Variation')\naxes[1, 0].set_xlabel('Time t')\naxes[1, 0].set_ylabel('[W,W]_t')\naxes[1, 0].legend()\naxes[1, 0].grid(True, alpha=0.3)\n\n# Path roughness (non-differentiability)\n# Compute finite difference approximations to derivatives\nh_values = [0.1, 0.05, 0.01, 0.005]\ncolors = ['red', 'blue', 'green', 'orange']\n\nfor i, h in enumerate(h_values):\n    n_h = int(h / dt)\n    if n_h &gt; 0:\n        t_deriv = t[:-n_h]\n        finite_diff = (paths[0, n_h:] - paths[0, :-n_h]) / h\n        axes[1, 1].plot(t_deriv, finite_diff, color=colors[i], alpha=0.7, \n                       linewidth=1, label=f'h = {h}')\n\naxes[1, 1].set_title('Finite Difference Approximations\\n(Illustrating Non-differentiability)')\naxes[1, 1].set_xlabel('Time t')\naxes[1, 1].set_ylabel('(W(t+h) - W(t))/h')\naxes[1, 1].legend()\naxes[1, 1].grid(True, alpha=0.3)\n\n# Scaling property demonstration\nscaled_paths = []\nscale_factors = [0.5, 1.0, 2.0]\ncolors_scale = ['blue', 'red', 'green']\n\nfor i, c in enumerate(scale_factors):\n    # W(ct) has same distribution as sqrt(c) * W(t)\n    if c != 1.0:\n        t_scaled = t * c\n        if c &lt; 1.0:\n            # Subsample for c &lt; 1\n            indices = np.linspace(0, len(t)-1, int(len(t)*c)).astype(int)\n            scaled_path = paths[0, indices] / np.sqrt(c)\n            t_plot = t[:len(indices)]\n        else:\n            # Extend time for c &gt; 1 (simplified for faster rendering)\n            extended_path = simulate_brownian_motion(T*c, int(N*c*0.5), 1)[0]\n            scaled_path = extended_path / np.sqrt(c)\n            t_plot = np.linspace(0, T, len(scaled_path))\n    else:\n        scaled_path = paths[0]\n        t_plot = t\n    \n    axes[1, 2].plot(t_plot, scaled_path, color=colors_scale[i], \n                   linewidth=1.5, alpha=0.8, label=f'c = {c}')\n\naxes[1, 2].set_title('Self-Similarity Property\\nW(ct) ~ √c · W(t)')\naxes[1, 2].set_xlabel('Time t')\naxes[1, 2].set_ylabel('Scaled W(t)')\naxes[1, 2].legend()\naxes[1, 2].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1: Sample paths of Brownian motion and their key properties\n\n\n\n\n\nTheorem 2.4 (Properties of Brownian Motion): Standard Brownian motion possesses the following fundamental properties:\n\nMartingale property: \\(\\{W_t\\}\\) is a martingale with respect to its natural filtration\nQuadratic variation: \\([W,W]_t = t\\) (in the sense of convergence in probability)\nMarkov property: For \\(s &lt; t\\), \\(\\mathbb{E}[f(W_t) | \\mathcal{F}_s] = \\mathbb{E}[f(W_t) | W_s]\\)\nSelf-similarity: \\(\\{W_{ct}\\}_{t \\geq 0} \\stackrel{d}{=} \\{\\sqrt{c} W_t\\}_{t \\geq 0}\\) for any \\(c &gt; 0\\)\nPath properties: Paths are continuous but nowhere differentiable with probability 1\n\n\n\n2.3 Multi-dimensional Brownian Motion\nDefinition 2.5 (d-dimensional Brownian Motion): A \\(d\\)-dimensional Brownian motion is a vector process \\(\\mathbf{W}_t = (W_t^{(1)}, \\ldots, W_t^{(d)})^T\\) where each component \\(W_t^{(i)}\\) is independent standard Brownian motion.\nFor correlated Brownian motions, we can construct them using: \\[\\mathbf{W}_t = \\mathbf{L} \\mathbf{Z}_t\\] where \\(\\mathbf{Z}_t\\) is \\(d\\)-dimensional independent Brownian motion and \\(\\mathbf{L}\\) is the Cholesky decomposition of the correlation matrix \\(\\boldsymbol{\\Sigma}\\).\n\n\nCode\ndef simulate_correlated_brownian(T, N, correlation_matrix, n_paths=1):\n    \"\"\"Simulate correlated multi-dimensional Brownian motion.\"\"\"\n    d = correlation_matrix.shape[0]\n    dt = T / N\n    sqrt_dt = np.sqrt(dt)\n    \n    # Cholesky decomposition for correlation\n    L = cholesky(correlation_matrix, lower=True)\n    \n    paths = np.zeros((n_paths, d, N + 1))\n    \n    for path in range(n_paths):\n        for i in range(1, N + 1):\n            # Generate independent increments\n            dZ = np.random.randn(d) * sqrt_dt\n            # Apply correlation structure\n            dW = L @ dZ\n            paths[path, :, i] = paths[path, :, i-1] + dW\n    \n    return paths\n\n# Correlation matrices\ncorrelations = [\n    np.array([[1.0, 0.0], [0.0, 1.0]]),  # Independent\n    np.array([[1.0, 0.7], [0.7, 1.0]]),  # Positive correlation\n    np.array([[1.0, -0.5], [-0.5, 1.0]]) # Negative correlation\n]\n\ncorrelation_names = ['Independent (ρ=0)', 'Positive (ρ=0.7)', 'Negative (ρ=-0.5)']\n\nfig, axes = plt.subplots(2, 3, figsize=(16, 10))\n\nfor i, (corr_matrix, name) in enumerate(zip(correlations, correlation_names)):\n    # Simulate paths\n    paths = simulate_correlated_brownian(T, N, corr_matrix, n_paths=100)\n    t = np.linspace(0, T, N + 1)\n    \n    # Time series plot\n    for j in range(20):  # Plot subset of paths\n        axes[0, i].plot(t, paths[j, 0, :], alpha=0.3, color='blue', linewidth=0.8)\n        axes[0, i].plot(t, paths[j, 1, :], alpha=0.3, color='red', linewidth=0.8)\n    \n    # Highlight one path\n    axes[0, i].plot(t, paths[0, 0, :], color='blue', linewidth=2, label='W₁(t)')\n    axes[0, i].plot(t, paths[0, 1, :], color='red', linewidth=2, label='W₂(t)')\n    axes[0, i].set_title(f'Time Series: {name}')\n    axes[0, i].set_xlabel('Time t')\n    axes[0, i].set_ylabel('W(t)')\n    axes[0, i].legend()\n    axes[0, i].grid(True, alpha=0.3)\n    \n    # Phase plot (W₁ vs W₂)\n    for j in range(50):\n        axes[1, i].plot(paths[j, 0, :], paths[j, 1, :], alpha=0.4, linewidth=0.6)\n    \n    axes[1, i].scatter(0, 0, color='green', s=100, marker='o', zorder=5, label='Origin')\n    axes[1, i].set_title(f'Phase Plot: {name}')\n    axes[1, i].set_xlabel('W₁(t)')\n    axes[1, i].set_ylabel('W₂(t)')\n    axes[1, i].legend()\n    axes[1, i].grid(True, alpha=0.3)\n    axes[1, i].axis('equal')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 2: Multi-dimensional Brownian motion with correlation structure\n\n\n\n\n\n\n\n2.4 Martingales and Stopping Times\nDefinition 2.6 (Martingale): A stochastic process \\(\\{M_t\\}_{t \\geq 0}\\) adapted to filtration \\(\\{\\mathcal{F}_t\\}\\) is a martingale if: 1. \\(\\mathbb{E}[|M_t|] &lt; \\infty\\) for all \\(t \\geq 0\\) 2. \\(\\mathbb{E}[M_t | \\mathcal{F}_s] = M_s\\) for all \\(0 \\leq s \\leq t\\)\nTheorem 2.7 (Examples of Martingales): The following processes are martingales: 1. Brownian motion \\(W_t\\) 2. \\(W_t^2 - t\\) (compensated quadratic variation) 3. \\(\\exp(\\sigma W_t - \\frac{\\sigma^2 t}{2})\\) for any \\(\\sigma \\in \\mathbb{R}\\) (exponential martingale)\nDefinition 2.8 (Stopping Time): A random variable \\(\\tau: \\Omega \\to [0, \\infty]\\) is a stopping time with respect to \\(\\{\\mathcal{F}_t\\}\\) if for every \\(t \\geq 0\\): \\[\\{\\tau \\leq t\\} \\in \\mathcal{F}_t\\]\nTheorem 2.9 (Optional Stopping Theorem): If \\(M_t\\) is a martingale and \\(\\tau\\) is a bounded stopping time, then: \\[\\mathbb{E}[M_\\tau] = \\mathbb{E}[M_0]\\]\nThese foundational concepts provide the mathematical infrastructure necessary for constructing stochastic integrals and developing the theory of stochastic differential equations. In the next section, we will build upon this foundation to develop Itô calculus, the cornerstone of stochastic analysis."
  },
  {
    "objectID": "posts/03-04-2025_intro_to_sde/index.html#sec-ito-calculus",
    "href": "posts/03-04-2025_intro_to_sde/index.html#sec-ito-calculus",
    "title": "Stochastic Differential Equations: From Mathematical Foundations to Modern Applications",
    "section": "3 Itô Calculus and Stochastic Integration",
    "text": "3 Itô Calculus and Stochastic Integration\nThe development of stochastic calculus represents one of the most profound mathematical achievements of the 20th century. Classical calculus fails when applied to functions of Brownian motion due to their infinite variation and non-differentiable nature. Itô’s revolutionary insight was to develop a new form of calculus specifically designed for stochastic processes.\n\n3.1 The Need for Stochastic Calculus\nConsider attempting to define the integral \\(\\int_0^t W_s \\, dW_s\\) using classical Riemann-Stieltjes integration. The fundamental problem arises from the fact that Brownian motion has infinite variation on any interval, making classical integration impossible.\n\n\nCode\ndef compute_variation(path, time_grid):\n    \"\"\"Compute total variation of a function on given grid.\"\"\"\n    return np.sum(np.abs(np.diff(path)))\n\ndef compute_quadratic_variation(path, time_grid):\n    \"\"\"Compute quadratic variation approximation.\"\"\"\n    return np.sum(np.diff(path)**2)\n\n# Generate fine Brownian motion path\nT = 1.0\nN_fine = 10000\nt_fine = np.linspace(0, T, N_fine + 1)\ndt_fine = T / N_fine\n\nnp.random.seed(42)\nW_fine = np.cumsum(np.concatenate([[0], np.random.randn(N_fine) * np.sqrt(dt_fine)]))\n\n# Compute variations for different grid sizes\ngrid_sizes = np.logspace(1, 4, 20).astype(int)\ntotal_variations = []\nquadratic_variations = []\n\nfor N in grid_sizes:\n    if N &lt;= N_fine:\n        indices = np.linspace(0, N_fine, N + 1).astype(int)\n        subpath = W_fine[indices]\n        t_sub = t_fine[indices]\n        \n        total_var = compute_variation(subpath, t_sub)\n        quad_var = compute_quadratic_variation(subpath, t_sub)\n        \n        total_variations.append(total_var)\n        quadratic_variations.append(quad_var)\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 8))\n\n# Plot path and variations\nN_display = 1000\nindices = np.linspace(0, N_fine, N_display + 1).astype(int)\naxes[0].plot(t_fine[indices], W_fine[indices], 'b-', linewidth=1, alpha=0.8)\naxes[0].set_title('Sample Brownian Motion Path')\naxes[0].set_xlabel('Time t')\naxes[0].set_ylabel('W(t)')\naxes[0].grid(True, alpha=0.3)\n\n# Plot variation convergence\naxes[1].loglog(grid_sizes[:len(total_variations)], total_variations, 'ro-', \n               label='Total Variation', markersize=4)\naxes[1].loglog(grid_sizes[:len(quadratic_variations)], quadratic_variations, 'bs-', \n               label='Quadratic Variation', markersize=4)\naxes[1].axhline(y=T, color='black', linestyle='--', linewidth=2, \n                label=f'Theoretical QV = {T}')\naxes[1].set_xlabel('Number of Grid Points')\naxes[1].set_ylabel('Variation')\naxes[1].set_title('Variation Behavior as Grid Refines')\naxes[1].legend()\naxes[1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(f\"Final total variation: {total_variations[-1]:.2f}\")\nprint(f\"Final quadratic variation: {quadratic_variations[-1]:.3f}\")\nprint(f\"Theoretical quadratic variation: {T}\")\n\n\n\n\n\n\n\n\nFigure 3: Illustration of infinite variation in Brownian motion\n\n\n\n\n\nFinal total variation: 79.95\nFinal quadratic variation: 1.007\nTheoretical quadratic variation: 1.0\n\n\n\n\n3.2 Construction of the Itô Integral\nDefinition 3.1 (Simple Process): A stochastic process \\(\\{H_t\\}\\) is simple if it can be written as: \\[H_t = H_0 \\mathbf{1}_{\\{0\\}}(t) + \\sum_{i=1}^n H_{t_i} \\mathbf{1}_{(t_i, t_{i+1}]}(t)\\] where \\(0 = t_0 &lt; t_1 &lt; \\cdots &lt; t_n &lt; \\infty\\) and each \\(H_{t_i}\\) is \\(\\mathcal{F}_{t_i}\\)-measurable.\nDefinition 3.2 (Itô Integral for Simple Processes): For a simple process \\(H_t\\), the Itô integral is defined as: \\[\\int_0^t H_s \\, dW_s = \\sum_{i=0}^{n-1} H_{t_i}(W_{t_{i+1} \\wedge t} - W_{t_i \\wedge t})\\]\nTheorem 3.3 (Itô Isometry): For simple processes \\(H_t\\): \\[\\mathbb{E}\\left[\\left(\\int_0^t H_s \\, dW_s\\right)^2\\right] = \\mathbb{E}\\left[\\int_0^t H_s^2 \\, ds\\right]\\]\nDefinition 3.4 (General Itô Integral): For adapted processes \\(H_t\\) satisfying \\(\\mathbb{E}\\left[\\int_0^t H_s^2 \\, ds\\right] &lt; \\infty\\), the Itô integral \\(\\int_0^t H_s \\, dW_s\\) is defined as the \\(L^2\\) limit of Itô integrals of simple processes approximating \\(H_t\\).\n\n\n3.3 Itô’s Lemma: The Fundamental Theorem\nTheorem 3.5 (Itô’s Lemma): Let \\(W_t\\) be Brownian motion and \\(f(t,x) \\in C^{1,2}([0,\\infty) \\times \\mathbb{R})\\). Then:\n\\[df(t, W_t) = \\frac{\\partial f}{\\partial t}(t, W_t) dt + \\frac{\\partial f}{\\partial x}(t, W_t) dW_t + \\frac{1}{2}\\frac{\\partial^2 f}{\\partial x^2}(t, W_t) dt\\]\nProof Sketch: The key insight is the quadratic variation term. Using Taylor expansion: \\[df = f_t dt + f_x dW_t + \\frac{1}{2}f_{xx}(dW_t)^2 + \\frac{1}{2}f_{tt}(dt)^2 + f_{tx} dt \\, dW_t + \\cdots\\]\nSince \\((dW_t)^2 = dt\\) in the sense of quadratic variation, and higher-order terms vanish, we obtain Itô’s formula. □\n\n\nCode\ndef ito_lemma_verification(f, df_dt, df_dx, d2f_dx2, W_path, dt):\n    \"\"\"\n    Verify Itô's lemma numerically by comparing direct computation\n    with the Itô formula prediction.\n    \"\"\"\n    t = np.arange(len(W_path)) * dt\n    \n    # Direct computation of f(t, W_t)\n    f_values = f(t, W_path)\n    df_direct = np.diff(f_values)\n    \n    # Itô formula prediction\n    t_mid = t[:-1] + dt/2  # Midpoint rule for better accuracy\n    W_mid = (W_path[:-1] + W_path[1:]) / 2\n    dW = np.diff(W_path)\n    \n    df_ito = (df_dt(t_mid, W_mid) * dt + \n              df_dx(t_mid, W_mid) * dW + \n              0.5 * d2f_dx2(t_mid, W_mid) * dt)\n    \n    return df_direct, df_ito, f_values\n\n# Example 1: f(t,x) = x^2\ndef f1(t, x):\n    return x**2\n\ndef df1_dt(t, x):\n    return np.zeros_like(x)\n\ndef df1_dx(t, x):\n    return 2*x\n\ndef d2f1_dx2(t, x):\n    return 2 * np.ones_like(x)\n\n# Example 2: f(t,x) = exp(x - t/2) (Exponential martingale)\ndef f2(t, x):\n    return np.exp(x - t/2)\n\ndef df2_dt(t, x):\n    return -0.5 * np.exp(x - t/2)\n\ndef df2_dx(t, x):\n    return np.exp(x - t/2)\n\ndef d2f2_dx2(t, x):\n    return np.exp(x - t/2)\n\n# Simulation parameters\nT = 1.0\nN = 1000\ndt = T / N\nt = np.linspace(0, T, N + 1)\n\nnp.random.seed(42)\nW = np.cumsum(np.concatenate([[0], np.random.randn(N) * np.sqrt(dt)]))\n\nfig, axes = plt.subplots(2, 3, figsize=(16, 10))\n\n# Example 1: f(t,x) = x^2\ndf1_direct, df1_ito, f1_values = ito_lemma_verification(\n    f1, df1_dt, df1_dx, d2f1_dx2, W, dt)\n\naxes[0, 0].plot(t, f1_values, 'b-', linewidth=2, label='W²(t)')\naxes[0, 0].set_title('Function: f(t,x) = x²')\naxes[0, 0].set_xlabel('Time t')\naxes[0, 0].set_ylabel('f(t, W(t))')\naxes[0, 0].legend()\naxes[0, 0].grid(True, alpha=0.3)\n\naxes[0, 1].plot(t[:-1], df1_direct, 'b-', alpha=0.7, label='Direct: Δf')\naxes[0, 1].plot(t[:-1], df1_ito, 'r--', alpha=0.7, label='Itô formula')\naxes[0, 1].set_title('Increment Comparison')\naxes[0, 1].set_xlabel('Time t')\naxes[0, 1].set_ylabel('df')\naxes[0, 1].legend()\naxes[0, 1].grid(True, alpha=0.3)\n\n# Error analysis\nerror1 = df1_direct - df1_ito\naxes[0, 2].plot(t[:-1], error1, 'g-', linewidth=1)\naxes[0, 2].set_title(f'Error (RMS: {np.sqrt(np.mean(error1**2)):.6f})')\naxes[0, 2].set_xlabel('Time t')\naxes[0, 2].set_ylabel('Direct - Itô')\naxes[0, 2].grid(True, alpha=0.3)\n\n# Example 2: Exponential martingale\ndf2_direct, df2_ito, f2_values = ito_lemma_verification(\n    f2, df2_dt, df2_dx, d2f2_dx2, W, dt)\n\naxes[1, 0].plot(t, f2_values, 'purple', linewidth=2, label='exp(W(t) - t/2)')\naxes[1, 0].set_title('Exponential Martingale')\naxes[1, 0].set_xlabel('Time t')\naxes[1, 0].set_ylabel('f(t, W(t))')\naxes[1, 0].legend()\naxes[1, 0].grid(True, alpha=0.3)\n\naxes[1, 1].plot(t[:-1], df2_direct, 'purple', alpha=0.7, label='Direct: Δf')\naxes[1, 1].plot(t[:-1], df2_ito, 'orange', linestyle='--', alpha=0.7, label='Itô formula')\naxes[1, 1].set_title('Increment Comparison')\naxes[1, 1].set_xlabel('Time t')\naxes[1, 1].set_ylabel('df')\naxes[1, 1].legend()\naxes[1, 1].grid(True, alpha=0.3)\n\nerror2 = df2_direct - df2_ito\naxes[1, 2].plot(t[:-1], error2, 'red', linewidth=1)\naxes[1, 2].set_title(f'Error (RMS: {np.sqrt(np.mean(error2**2)):.6f})')\naxes[1, 2].set_xlabel('Time t')\naxes[1, 2].set_ylabel('Direct - Itô')\naxes[1, 2].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# Theoretical verification for x^2\nprint(\"Theoretical verification for f(t,x) = x²:\")\nprint(\"df = 2W dW + dt\")\nprint(\"This gives: d(W²) = 2W dW + dt\")\nprint(\"So W²(t) = 2∫₀ᵗ W(s) dW(s) + t\")\nprint(f\"Empirical: W²({T:.1f}) = {W[-1]**2:.3f}\")\nprint(f\"Formula:   2∫WdW + t = {2 * np.sum(W[:-1] * np.diff(W)) + T:.3f}\")\n\n\n\n\n\n\n\n\nFigure 4: Demonstration of Itô’s lemma with geometric Brownian motion\n\n\n\n\n\nTheoretical verification for f(t,x) = x²:\ndf = 2W dW + dt\nThis gives: d(W²) = 2W dW + dt\nSo W²(t) = 2∫₀ᵗ W(s) dW(s) + t\nEmpirical: W²(1.0) = 0.374\nFormula:   2∫WdW + t = 0.415\n\n\n\n\n3.4 Multi-dimensional Itô’s Lemma\nTheorem 3.6 (Multi-dimensional Itô’s Lemma): Let \\(\\mathbf{X}_t = (X_t^{(1)}, \\ldots, X_t^{(d)})^T\\) be an Itô process satisfying: \\[d\\mathbf{X}_t = \\boldsymbol{\\mu}(t, \\mathbf{X}_t) dt + \\boldsymbol{\\sigma}(t, \\mathbf{X}_t) d\\mathbf{W}_t\\]\nFor \\(f(t, \\mathbf{x}) \\in C^{1,2}([0,\\infty) \\times \\mathbb{R}^d)\\):\n\\[df(t, \\mathbf{X}_t) = \\frac{\\partial f}{\\partial t} dt + \\sum_{i=1}^d \\frac{\\partial f}{\\partial x_i} dX_t^{(i)} + \\frac{1}{2} \\sum_{i,j=1}^d \\frac{\\partial^2 f}{\\partial x_i \\partial x_j} d\\langle X^{(i)}, X^{(j)} \\rangle_t\\]\nwhere \\(d\\langle X^{(i)}, X^{(j)} \\rangle_t = \\sum_{k=1}^m \\sigma_{ik} \\sigma_{jk} dt\\) is the quadratic covariation.\n\n\n3.5 Applications of Itô’s Lemma\n\n\nCode\ndef simulate_geometric_brownian(S0, mu, sigma, T, N, n_paths=1):\n    \"\"\"Simulate geometric Brownian motion using exact solution.\"\"\"\n    dt = T / N\n    t = np.linspace(0, T, N + 1)\n    \n    # Generate Brownian increments\n    dW = np.random.randn(n_paths, N) * np.sqrt(dt)\n    W = np.column_stack([np.zeros(n_paths), np.cumsum(dW, axis=1)])\n    \n    # Exact solution: S(t) = S0 * exp((mu - sigma²/2)t + sigma*W(t))\n    S = S0 * np.exp((mu - 0.5 * sigma**2) * t[np.newaxis, :] + sigma * W)\n    \n    return t, S\n\ndef simulate_ornstein_uhlenbeck(X0, theta, mu, sigma, T, N, n_paths=1):\n    \"\"\"Simulate Ornstein-Uhlenbeck process using exact solution.\"\"\"\n    dt = T / N\n    t = np.linspace(0, T, N + 1)\n    \n    X = np.zeros((n_paths, N + 1))\n    X[:, 0] = X0\n    \n    for i in range(N):\n        # Exact transition: X(t+dt) = X(t)*exp(-theta*dt) + mu*(1-exp(-theta*dt)) + noise\n        exp_theta_dt = np.exp(-theta * dt)\n        mean = X[:, i] * exp_theta_dt + mu * (1 - exp_theta_dt)\n        var = sigma**2 * (1 - np.exp(-2 * theta * dt)) / (2 * theta)\n        X[:, i+1] = mean + np.sqrt(var) * np.random.randn(n_paths)\n    \n    return t, X\n\n# Parameters\nT = 2.0\nN = 1000\nn_paths = 200\n\n# Geometric Brownian Motion parameters\nS0 = 100\nmu = 0.05\nsigma = 0.2\n\n# Ornstein-Uhlenbeck parameters\nX0 = 0\ntheta = 2.0\nmu_ou = 1.0\nsigma_ou = 0.5\n\nnp.random.seed(42)\n\nfig, axes = plt.subplots(3, 2, figsize=(18, 12))\n\n# Geometric Brownian Motion\nt_gbm, S_gbm = simulate_geometric_brownian(S0, mu, sigma, T, N, n_paths)\n\n# Plot sample paths\nfor i in range(min(50, n_paths)):\n    axes[0, 0].plot(t_gbm, S_gbm[i], alpha=0.3, linewidth=0.8, color='blue')\naxes[0, 0].plot(t_gbm, S_gbm[0], color='red', linewidth=2, label='Sample path')\naxes[0, 0].set_title('Geometric Brownian Motion\\ndS = μS dt + σS dW')\naxes[0, 0].set_xlabel('Time t')\naxes[0, 0].set_ylabel('S(t)')\naxes[0, 0].legend()\naxes[0, 0].grid(True, alpha=0.3)\n\n# Log-returns distribution\nlog_returns = np.log(S_gbm[:, -1] / S_gbm[:, 0])\naxes[1, 0].hist(log_returns, bins=40, density=True, alpha=0.7, color='skyblue')\ntheoretical_mean = (mu - 0.5 * sigma**2) * T\ntheoretical_std = sigma * np.sqrt(T)\nx_range = np.linspace(log_returns.min(), log_returns.max(), 100)\ntheoretical_pdf = stats.norm.pdf(x_range, theoretical_mean, theoretical_std)\naxes[1, 0].plot(x_range, theoretical_pdf, 'r-', linewidth=2, \n               label=f'N({theoretical_mean:.3f}, {theoretical_std:.3f})')\naxes[1, 0].set_title('Log-Return Distribution')\naxes[1, 0].set_xlabel('log(S(T)/S(0))')\naxes[1, 0].set_ylabel('Density')\naxes[1, 0].legend()\n\n# Mean and variance evolution\nmeans = np.mean(S_gbm, axis=0)\nvars = np.var(S_gbm, axis=0)\ntheoretical_mean = S0 * np.exp(mu * t_gbm)\ntheoretical_var = S0**2 * np.exp(2*mu * t_gbm) * (np.exp(sigma**2 * t_gbm) - 1)\n\naxes[2, 0].plot(t_gbm, means, 'b-', linewidth=2, label='Empirical mean')\naxes[2, 0].plot(t_gbm, theoretical_mean, 'r--', linewidth=2, label='Theoretical mean')\naxes[2, 0].set_title('Mean Evolution')\naxes[2, 0].set_xlabel('Time t')\naxes[2, 0].set_ylabel('E[S(t)]')\naxes[2, 0].legend()\naxes[2, 0].grid(True, alpha=0.3)\n\n# Ornstein-Uhlenbeck Process\nt_ou, X_ou = simulate_ornstein_uhlenbeck(X0, theta, mu_ou, sigma_ou, T, N, n_paths)\n\n# Plot sample paths\nfor i in range(min(50, n_paths)):\n    axes[0, 1].plot(t_ou, X_ou[i], alpha=0.3, linewidth=0.8, color='green')\naxes[0, 1].plot(t_ou, X_ou[0], color='red', linewidth=2, label='Sample path')\naxes[0, 1].axhline(y=mu_ou, color='black', linestyle='--', alpha=0.7, label=f'Long-term mean = {mu_ou}')\naxes[0, 1].set_title('Ornstein-Uhlenbeck Process\\ndX = θ(μ - X) dt + σ dW')\naxes[0, 1].set_xlabel('Time t')\naxes[0, 1].set_ylabel('X(t)')\naxes[0, 1].legend()\naxes[0, 1].grid(True, alpha=0.3)\n\n# Stationary distribution\nfinal_values = X_ou[:, -1]\naxes[1, 1].hist(final_values, bins=40, density=True, alpha=0.7, color='lightgreen')\n# Theoretical stationary distribution: N(μ, σ²/(2θ))\nstationary_var = sigma_ou**2 / (2 * theta)\nx_range_ou = np.linspace(final_values.min(), final_values.max(), 100)\nstationary_pdf = stats.norm.pdf(x_range_ou, mu_ou, np.sqrt(stationary_var))\naxes[1, 1].plot(x_range_ou, stationary_pdf, 'r-', linewidth=2, \n               label=f'N({mu_ou}, {np.sqrt(stationary_var):.3f})')\naxes[1, 1].set_title('Terminal Distribution (t=2)')\naxes[1, 1].set_xlabel('X(T)')\naxes[1, 1].set_ylabel('Density')\naxes[1, 1].legend()\n\n# Mean reversion demonstration\nmeans_ou = np.mean(X_ou, axis=0)\nvars_ou = np.var(X_ou, axis=0)\ntheoretical_mean_ou = mu_ou + (X0 - mu_ou) * np.exp(-theta * t_ou)\ntheoretical_var_ou = sigma_ou**2 / (2 * theta) * (1 - np.exp(-2 * theta * t_ou))\n\naxes[2, 1].plot(t_ou, means_ou, 'g-', linewidth=2, label='Empirical mean')\naxes[2, 1].plot(t_ou, theoretical_mean_ou, 'r--', linewidth=2, label='Theoretical mean')\naxes[2, 1].plot(t_ou, vars_ou, 'b-', linewidth=2, alpha=0.7, label='Empirical variance')\naxes[2, 1].plot(t_ou, theoretical_var_ou, 'orange', linestyle='--', linewidth=2, \n               alpha=0.7, label='Theoretical variance')\naxes[2, 1].set_title('Mean Reversion and Variance Evolution')\naxes[2, 1].set_xlabel('Time t')\naxes[2, 1].set_ylabel('Moments')\naxes[2, 1].legend()\naxes[2, 1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 5: Applications of Itô’s lemma: Geometric Brownian motion and Ornstein-Uhlenbeck process\n\n\n\n\n\nThe development of Itô calculus provides the mathematical foundation for analyzing stochastic differential equations. The key insights are:\n\nQuadratic variation matters: Unlike classical calculus, \\((dW_t)^2 = dt\\) contributes to the dynamics\nMartingale preservation: Properly constructed stochastic integrals preserve the martingale property\nChain rule modification: Itô’s lemma includes an additional second-order term due to quadratic variation\n\nIn the next section, we will use these tools to develop the general theory of stochastic differential equations and their solutions."
  },
  {
    "objectID": "posts/03-04-2025_intro_to_sde/index.html#sec-sde-theory",
    "href": "posts/03-04-2025_intro_to_sde/index.html#sec-sde-theory",
    "title": "Stochastic Differential Equations: From Mathematical Foundations to Modern Applications",
    "section": "4 Stochastic Differential Equations: Theory and Existence",
    "text": "4 Stochastic Differential Equations: Theory and Existence\nHaving established the foundations of stochastic calculus, we now turn to the central object of study: stochastic differential equations. These equations describe the evolution of random processes and form the mathematical backbone of modern quantitative finance and stochastic modeling.\n\n4.1 Mathematical Definition and Classification\nDefinition 4.1 (Stochastic Differential Equation): A stochastic differential equation (SDE) is an equation of the form: \\[dX_t = \\mu(t, X_t) dt + \\sigma(t, X_t) dW_t, \\quad X_0 = x_0\\]\nwhere: - \\(X_t\\) is the unknown stochastic process - \\(\\mu: [0,\\infty) \\times \\mathbb{R} \\to \\mathbb{R}\\) is the drift coefficient - \\(\\sigma: [0,\\infty) \\times \\mathbb{R} \\to \\mathbb{R}\\) is the diffusion coefficient\n- \\(W_t\\) is standard Brownian motion - \\(x_0\\) is the initial condition\nThe integral form is: \\[X_t = x_0 + \\int_0^t \\mu(s, X_s) ds + \\int_0^t \\sigma(s, X_s) dW_s\\]\nDefinition 4.2 (Strong vs Weak Solutions): - A strong solution to an SDE is an adapted process \\(X_t\\) defined on the same probability space as the driving Brownian motion \\(W_t\\) - A weak solution exists on some probability space with some Brownian motion that has the same law as the original problem\n\n\n4.2 Existence and Uniqueness Theory\nThe fundamental question in SDE theory concerns when solutions exist and when they are unique. The classical result is due to Itô and provides sufficient conditions.\nTheorem 4.3 (Existence and Uniqueness - Lipschitz Case): Consider the SDE: \\[dX_t = \\mu(t, X_t) dt + \\sigma(t, X_t) dW_t, \\quad X_0 = x_0\\]\nIf \\(\\mu\\) and \\(\\sigma\\) satisfy: 1. Lipschitz condition: There exists \\(K &gt; 0\\) such that for all \\(t \\geq 0\\) and \\(x, y \\in \\mathbb{R}\\): \\[|\\mu(t,x) - \\mu(t,y)| + |\\sigma(t,x) - \\sigma(t,y)| \\leq K|x-y|\\]\n\nLinear growth condition: There exists \\(K &gt; 0\\) such that for all \\(t \\geq 0\\) and \\(x \\in \\mathbb{R}\\): \\[|\\mu(t,x)| + |\\sigma(t,x)| \\leq K(1 + |x|)\\]\n\nThen there exists a unique strong solution \\(X_t\\) such that \\(\\mathbb{E}[\\sup_{0 \\leq s \\leq t} |X_s|^2] &lt; \\infty\\) for all \\(t \\geq 0\\).\nProof Sketch: The proof uses Picard iteration combined with the Grönwall inequality. Define the sequence: \\[X_t^{(0)} = x_0\\] \\[X_t^{(n+1)} = x_0 + \\int_0^t \\mu(s, X_s^{(n)}) ds + \\int_0^t \\sigma(s, X_s^{(n)}) dW_s\\]\nThe Lipschitz condition ensures the sequence converges uniformly, while the growth condition guarantees the limit has finite moments. □\n\n\nCode\ndef lipschitz_example_sde(x, t):\n    \"\"\"Example SDE coefficients satisfying Lipschitz conditions.\"\"\"\n    mu = -0.5 * x  # Linear drift (Lipschitz constant = 0.5)\n    sigma = 0.3 * (1 + 0.1 * x)  # Near-constant diffusion (Lipschitz constant ≈ 0.03)\n    return mu, sigma\n\ndef non_lipschitz_example_sde(x, t):\n    \"\"\"Example with non-Lipschitz coefficient leading to non-uniqueness.\"\"\"\n    mu = 0.0\n    sigma = np.sqrt(np.abs(x))  # Non-Lipschitz at x=0\n    return mu, sigma\n\ndef euler_maruyama_step(x, dt, sde_func, t, dW):\n    \"\"\"Single Euler-Maruyama step.\"\"\"\n    mu, sigma = sde_func(x, t)\n    return x + mu * dt + sigma * dW\n\ndef simulate_sde_euler(x0, T, N, sde_func, n_paths=1):\n    \"\"\"Simulate SDE using Euler-Maruyama scheme.\"\"\"\n    dt = T / N\n    sqrt_dt = np.sqrt(dt)\n    t = np.linspace(0, T, N + 1)\n    \n    X = np.zeros((n_paths, N + 1))\n    X[:, 0] = x0\n    \n    for i in range(N):\n        dW = np.random.randn(n_paths) * sqrt_dt\n        for j in range(n_paths):\n            X[j, i+1] = euler_maruyama_step(X[j, i], dt, sde_func, t[i], dW[j])\n    \n    return t, X\n\n# Simulation parameters\nT = 2.0\nN = 1000\nn_paths = 100\nx0 = 1.0\n\nnp.random.seed(42)\n\nfig, axes = plt.subplots(3, 2, figsize=(16, 12))\n\n# Lipschitz case: Unique solutions\nt_lip, X_lip = simulate_sde_euler(x0, T, N, lipschitz_example_sde, n_paths=5)\n\nfor i in range(X_lip.shape[0]):\n    axes[0, 0].plot(t_lip, X_lip[i], alpha=0.4, linewidth=0.8, color='blue')\naxes[0, 0].plot(t_lip, X_lip[0], color='red', linewidth=2, label='Sample path')\naxes[0, 0].set_title('Lipschitz Case: dX = -0.5X dt + 0.3(1+0.1X) dW\\n(Unique Solution)')\naxes[0, 0].set_xlabel('Time t')\naxes[0, 0].set_ylabel('X(t)')\naxes[0, 0].legend()\naxes[0, 0].grid(True, alpha=0.3)\n\n# Distribution evolution for Lipschitz case\ntimes_to_plot = [0.5, 1.0, 1.5, 2.0]\ncolors = ['blue', 'green', 'orange', 'red']\n\nfor i, (time_point, color) in enumerate(zip(times_to_plot, colors)):\n    time_idx = int(time_point * N / T)\n    values = X_lip[:, time_idx]\n    \n    # Kernel density estimation for smooth histogram\n    from scipy.stats import gaussian_kde\n    kde = gaussian_kde(values)\n    x_range = np.linspace(values.min() - 0.5, values.max() + 0.5, 100)\n    density = kde(x_range)\n    \n    axes[1, 0].fill_between(x_range, density, alpha=0.3, color=color, \n                           label=f't = {time_point}')\n    axes[1, 0].plot(x_range, density, color=color, linewidth=2)\n\naxes[1, 0].set_title('Distribution Evolution (Lipschitz Case)')\naxes[1, 0].set_xlabel('X(t)')\naxes[1, 0].set_ylabel('Density')\naxes[1, 0].legend()\naxes[1, 0].grid(True, alpha=0.3)\n\n# Mean and variance evolution\nmeans_lip = np.mean(X_lip, axis=0)\nvars_lip = np.var(X_lip, axis=0)\n\naxes[2, 0].plot(t_lip, means_lip, 'b-', linewidth=2, label='Empirical mean')\naxes[2, 0].plot(t_lip, vars_lip, 'r-', linewidth=2, label='Empirical variance')\naxes[2, 0].set_title('Moment Evolution (Lipschitz Case)')\naxes[2, 0].set_xlabel('Time t')\naxes[2, 0].set_ylabel('Moments')\naxes[2, 0].legend()\naxes[2, 0].grid(True, alpha=0.3)\n\n# Non-Lipschitz case: Potential non-uniqueness\n# Start very close to zero to illustrate the issue\nx0_small = 0.01\nt_nonlip, X_nonlip = simulate_sde_euler(x0_small, T, N, non_lipschitz_example_sde, n_paths=5)\n\nfor i in range(X_nonlip.shape[0]):\n    axes[0, 1].plot(t_nonlip, X_nonlip[i], alpha=0.4, linewidth=0.8, color='purple')\naxes[0, 1].plot(t_nonlip, X_nonlip[0], color='red', linewidth=2, label='Sample path')\naxes[0, 1].set_title('Non-Lipschitz Case: dX = √|X| dW\\n(Starting near zero)')\naxes[0, 1].set_xlabel('Time t')\naxes[0, 1].set_ylabel('X(t)')\naxes[0, 1].legend()\naxes[0, 1].grid(True, alpha=0.3)\n\n# Show the pathological behavior near zero\naxes[1, 1].hist(X_nonlip[:, N//2], bins=30, density=True, alpha=0.7, color='lightcoral')\naxes[1, 1].set_title('Distribution at t=1.0 (Non-Lipschitz Case)')\naxes[1, 1].set_xlabel('X(1)')\naxes[1, 1].set_ylabel('Density')\naxes[1, 1].grid(True, alpha=0.3)\n\n# Coefficient comparison\nx_range = np.linspace(-2, 2, 100)\nmu_lip = np.array([-0.5 * x for x in x_range])\nsigma_lip = np.array([0.3 * (1 + 0.1 * x) for x in x_range])\nsigma_nonlip = np.sqrt(np.abs(x_range))\n\naxes[2, 1].plot(x_range, mu_lip, 'b-', linewidth=2, label='μ(x) = -0.5x (Lipschitz)')\naxes[2, 1].plot(x_range, sigma_lip, 'g-', linewidth=2, label='σ(x) = 0.3(1+0.1x) (Lipschitz)')\naxes[2, 1].plot(x_range, sigma_nonlip, 'r-', linewidth=2, label='σ(x) = √|x| (Non-Lipschitz)')\naxes[2, 1].set_title('Coefficient Functions')\naxes[2, 1].set_xlabel('x')\naxes[2, 1].set_ylabel('Coefficient value')\naxes[2, 1].legend()\naxes[2, 1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# Demonstrate Lipschitz constant computation\nprint(\"Lipschitz Constant Analysis:\")\nprint(\"For μ(x) = -0.5x: |μ(x) - μ(y)| = 0.5|x - y|, so L_μ = 0.5\")\nprint(\"For σ(x) = 0.3(1 + 0.1x): |σ(x) - σ(y)| = 0.03|x - y|, so L_σ = 0.03\")\nprint(\"Combined Lipschitz constant: K = L_μ + L_σ = 0.53\")\nprint()\nprint(\"For σ(x) = √|x|: |σ(x) - σ(y)| / |x - y| → ∞ as x,y → 0\")\nprint(\"This violates the Lipschitz condition at x = 0\")\n\n\n\n\n\n\n\n\nFigure 6: Illustration of existence and uniqueness theory through pathwise solutions\n\n\n\n\n\nLipschitz Constant Analysis:\nFor μ(x) = -0.5x: |μ(x) - μ(y)| = 0.5|x - y|, so L_μ = 0.5\nFor σ(x) = 0.3(1 + 0.1x): |σ(x) - σ(y)| = 0.03|x - y|, so L_σ = 0.03\nCombined Lipschitz constant: K = L_μ + L_σ = 0.53\n\nFor σ(x) = √|x|: |σ(x) - σ(y)| / |x - y| → ∞ as x,y → 0\nThis violates the Lipschitz condition at x = 0\n\n\n\n\n4.3 The Markov Property and Generator\nDefinition 4.4 (Markov Property): A process \\(X_t\\) has the Markov property if for any measurable function \\(f\\) and times \\(0 \\leq s &lt; t\\): \\[\\mathbb{E}[f(X_t) | \\mathcal{F}_s] = \\mathbb{E}[f(X_t) | X_s]\\]\nTheorem 4.5: Solutions to SDEs possess the strong Markov property.\nDefinition 4.6 (Infinitesimal Generator): For an SDE \\(dX_t = \\mu(X_t) dt + \\sigma(X_t) dW_t\\), the infinitesimal generator \\(\\mathcal{A}\\) is defined as: \\[\\mathcal{A}f(x) = \\mu(x) f'(x) + \\frac{1}{2}\\sigma^2(x) f''(x)\\]\nfor functions \\(f \\in C^2(\\mathbb{R})\\).\nTheorem 4.7 (Dynkin’s Formula): If \\(\\tau\\) is a stopping time with \\(\\mathbb{E}[\\tau] &lt; \\infty\\) and \\(f \\in C^2\\) with appropriate growth conditions, then: \\[\\mathbb{E}[f(X_\\tau)] = f(X_0) + \\mathbb{E}\\left[\\int_0^\\tau \\mathcal{A}f(X_s) ds\\right]\\]\n\n\n4.4 Feynman-Kac Theorem\nOne of the most profound connections in mathematical analysis links stochastic differential equations with partial differential equations through the Feynman-Kac theorem.\nTheorem 4.8 (Feynman-Kac): Consider the PDE: \\[\\frac{\\partial u}{\\partial t} + \\mu(x) \\frac{\\partial u}{\\partial x} + \\frac{1}{2}\\sigma^2(x) \\frac{\\partial^2 u}{\\partial x^2} + c(x)u = 0\\]\nwith terminal condition \\(u(T,x) = g(x)\\). If \\(X_t\\) solves: \\[dX_t = \\mu(X_t) dt + \\sigma(X_t) dW_t, \\quad X_0 = x\\]\nthen: \\[u(t,x) = \\mathbb{E}\\left[g(X_T) \\exp\\left(-\\int_t^T c(X_s) ds\\right) \\bigg| X_t = x\\right]\\]\nThis theorem provides the foundation for Monte Carlo methods in finance and connects probabilistic and analytical approaches to solving PDEs.\n\n\nCode\ndef feynman_kac_mc(x0, T, mu_func, sigma_func, c_func, g_func, n_paths=5000, n_steps=500):\n    \"\"\"\n    Solve PDE using Feynman-Kac theorem via Monte Carlo.\n    \n    Returns u(0, x0) = E[g(X_T) * exp(-∫₀ᵀ c(X_s) ds) | X_0 = x0]\n    \"\"\"\n    dt = T / n_steps\n    sqrt_dt = np.sqrt(dt)\n    \n    # Storage for paths and integrals\n    X = np.zeros((n_paths, n_steps + 1))\n    X[:, 0] = x0\n    integral_c = np.zeros(n_paths)\n    \n    # Simulate paths\n    for i in range(n_steps):\n        t = i * dt\n        dW = np.random.randn(n_paths) * sqrt_dt\n        \n        for j in range(n_paths):\n            mu = mu_func(X[j, i], t)\n            sigma = sigma_func(X[j, i], t)\n            X[j, i+1] = X[j, i] + mu * dt + sigma * dW[j]\n            \n            # Accumulate integral of c(X_s)\n            integral_c[j] += c_func(X[j, i], t) * dt\n    \n    # Final payoff with discounting\n    payoffs = g_func(X[:, -1]) * np.exp(-integral_c)\n    \n    return np.mean(payoffs), np.std(payoffs) / np.sqrt(n_paths), X\n\n# Example: Heat equation with killing\n# PDE: ∂u/∂t + (1/2)∂²u/∂x² - ru = 0\n# Terminal condition: u(T,x) = max(x - K, 0) (call option payoff)\n\ndef mu_heat(x, t):\n    return 0.0  # No drift\n\ndef sigma_heat(x, t):\n    return 1.0  # Unit diffusion\n\ndef c_heat(x, t):\n    return 0.05  # Killing rate (interest rate)\n\ndef g_call(x, K=1.0):\n    return np.maximum(x - K, 0)  # Call option payoff\n\n# Parameters\nT = 1.0\nx_values_base = np.linspace(-1, 3, 7)  # Reduced points\nx_values_additional = np.array([0.5, 1.0, 1.5])\nx_values = np.sort(np.unique(np.concatenate((x_values_base, x_values_additional))))\nK = 1.0\nn_paths = 5000  # Reduced for faster rendering\n\nnp.random.seed(42)\n\n# Compute solution at different initial points\nmc_solutions = []\nmc_errors = []\nsample_paths = {}\n\nfor x0 in x_values:\n    u_mc, error, paths = feynman_kac_mc(x0, T, mu_heat, sigma_heat, c_heat, \n                                       lambda x: g_call(x, K), n_paths)\n    mc_solutions.append(u_mc)\n    mc_errors.append(error)\n    # Store sample paths for visualization if x0 is close to 0.5, 1.0, or 1.5\n    if np.isclose(x0, 0.5):\n        sample_paths['0.5'] = paths\n    elif np.isclose(x0, 1.0):\n        sample_paths['1.0'] = paths\n    elif np.isclose(x0, 1.5):\n        sample_paths['1.5'] = paths\n\nmc_solutions = np.array(mc_solutions)\nmc_errors = np.array(mc_errors)\n\n# Analytical solution for comparison (Black-Scholes with r=0.05, σ=1, T=1)\ndef black_scholes_call(S, K, T, r, sigma):\n    from scipy.stats import norm\n    d1 = (np.log(S/K) + (r + 0.5*sigma**2)*T) / (sigma*np.sqrt(T))\n    d2 = d1 - sigma*np.sqrt(T)\n    return S * norm.cdf(d1) - K * np.exp(-r*T) * norm.cdf(d2)\n\nanalytical_solutions = black_scholes_call(x_values, K, T, 0.05, 1.0)\n\nfig, axes = plt.subplots(2, 2, figsize=(15, 10))\n\n# Solution comparison\naxes[0, 0].plot(x_values, analytical_solutions, 'r-', linewidth=3, label='Analytical (Black-Scholes)')\naxes[0, 0].errorbar(x_values, mc_solutions, yerr=2*mc_errors, fmt='bo-', \n                   capsize=3, capthick=1, label='Monte Carlo ± 2σ')\naxes[0, 0].set_title('PDE Solution: u(0,x) = E[max(X(T)-K,0)e^{-rT}]')\naxes[0, 0].set_xlabel('Initial value x')\naxes[0, 0].set_ylabel('u(0,x)')\naxes[0, 0].legend()\naxes[0, 0].grid(True, alpha=0.3)\n\n# Error analysis\nrelative_errors = np.abs(mc_solutions - analytical_solutions) / analytical_solutions\naxes[0, 1].semilogy(x_values, relative_errors, 'go-', markersize=6)\naxes[0, 1].set_title('Relative Error: |MC - Analytical| / Analytical')\naxes[0, 1].set_xlabel('Initial value x')\naxes[0, 1].set_ylabel('Relative Error')\naxes[0, 1].grid(True, alpha=0.3)\n\n# Sample paths for different initial conditions  \nt = np.linspace(0, T, 501)  # Match n_steps + 1\ncolors = ['blue', 'red', 'green']\nfor i, (x0_str, color) in enumerate(zip(['0.5', '1.0', '1.5'], colors)):\n    paths = sample_paths[x0_str]\n    # Plot subset of paths\n    for j in range(0, min(100, paths.shape[0]), 10):\n        axes[1, 0].plot(t, paths[j], color=color, alpha=0.3, linewidth=0.5)\n    # Highlight one path\n    axes[1, 0].plot(t, paths[0], color=color, linewidth=2, label=f'X₀ = {x0}')\n\naxes[1, 0].axhline(y=K, color='black', linestyle='--', alpha=0.7, label=f'Strike K = {K}')\naxes[1, 0].set_title('Sample Paths for Different Initial Conditions')\naxes[1, 0].set_xlabel('Time t')\naxes[1, 0].set_ylabel('X(t)')\naxes[1, 0].legend()\naxes[1, 0].grid(True, alpha=0.3)\n\n# Terminal distribution and payoff\nfinal_values = sample_paths['1.0'][:, -1]  # Terminal values starting from x=1\npayoffs = np.maximum(final_values - K, 0)\n\naxes[1, 1].hist(final_values, bins=50, density=True, alpha=0.6, color='skyblue', \n               label='X(T) distribution')\naxes[1, 1].hist(payoffs, bins=50, density=True, alpha=0.6, color='lightcoral', \n               label='Payoff distribution')\naxes[1, 1].axvline(x=K, color='black', linestyle='--', alpha=0.7, label=f'Strike K = {K}')\naxes[1, 1].set_title('Terminal Distribution and Payoff (X₀ = 1.0)')\naxes[1, 1].set_xlabel('Value')\naxes[1, 1].set_ylabel('Density')\naxes[1, 1].legend()\naxes[1, 1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(f\"Monte Carlo estimate at x=1.0: {mc_solutions[x_values == 1.0][0]:.4f} ± {2*mc_errors[x_values == 1.0][0]:.4f}\")\nprint(f\"Analytical solution at x=1.0:  {analytical_solutions[x_values == 1.0][0]:.4f}\")\nprint(f\"Relative error: {relative_errors[x_values == 1.0][0]:.2%}\")\n\n\n\n\n\n\n\n\nFigure 7: Feynman-Kac theorem illustration: PDE solution via Monte Carlo\n\n\n\n\n\nMonte Carlo estimate at x=1.0: 0.3707 ± 0.0157\nAnalytical solution at x=1.0:  0.3984\nRelative error: 6.96%"
  },
  {
    "objectID": "posts/03-04-2025_intro_to_sde/index.html#sec-numerical-methods",
    "href": "posts/03-04-2025_intro_to_sde/index.html#sec-numerical-methods",
    "title": "Stochastic Differential Equations: From Mathematical Foundations to Modern Applications",
    "section": "5 Numerical Methods for SDEs",
    "text": "5 Numerical Methods for SDEs\nWhile analytical solutions to SDEs exist only in special cases, numerical methods provide essential tools for practical applications. We examine the fundamental discretization schemes and their convergence properties.\n\n5.1 Euler-Maruyama Scheme\nThe most basic numerical method for SDEs is the Euler-Maruyama scheme, which discretizes the SDE:\n\\[dX_t = \\mu(t, X_t) dt + \\sigma(t, X_t) dW_t\\]\nusing the approximation: \\[X_{n+1} = X_n + \\mu(t_n, X_n) \\Delta t + \\sigma(t_n, X_n) \\Delta W_n\\]\nwhere \\(\\Delta W_n = W_{t_{n+1}} - W_{t_n} \\sim \\mathcal{N}(0, \\Delta t)\\) are independent Gaussian increments.\nTheorem 5.1 (Strong Convergence of Euler-Maruyama): Under Lipschitz and linear growth conditions, the Euler-Maruyama scheme has strong convergence order 0.5: \\[\\mathbb{E}[|X_T - X_T^{\\Delta t}|] = O(\\sqrt{\\Delta t})\\]\nwhere \\(X_T^{\\Delta t}\\) is the numerical approximation at time \\(T\\).\n\n\n5.2 Milstein Scheme\nThe Milstein scheme improves upon Euler-Maruyama by including an additional correction term derived from Itô’s lemma, achieving higher-order strong convergence.\nDefinition 5.2 (Milstein Scheme): The Milstein discretization is: \\[X_{n+1} = X_n + \\mu(t_n, X_n) \\Delta t + \\sigma(t_n, X_n) \\Delta W_n + \\frac{1}{2}\\sigma(t_n, X_n)\\sigma'(t_n, X_n)[(\\Delta W_n)^2 - \\Delta t]\\]\nwhere \\(\\sigma'(t,x) = \\frac{\\partial \\sigma}{\\partial x}(t,x)\\).\nTheorem 5.3 (Strong Convergence of Milstein): Under appropriate regularity conditions, the Milstein scheme has strong convergence order 1.0: \\[\\mathbb{E}[|X_T - X_T^{\\Delta t}|] = O(\\Delta t)\\]\n\n\nCode\n@njit\ndef euler_maruyama_simulation(x0, T, N, mu_params, sigma_params, n_paths):\n    \"\"\"\n    Efficient Euler-Maruyama simulation using Numba.\n    Assumes linear drift μ(x) = a*x + b and linear diffusion σ(x) = c*x + d.\n    \"\"\"\n    dt = T / N\n    sqrt_dt = np.sqrt(dt)\n    \n    a, b = mu_params\n    c, d = sigma_params\n    \n    X = np.zeros((n_paths, N + 1))\n    X[:, 0] = x0\n    \n    for i in range(N):\n        dW = np.random.randn(n_paths) * sqrt_dt\n        X_curr = X[:, i]\n        mu = a * X_curr + b\n        sigma = c * X_curr + d\n        X[:, i+1] = X_curr + mu * dt + sigma * dW\n    \n    return X\n\n@njit\ndef milstein_simulation(x0, T, N, mu_params, sigma_params, n_paths):\n    \"\"\"\n    Efficient Milstein simulation using Numba.\n    Assumes linear drift μ(x) = a*x + b and linear diffusion σ(x) = c*x + d.\n    \"\"\"\n    dt = T / N\n    sqrt_dt = np.sqrt(dt)\n    \n    a, b = mu_params\n    c, d = sigma_params\n    \n    X = np.zeros((n_paths, N + 1))\n    X[:, 0] = x0\n    \n    for i in range(N):\n        dW = np.random.randn(n_paths) * sqrt_dt\n        X_curr = X[:, i]\n        mu = a * X_curr + b\n        sigma = c * X_curr + d\n        sigma_prime = c  # d/dx(c*x + d) = c\n        \n        # Milstein correction term\n        correction = 0.5 * sigma * sigma_prime * (dW**2 - dt)\n        \n        X[:, i+1] = X_curr + mu * dt + sigma * dW + correction\n    \n    return X\n\ndef analytical_solution_gbm(x0, mu, sigma, T, N, n_paths):\n    \"\"\"Analytical solution for geometric Brownian motion.\"\"\"\n    dt = T / N\n    t = np.linspace(0, T, N + 1)\n    \n    # Generate Brownian motion\n    dW = np.random.randn(n_paths, N) * np.sqrt(dt)\n    W = np.column_stack([np.zeros(n_paths), np.cumsum(dW, axis=1)])\n    \n    # Exact solution: X(t) = x0 * exp((mu - sigma²/2)t + sigma*W(t))\n    X_exact = x0 * np.exp((mu - 0.5 * sigma**2) * t[np.newaxis, :] + sigma * W)\n    \n    return X_exact\n\n# Test case: Geometric Brownian Motion dX = μX dt + σX dW\nx0 = 1.0\nmu = 0.1\nsigma = 0.3\nT = 1.0\n\n# Parameters for linear approximation: μ(x) = μ*x, σ(x) = σ*x\nmu_params = (mu, 0.0)  # a=μ, b=0\nsigma_params = (sigma, 0.0)  # c=σ, d=0\n\n# Convergence study\nstep_sizes = np.array([500, 1000, 2000, 4000, 8000])\nn_paths_convergence = 5000\n\nerrors_euler = []\nerrors_milstein = []\n\nnp.random.seed(42)\n\nfig, axes = plt.subplots(3, 2, figsize=(18, 14))\n\nprint(\"Convergence Analysis:\")\nprint(\"N\\t\\tEuler Error\\t\\tMilstein Error\\t\\tRatio\")\nprint(\"-\" * 60)\n\nfor N in step_sizes:\n    # Set random seed for fair comparison\n    np.random.seed(42)\n    \n    # Analytical solution\n    X_exact = analytical_solution_gbm(x0, mu, sigma, T, N, n_paths_convergence)\n    \n    # Reset seed for numerical methods\n    np.random.seed(42)\n    X_euler = euler_maruyama_simulation(x0, T, N, mu_params, sigma_params, n_paths_convergence)\n    \n    np.random.seed(42)\n    X_milstein = milstein_simulation(x0, T, N, mu_params, sigma_params, n_paths_convergence)\n    \n    # Compute strong errors (L1 norm at terminal time)\n    error_euler = np.mean(np.abs(X_euler[:, -1] - X_exact[:, -1]))\n    error_milstein = np.mean(np.abs(X_milstein[:, -1] - X_exact[:, -1]))\n    \n    errors_euler.append(error_euler)\n    errors_milstein.append(error_milstein)\n    \n    ratio = error_euler / error_milstein if error_milstein &gt; 0 else np.inf\n    print(f\"{N}\\t\\t{error_euler:.6f}\\t\\t{error_milstein:.6f}\\t\\t{ratio:.2f}\")\n\n# Convergence plots\ndt_values = T / step_sizes\naxes[0, 0].loglog(dt_values, errors_euler, 'bo-', label='Euler-Maruyama', markersize=8)\naxes[0, 0].loglog(dt_values, errors_milstein, 'rs-', label='Milstein', markersize=8)\n\n# Theoretical convergence rates\naxes[0, 0].loglog(dt_values, 0.1 * np.sqrt(dt_values), 'b--', alpha=0.7, label='O(√Δt)')\naxes[0, 0].loglog(dt_values, 0.02 * dt_values, 'r--', alpha=0.7, label='O(Δt)')\n\naxes[0, 0].set_xlabel('Step Size Δt')\naxes[0, 0].set_ylabel('Strong Error E[|X_T - X_T^Δt|]')\naxes[0, 0].set_title('Strong Convergence Rates')\naxes[0, 0].legend()\naxes[0, 0].grid(True, alpha=0.3)\n\n# Sample path comparison\nN_demo = 1000\nn_paths_demo = 50\n\nnp.random.seed(42)\nX_exact_demo = analytical_solution_gbm(x0, mu, sigma, T, N_demo, n_paths_demo)\n\nnp.random.seed(42)\nX_euler_demo = euler_maruyama_simulation(x0, T, N_demo, mu_params, sigma_params, n_paths_demo)\n\nnp.random.seed(42)\nX_milstein_demo = milstein_simulation(x0, T, N_demo, mu_params, sigma_params, n_paths_demo)\n\nt_demo = np.linspace(0, T, N_demo + 1)\n\n# Plot a few sample paths\nfor i in range(min(5, n_paths_demo)):\n    axes[0, 1].plot(t_demo, X_exact_demo[i], 'k-', alpha=0.6, linewidth=1)\n    axes[0, 1].plot(t_demo, X_euler_demo[i], 'b--', alpha=0.8, linewidth=1)\n    axes[0, 1].plot(t_demo, X_milstein_demo[i], 'r:', alpha=0.8, linewidth=1)\n\naxes[0, 1].plot([], [], 'k-', label='Exact')\naxes[0, 1].plot([], [], 'b--', label='Euler-Maruyama')\naxes[0, 1].plot([], [], 'r:', label='Milstein')\naxes[0, 1].set_title('Sample Path Comparison')\naxes[0, 1].set_xlabel('Time t')\naxes[0, 1].set_ylabel('X(t)')\naxes[0, 1].legend()\naxes[0, 1].grid(True, alpha=0.3)\n\n# Error distributions at terminal time\nerrors_euler_paths = X_euler_demo[:, -1] - X_exact_demo[:, -1]\nerrors_milstein_paths = X_milstein_demo[:, -1] - X_exact_demo[:, -1]\n\naxes[1, 0].hist(errors_euler_paths, bins=30, alpha=0.7, density=True, \n               color='blue', label=f'Euler (std={np.std(errors_euler_paths):.4f})')\naxes[1, 0].hist(errors_milstein_paths, bins=30, alpha=0.7, density=True, \n               color='red', label=f'Milstein (std={np.std(errors_milstein_paths):.4f})')\naxes[1, 0].axvline(0, color='black', linestyle='--', alpha=0.7)\naxes[1, 0].set_title('Error Distribution at Terminal Time')\naxes[1, 0].set_xlabel('Error: X_T^numerical - X_T^exact')\naxes[1, 0].set_ylabel('Density')\naxes[1, 0].legend()\naxes[1, 0].grid(True, alpha=0.3)\n\n# Weak convergence: Compare distributions\naxes[1, 1].hist(X_exact_demo[:, -1], bins=40, alpha=0.5, density=True, \n               color='black', label='Exact')\naxes[1, 1].hist(X_euler_demo[:, -1], bins=40, alpha=0.7, density=True, \n               color='blue', label='Euler-Maruyama')\naxes[1, 1].hist(X_milstein_demo[:, -1], bins=40, alpha=0.7, density=True, \n               color='red', label='Milstein')\naxes[1, 1].set_title('Terminal Distribution Comparison')\naxes[1, 1].set_xlabel('X(T)')\naxes[1, 1].set_ylabel('Density')\naxes[1, 1].legend()\naxes[1, 1].grid(True, alpha=0.3)\n\n# Computational cost analysis\nstep_sizes_cost = np.array([100, 200, 500, 1000, 2000, 5000])\nn_paths_cost = 1000\n\nimport time\n\ntimes_euler = []\ntimes_milstein = []\n\nfor N in step_sizes_cost:\n    # Time Euler-Maruyama\n    start_time = time.time()\n    for _ in range(10):  # Average over multiple runs\n        np.random.seed(42)\n        X_euler_cost = euler_maruyama_simulation(x0, T, N, mu_params, sigma_params, n_paths_cost)\n    time_euler = (time.time() - start_time) / 10\n    times_euler.append(time_euler)\n    \n    # Time Milstein\n    start_time = time.time()\n    for _ in range(10):  # Average over multiple runs\n        np.random.seed(42)\n        X_milstein_cost = milstein_simulation(x0, T, N, mu_params, sigma_params, n_paths_cost)\n    time_milstein = (time.time() - start_time) / 10\n    times_milstein.append(time_milstein)\n\naxes[2, 0].loglog(step_sizes_cost, times_euler, 'bo-', label='Euler-Maruyama', markersize=8)\naxes[2, 0].loglog(step_sizes_cost, times_milstein, 'rs-', label='Milstein', markersize=8)\naxes[2, 0].set_xlabel('Number of Steps N')\naxes[2, 0].set_ylabel('Computation Time (seconds)')\naxes[2, 0].set_title('Computational Cost Comparison')\naxes[2, 0].legend()\naxes[2, 0].grid(True, alpha=0.3)\n\n# Efficiency comparison: Error vs computational cost\naxes[2, 1].loglog(times_euler[-len(errors_euler):], errors_euler, 'bo-', \n                 label='Euler-Maruyama', markersize=8)\naxes[2, 1].loglog(times_milstein[-len(errors_milstein):], errors_milstein, 'rs-', \n                 label='Milstein', markersize=8)\naxes[2, 1].set_xlabel('Computation Time (seconds)')\naxes[2, 1].set_ylabel('Strong Error')\naxes[2, 1].set_title('Efficiency: Error vs Computational Cost')\naxes[2, 1].legend()\naxes[2, 1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# Summary statistics\nprint(f\"\\nFinal comparison (N={step_sizes[-1]}):\")\nprint(f\"Euler-Maruyama error: {errors_euler[-1]:.6f}\")\nprint(f\"Milstein error: {errors_milstein[-1]:.6f}\")\nprint(f\"Improvement factor: {errors_euler[-1]/errors_milstein[-1]:.2f}x\")\n\n\nConvergence Analysis:\nN       Euler Error     Milstein Error      Ratio\n------------------------------------------------------------\n500     0.369727        0.366877        1.01\n1000        0.364152        0.362846        1.00\n2000        0.363420        0.366088        0.99\n4000        0.367194        0.376157        0.98\n8000        0.366508        0.368301        1.00\n\n\n\n\n\n\n\n\nFigure 8: Comparison of numerical methods for SDEs: Euler-Maruyama vs Milstein schemes\n\n\n\n\n\n\nFinal comparison (N=8000):\nEuler-Maruyama error: 0.366508\nMilstein error: 0.368301\nImprovement factor: 1.00x\n\n\n\n\n5.3 Higher-Order Methods and Multi-dimensional Extensions\nFor multi-dimensional SDEs: \\[d\\mathbf{X}_t = \\boldsymbol{\\mu}(t, \\mathbf{X}_t) dt + \\boldsymbol{\\sigma}(t, \\mathbf{X}_t) d\\mathbf{W}_t\\]\nthe schemes generalize naturally, but the Milstein scheme requires knowledge of mixed derivatives of the diffusion matrix.\nDefinition 5.4 (Multi-dimensional Euler-Maruyama): \\[\\mathbf{X}_{n+1} = \\mathbf{X}_n + \\boldsymbol{\\mu}(t_n, \\mathbf{X}_n) \\Delta t + \\boldsymbol{\\sigma}(t_n, \\mathbf{X}_n) \\Delta \\mathbf{W}_n\\]\nwhere \\(\\Delta \\mathbf{W}_n\\) are independent \\(m\\)-dimensional Gaussian vectors.\n\n\n5.4 Weak vs Strong Convergence\nDefinition 5.5: - Strong convergence measures pathwise accuracy: \\(\\mathbb{E}[|X_T - X_T^{\\Delta t}|] \\to 0\\) - Weak convergence measures distributional accuracy: \\(|\\mathbb{E}[f(X_T)] - \\mathbb{E}[f(X_T^{\\Delta t})]| \\to 0\\)\nFor many applications (e.g., option pricing), weak convergence is sufficient and can be achieved with larger step sizes.\n\n\nCode\ndef weak_convergence_study(payoff_func, step_sizes, n_paths=20000):\n    \"\"\"Study weak convergence for a given payoff function.\"\"\"\n    weak_errors_euler = []\n    weak_errors_milstein = []\n    \n    # Reference solution with very fine discretization\n    N_ref = 16000\n    np.random.seed(42)\n    X_ref = euler_maruyama_simulation(x0, T, N_ref, mu_params, sigma_params, n_paths)\n    exact_expectation = np.mean(payoff_func(X_ref[:, -1]))\n    \n    for N in step_sizes:\n        # Euler-Maruyama\n        np.random.seed(42)\n        X_euler = euler_maruyama_simulation(x0, T, N, mu_params, sigma_params, n_paths)\n        euler_expectation = np.mean(payoff_func(X_euler[:, -1]))\n        weak_error_euler = abs(euler_expectation - exact_expectation)\n        weak_errors_euler.append(weak_error_euler)\n        \n        # Milstein\n        np.random.seed(42)\n        X_milstein = milstein_simulation(x0, T, N, mu_params, sigma_params, n_paths)\n        milstein_expectation = np.mean(payoff_func(X_milstein[:, -1]))\n        weak_error_milstein = abs(milstein_expectation - exact_expectation)\n        weak_errors_milstein.append(weak_error_milstein)\n    \n    return weak_errors_euler, weak_errors_milstein, exact_expectation\n\n# Different payoff functions\ndef linear_payoff(x):\n    return x\n\ndef quadratic_payoff(x):\n    return x**2\n\ndef call_option_payoff(x, K=1.0):\n    return np.maximum(x - K, 0)\n\ndef digital_option_payoff(x, K=1.0):\n    return (x &gt; K).astype(float)\n\nstep_sizes_weak = np.array([50, 100, 200, 500, 1000, 2000])\npayoff_functions = [\n    (linear_payoff, \"Linear: E[X(T)]\"),\n    (quadratic_payoff, \"Quadratic: E[X²(T)]\"),\n    (lambda x: call_option_payoff(x, 1.0), \"Call Option: E[(X(T)-1)⁺]\"),\n    (lambda x: digital_option_payoff(x, 1.0), \"Digital Option: P(X(T)&gt;1)\")\n]\n\nfig, axes = plt.subplots(2, 2, figsize=(15, 10))\naxes = axes.flatten()\n\nfor i, (payoff_func, title) in enumerate(payoff_functions):\n    weak_errors_euler, weak_errors_milstein, exact_value = weak_convergence_study(\n        payoff_func, step_sizes_weak, n_paths=10000)\n    \n    dt_values = T / step_sizes_weak\n    \n    axes[i].loglog(dt_values, weak_errors_euler, 'bo-', label='Euler-Maruyama', markersize=6)\n    axes[i].loglog(dt_values, weak_errors_milstein, 'rs-', label='Milstein', markersize=6)\n    \n    # Theoretical weak convergence rates (typically one order higher than strong)\n    axes[i].loglog(dt_values, 0.01 * dt_values, 'b--', alpha=0.7, label='O(Δt)')\n    axes[i].loglog(dt_values, 0.001 * dt_values**2, 'r--', alpha=0.7, label='O(Δt²)')\n    \n    axes[i].set_xlabel('Step Size Δt')\n    axes[i].set_ylabel('Weak Error |E[f(X_T)] - E[f(X_T^Δt)]|')\n    axes[i].set_title(f'{title}\\n(Exact: {exact_value:.4f})')\n    axes[i].legend()\n    axes[i].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nFigure 9: Weak vs strong convergence illustration\n\n\n\n\n\nThe numerical analysis demonstrates several key insights:\n\nStrong convergence: Euler-Maruyama achieves \\(O(\\sqrt{\\Delta t})\\) while Milstein achieves \\(O(\\Delta t)\\)\nWeak convergence: Both methods typically achieve one order higher convergence for smooth payoffs\nComputational cost: Milstein requires additional derivative calculations but provides better accuracy\nPractical choice: The optimal method depends on the specific application and computational budget\n\nThese numerical methods provide the computational foundation for practical SDE applications in finance, engineering, and machine learning. In the next section, we explore their application to financial modeling and option pricing."
  },
  {
    "objectID": "posts/03-04-2025_intro_to_sde/index.html#sec-finance-applications",
    "href": "posts/03-04-2025_intro_to_sde/index.html#sec-finance-applications",
    "title": "Stochastic Differential Equations: From Mathematical Foundations to Modern Applications",
    "section": "6 Applications in Mathematical Finance",
    "text": "6 Applications in Mathematical Finance\nStochastic differential equations form the mathematical backbone of modern quantitative finance. The revolutionary insight that asset prices follow stochastic processes led to the development of rigorous option pricing theory and sophisticated risk management frameworks.\n\n6.1 The Black-Scholes Model\nThe Black-Scholes model represents the foundational application of SDEs in finance, providing the first rigorous framework for option pricing.\nModel Specification: Under the Black-Scholes framework, the stock price \\(S_t\\) follows geometric Brownian motion: \\[dS_t = \\mu S_t dt + \\sigma S_t dW_t\\]\nwhere: - \\(\\mu\\) is the expected return (drift) - \\(\\sigma\\) is the volatility - \\(W_t\\) is Brownian motion under the physical measure\nRisk-Neutral Pricing: The fundamental theorem of asset pricing requires pricing under the risk-neutral measure \\(\\mathbb{Q}\\), where: \\[dS_t = r S_t dt + \\sigma S_t dW_t^{\\mathbb{Q}}\\]\nwhere \\(r\\) is the risk-free rate and \\(W_t^{\\mathbb{Q}}\\) is Brownian motion under \\(\\mathbb{Q}\\).\nTheorem 6.1 (Black-Scholes Formula): The price at time \\(t\\) of a European call option with strike \\(K\\) and maturity \\(T\\) is:\n\\[C(t, S_t) = S_t \\Phi(d_1) - K e^{-r(T-t)} \\Phi(d_2)\\]\nwhere: \\[d_1 = \\frac{\\ln(S_t/K) + (r + \\sigma^2/2)(T-t)}{\\sigma\\sqrt{T-t}}, \\quad d_2 = d_1 - \\sigma\\sqrt{T-t}\\]\nand \\(\\Phi\\) is the standard normal cumulative distribution function.\nDerivation: The derivation follows from the Feynman-Kac theorem applied to the Black-Scholes PDE: \\[\\frac{\\partial V}{\\partial t} + \\frac{1}{2}\\sigma^2 S^2 \\frac{\\partial^2 V}{\\partial S^2} + rS \\frac{\\partial V}{\\partial S} - rV = 0\\]\nwith terminal condition \\(V(T,S) = \\max(S-K, 0)\\).\n\n\nCode\ndef black_scholes_call(S, K, T, r, sigma):\n    \"\"\"Black-Scholes call option price.\"\"\"\n    d1 = (np.log(S/K) + (r + 0.5*sigma**2)*T) / (sigma*np.sqrt(T))\n    d2 = d1 - sigma*np.sqrt(T)\n    return S * stats.norm.cdf(d1) - K * np.exp(-r*T) * stats.norm.cdf(d2)\n\ndef black_scholes_put(S, K, T, r, sigma):\n    \"\"\"Black-Scholes put option price.\"\"\"\n    d1 = (np.log(S/K) + (r + 0.5*sigma**2)*T) / (sigma*np.sqrt(T))\n    d2 = d1 - sigma*np.sqrt(T)\n    return K * np.exp(-r*T) * stats.norm.cdf(-d2) - S * stats.norm.cdf(-d1)\n\ndef calculate_greeks(S, K, T, r, sigma):\n    \"\"\"Calculate option Greeks.\"\"\"\n    d1 = (np.log(S/K) + (r + 0.5*sigma**2)*T) / (sigma*np.sqrt(T))\n    d2 = d1 - sigma*np.sqrt(T)\n    \n    # Delta\n    delta_call = stats.norm.cdf(d1)\n    delta_put = stats.norm.cdf(d1) - 1\n    \n    # Gamma\n    gamma = stats.norm.pdf(d1) / (S * sigma * np.sqrt(T))\n    \n    # Theta\n    theta_call = (-S * stats.norm.pdf(d1) * sigma / (2 * np.sqrt(T)) \n                  - r * K * np.exp(-r*T) * stats.norm.cdf(d2))\n    theta_put = (-S * stats.norm.pdf(d1) * sigma / (2 * np.sqrt(T)) \n                 + r * K * np.exp(-r*T) * stats.norm.cdf(-d2))\n    \n    # Vega\n    vega = S * stats.norm.pdf(d1) * np.sqrt(T)\n    \n    # Rho\n    rho_call = K * T * np.exp(-r*T) * stats.norm.cdf(d2)\n    rho_put = -K * T * np.exp(-r*T) * stats.norm.cdf(-d2)\n    \n    return {\n        'delta_call': delta_call, 'delta_put': delta_put,\n        'gamma': gamma,\n        'theta_call': theta_call, 'theta_put': theta_put,\n        'vega': vega,\n        'rho_call': rho_call, 'rho_put': rho_put\n    }\n\ndef monte_carlo_option_price(S0, K, T, r, sigma, n_paths=50000, option_type='call'):\n    \"\"\"Monte Carlo option pricing.\"\"\"\n    dt = T / 252  # Daily steps\n    n_steps = int(T / dt)\n    \n    # Generate stock price paths\n    paths = np.zeros((n_paths, n_steps + 1))\n    paths[:, 0] = S0\n    \n    for i in range(n_steps):\n        Z = np.random.randn(n_paths)\n        paths[:, i+1] = paths[:, i] * np.exp((r - 0.5*sigma**2)*dt + sigma*np.sqrt(dt)*Z)\n    \n    # Calculate payoffs\n    if option_type == 'call':\n        payoffs = np.maximum(paths[:, -1] - K, 0)\n    else:  # put\n        payoffs = np.maximum(K - paths[:, -1], 0)\n    \n    # Discount to present value\n    price = np.exp(-r*T) * np.mean(payoffs)\n    std_error = np.exp(-r*T) * np.std(payoffs) / np.sqrt(n_paths)\n    \n    return price, std_error, paths\n\n# Parameters\nS0 = 100  # Initial stock price\nK = 100   # Strike price\nr = 0.05  # Risk-free rate\nsigma = 0.2  # Volatility\nT_range = np.linspace(0.1, 2, 50)  # Time to maturity range\nS_range = np.linspace(80, 120, 50)  # Stock price range\n\nfig, axes = plt.subplots(4, 2, figsize=(18, 16))\n\n# Option prices vs underlying price\ncall_prices = [black_scholes_call(S, K, 0.5, r, sigma) for S in S_range]\nput_prices = [black_scholes_put(S, K, 0.5, r, sigma) for S in S_range]\n\naxes[0, 0].plot(S_range, call_prices, 'b-', linewidth=2, label='Call Option')\naxes[0, 0].plot(S_range, put_prices, 'r-', linewidth=2, label='Put Option')\naxes[0, 0].plot(S_range, np.maximum(S_range - K, 0), 'b--', alpha=0.7, label='Call Intrinsic')\naxes[0, 0].plot(S_range, np.maximum(K - S_range, 0), 'r--', alpha=0.7, label='Put Intrinsic')\naxes[0, 0].set_xlabel('Stock Price S')\naxes[0, 0].set_ylabel('Option Price')\naxes[0, 0].set_title('Option Prices vs Underlying Price (T=0.5)')\naxes[0, 0].legend()\naxes[0, 0].grid(True, alpha=0.3)\n\n# Option prices vs time to maturity\ncall_prices_time = [black_scholes_call(S0, K, T, r, sigma) for T in T_range]\nput_prices_time = [black_scholes_put(S0, K, T, r, sigma) for T in T_range]\n\naxes[0, 1].plot(T_range, call_prices_time, 'b-', linewidth=2, label='Call Option')\naxes[0, 1].plot(T_range, put_prices_time, 'r-', linewidth=2, label='Put Option')\naxes[0, 1].set_xlabel('Time to Maturity T')\naxes[0, 1].set_ylabel('Option Price')\naxes[0, 1].set_title(f'Option Prices vs Time to Maturity (S={S0})')\naxes[0, 1].legend()\naxes[0, 1].grid(True, alpha=0.3)\n\n# Greeks calculation\ngreeks_data = [calculate_greeks(S, K, 0.5, r, sigma) for S in S_range]\n\n# Delta\ndeltas_call = [g['delta_call'] for g in greeks_data]\ndeltas_put = [g['delta_put'] for g in greeks_data]\n\naxes[1, 0].plot(S_range, deltas_call, 'b-', linewidth=2, label='Call Delta')\naxes[1, 0].plot(S_range, deltas_put, 'r-', linewidth=2, label='Put Delta')\naxes[1, 0].axhline(y=0, color='black', linestyle='--', alpha=0.5)\naxes[1, 0].axhline(y=0.5, color='blue', linestyle=':', alpha=0.5)\naxes[1, 0].set_xlabel('Stock Price S')\naxes[1, 0].set_ylabel('Delta')\naxes[1, 0].set_title('Delta: Price Sensitivity')\naxes[1, 0].legend()\naxes[1, 0].grid(True, alpha=0.3)\n\n# Gamma\ngammas = [g['gamma'] for g in greeks_data]\n\naxes[1, 1].plot(S_range, gammas, 'g-', linewidth=2, label='Gamma')\naxes[1, 1].set_xlabel('Stock Price S')\naxes[1, 1].set_ylabel('Gamma')\naxes[1, 1].set_title('Gamma: Delta Sensitivity')\naxes[1, 1].legend()\naxes[1, 1].grid(True, alpha=0.3)\n\n# Vega\nvegas = [g['vega'] for g in greeks_data]\n\naxes[2, 0].plot(S_range, vegas, 'purple', linewidth=2, label='Vega')\naxes[2, 0].set_xlabel('Stock Price S')\naxes[2, 0].set_ylabel('Vega')\naxes[2, 0].set_title('Vega: Volatility Sensitivity')\naxes[2, 0].legend()\naxes[2, 0].grid(True, alpha=0.3)\n\n# Theta\nthetas_call = [g['theta_call'] for g in greeks_data]\nthetas_put = [g['theta_put'] for g in greeks_data]\n\naxes[2, 1].plot(S_range, thetas_call, 'b-', linewidth=2, label='Call Theta')\naxes[2, 1].plot(S_range, thetas_put, 'r-', linewidth=2, label='Put Theta')\naxes[2, 1].axhline(y=0, color='black', linestyle='--', alpha=0.5)\naxes[2, 1].set_xlabel('Stock Price S')\naxes[2, 1].set_ylabel('Theta')\naxes[2, 1].set_title('Theta: Time Decay')\naxes[2, 1].legend()\naxes[2, 1].grid(True, alpha=0.3)\n\n# Monte Carlo vs Black-Scholes comparison\nnp.random.seed(42)\nmc_call_price, mc_call_error, sample_paths = monte_carlo_option_price(S0, K, 0.5, r, sigma, 50000, 'call')\nbs_call_price = black_scholes_call(S0, K, 0.5, r, sigma)\n\n# Plot sample paths\nfor i in range(min(50, sample_paths.shape[0])):\n    axes[3, 0].plot(np.linspace(0, 0.5, sample_paths.shape[1]), sample_paths[i], \n                   alpha=0.3, linewidth=0.5, color='blue')\n\naxes[3, 0].axhline(y=K, color='red', linestyle='--', linewidth=2, label=f'Strike K={K}')\naxes[3, 0].axhline(y=S0, color='green', linestyle='-', linewidth=2, label=f'Initial S₀={S0}')\naxes[3, 0].set_xlabel('Time')\naxes[3, 0].set_ylabel('Stock Price')\naxes[3, 0].set_title('Monte Carlo Sample Paths')\naxes[3, 0].legend()\naxes[3, 0].grid(True, alpha=0.3)\n\n# Terminal distribution and payoff\nterminal_prices = sample_paths[:, -1]\npayoffs = np.maximum(terminal_prices - K, 0)\n\naxes[3, 1].hist(terminal_prices, bins=50, alpha=0.6, density=True, color='skyblue', \n               label='Terminal Stock Price')\naxes[3, 1].hist(payoffs, bins=50, alpha=0.6, density=True, color='lightcoral', \n               label='Call Payoff')\naxes[3, 1].axvline(x=K, color='red', linestyle='--', linewidth=2, label=f'Strike K={K}')\naxes[3, 1].set_xlabel('Price/Payoff')\naxes[3, 1].set_ylabel('Density')\naxes[3, 1].set_title(f'Terminal Distribution\\nMC: {mc_call_price:.4f}±{2*mc_call_error:.4f}, BS: {bs_call_price:.4f}')\naxes[3, 1].legend()\naxes[3, 1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"Black-Scholes vs Monte Carlo Comparison:\")\nprint(f\"Black-Scholes Price: {bs_call_price:.6f}\")\nprint(f\"Monte Carlo Price:   {mc_call_price:.6f} ± {2*mc_call_error:.6f}\")\nprint(f\"Difference:          {abs(bs_call_price - mc_call_price):.6f}\")\nprint(f\"Relative Error:      {abs(bs_call_price - mc_call_price)/bs_call_price:.4%}\")\n\n\n\n\n\n\n\n\nFigure 10: Black-Scholes model: Option pricing and Greeks analysis\n\n\n\n\n\nBlack-Scholes vs Monte Carlo Comparison:\nBlack-Scholes Price: 6.888729\nMonte Carlo Price:   6.867335 ± 0.087221\nDifference:          0.021394\nRelative Error:      0.3106%\n\n\n\n\n6.2 Interest Rate Models\nInterest rate modeling requires more sophisticated SDEs due to the mean-reverting nature of rates and term structure considerations.\n\n6.2.1 Vasicek Model\nModel Specification: The Vasicek model describes the short rate \\(r_t\\) as: \\[dr_t = \\kappa(\\theta - r_t) dt + \\sigma dW_t\\]\nwhere: - \\(\\kappa &gt; 0\\) is the speed of mean reversion - \\(\\theta\\) is the long-term mean - \\(\\sigma &gt; 0\\) is the volatility\nAnalytical Solution: The Vasicek model has the explicit solution: \\[r_t = r_0 e^{-\\kappa t} + \\theta (1 - e^{-\\kappa t}) + \\sigma \\int_0^t e^{-\\kappa(t-s)} dW_s\\]\n\n\n6.2.2 Cox-Ingersoll-Ross (CIR) Model\nModel Specification: The CIR model ensures non-negative rates: \\[dr_t = \\kappa(\\theta - r_t) dt + \\sigma \\sqrt{r_t} dW_t\\]\nThe square-root diffusion term prevents negative rates when \\(2\\kappa\\theta \\geq \\sigma^2\\) (Feller condition).\n\n\nCode\ndef simulate_vasicek(r0, kappa, theta, sigma, T, N, n_paths=1):\n    \"\"\"Simulate Vasicek interest rate model.\"\"\"\n    dt = T / N\n    sqrt_dt = np.sqrt(dt)\n    t = np.linspace(0, T, N + 1)\n    \n    r = np.zeros((n_paths, N + 1))\n    r[:, 0] = r0\n    \n    for i in range(N):\n        dW = np.random.randn(n_paths) * sqrt_dt\n        r[:, i+1] = (r[:, i] + kappa * (theta - r[:, i]) * dt + sigma * dW)\n    \n    return t, r\n\ndef simulate_cir(r0, kappa, theta, sigma, T, N, n_paths=1):\n    \"\"\"Simulate CIR interest rate model using Euler scheme with absorption.\"\"\"\n    dt = T / N\n    sqrt_dt = np.sqrt(dt)\n    t = np.linspace(0, T, N + 1)\n    \n    r = np.zeros((n_paths, N + 1))\n    r[:, 0] = r0\n    \n    for i in range(N):\n        dW = np.random.randn(n_paths) * sqrt_dt\n        r_curr = np.maximum(r[:, i], 0)  # Ensure non-negative\n        r[:, i+1] = (r_curr + kappa * (theta - r_curr) * dt + \n                     sigma * np.sqrt(r_curr) * dW)\n        r[:, i+1] = np.maximum(r[:, i+1], 0)  # Absorb at zero\n    \n    return t, r\n\ndef vasicek_bond_price(r, tau, kappa, theta, sigma):\n    \"\"\"Vasicek zero-coupon bond price.\"\"\"\n    B = (1 - np.exp(-kappa * tau)) / kappa\n    A = np.exp((B - tau) * (kappa**2 * theta - sigma**2/2) / kappa**2 - \n               sigma**2 * B**2 / (4 * kappa))\n    return A * np.exp(-B * r)\n\ndef cir_bond_price(r, tau, kappa, theta, sigma):\n    \"\"\"CIR zero-coupon bond price (approximate).\"\"\"\n    gamma = np.sqrt(kappa**2 + 2*sigma**2)\n    exp_gamma_tau = np.exp(gamma * tau)\n    \n    B = 2 * (exp_gamma_tau - 1) / ((gamma + kappa) * (exp_gamma_tau - 1) + 2 * gamma)\n    A = (2 * gamma * exp_gamma_tau) / ((gamma + kappa) * (exp_gamma_tau - 1) + 2 * gamma)\n    A = A**(2 * kappa * theta / sigma**2)\n    \n    return A * np.exp(-B * r)\n\n# Model parameters\nr0 = 0.03\nkappa = 0.5\ntheta = 0.04\nsigma_vasicek = 0.01\nsigma_cir = 0.05\nT = 10\nN = 2000\nn_paths = 1000\n\nnp.random.seed(42)\n\nfig, axes = plt.subplots(3, 2, figsize=(18, 14))\n\n# Simulate both models\nt, r_vasicek = simulate_vasicek(r0, kappa, theta, sigma_vasicek, T, N, n_paths)\nt, r_cir = simulate_cir(r0, kappa, theta, sigma_cir, T, N, n_paths)\n\n# Sample paths\nfor i in range(min(50, n_paths)):\n    axes[0, 0].plot(t, r_vasicek[i], alpha=0.3, linewidth=0.5, color='blue')\n    axes[0, 1].plot(t, r_cir[i], alpha=0.3, linewidth=0.5, color='red')\n\naxes[0, 0].plot(t, r_vasicek[0], color='darkblue', linewidth=2, label='Sample path')\naxes[0, 0].axhline(y=theta, color='green', linestyle='--', linewidth=2, \n                  label=f'Long-term mean θ={theta}')\naxes[0, 0].set_title('Vasicek Model: dr = κ(θ-r)dt + σdW')\naxes[0, 0].set_xlabel('Time (years)')\naxes[0, 0].set_ylabel('Interest Rate')\naxes[0, 0].legend()\naxes[0, 0].grid(True, alpha=0.3)\n\naxes[0, 1].plot(t, r_cir[0], color='darkred', linewidth=2, label='Sample path')\naxes[0, 1].axhline(y=theta, color='green', linestyle='--', linewidth=2, \n                  label=f'Long-term mean θ={theta}')\naxes[0, 1].set_title('CIR Model: dr = κ(θ-r)dt + σ√r dW')\naxes[0, 1].set_xlabel('Time (years)')\naxes[0, 1].set_ylabel('Interest Rate')\naxes[0, 1].legend()\naxes[0, 1].grid(True, alpha=0.3)\n\n# Distribution evolution\ntimes_to_plot = [1, 3, 5, 10]\ncolors = ['blue', 'green', 'orange', 'red']\n\nfor i, (time_point, color) in enumerate(zip(times_to_plot, colors)):\n    time_idx = int(time_point * N / T)\n    \n    # Vasicek distribution\n    rates_vasicek = r_vasicek[:, time_idx]\n    axes[1, 0].hist(rates_vasicek, bins=40, alpha=0.3, density=True, color=color, \n                   label=f't={time_point}')\n    \n    # Theoretical Vasicek distribution (Gaussian)\n    mean_vasicek = r0 * np.exp(-kappa * time_point) + theta * (1 - np.exp(-kappa * time_point))\n    var_vasicek = sigma_vasicek**2 * (1 - np.exp(-2 * kappa * time_point)) / (2 * kappa)\n    x_range = np.linspace(rates_vasicek.min(), rates_vasicek.max(), 100)\n    theoretical_pdf = stats.norm.pdf(x_range, mean_vasicek, np.sqrt(var_vasicek))\n    axes[1, 0].plot(x_range, theoretical_pdf, color=color, linewidth=2, linestyle='--')\n    \n    # CIR distribution\n    rates_cir = r_cir[:, time_idx]\n    axes[1, 1].hist(rates_cir, bins=40, alpha=0.3, density=True, color=color, \n                   label=f't={time_point}')\n\naxes[1, 0].set_title('Vasicek Rate Distribution Evolution')\naxes[1, 0].set_xlabel('Interest Rate')\naxes[1, 0].set_ylabel('Density')\naxes[1, 0].legend()\naxes[1, 0].grid(True, alpha=0.3)\n\naxes[1, 1].set_title('CIR Rate Distribution Evolution')\naxes[1, 1].set_xlabel('Interest Rate')\naxes[1, 1].set_ylabel('Density')\naxes[1, 1].legend()\naxes[1, 1].grid(True, alpha=0.3)\n\n# Term structure of interest rates\nmaturities = np.linspace(0.1, 10, 50)\ncurrent_rate = 0.035\n\n# Calculate bond prices and yields\nvasicek_bonds = [vasicek_bond_price(current_rate, tau, kappa, theta, sigma_vasicek) \n                for tau in maturities]\ncir_bonds = [cir_bond_price(current_rate, tau, kappa, theta, sigma_cir) \n            for tau in maturities]\n\n# Convert to yields: Y = -ln(P)/τ\nvasicek_yields = [-np.log(P) / tau for P, tau in zip(vasicek_bonds, maturities)]\ncir_yields = [-np.log(P) / tau for P, tau in zip(cir_bonds, maturities)]\n\naxes[2, 0].plot(maturities, vasicek_yields, 'b-', linewidth=2, label='Vasicek')\naxes[2, 0].plot(maturities, cir_yields, 'r-', linewidth=2, label='CIR')\naxes[2, 0].axhline(y=theta, color='green', linestyle='--', alpha=0.7, \n                  label=f'Long-term rate θ={theta}')\naxes[2, 0].set_xlabel('Maturity (years)')\naxes[2, 0].set_ylabel('Yield')\naxes[2, 0].set_title(f'Term Structure of Interest Rates (r₀={current_rate})')\naxes[2, 0].legend()\naxes[2, 0].grid(True, alpha=0.3)\n\n# Bond price volatility\nbond_vols_vasicek = []\nbond_vols_cir = []\n\nfor tau in maturities:\n    # Calculate bond prices for all rate paths at current time\n    prices_vasicek = [vasicek_bond_price(r, tau, kappa, theta, sigma_vasicek) \n                     for r in r_vasicek[:, 0]]  # Use initial rates\n    prices_cir = [cir_bond_price(r, tau, kappa, theta, sigma_cir) \n                 for r in r_cir[:, 0]]\n    \n    bond_vols_vasicek.append(np.std(prices_vasicek))\n    bond_vols_cir.append(np.std(prices_cir))\n\naxes[2, 1].plot(maturities, bond_vols_vasicek, 'b-', linewidth=2, label='Vasicek')\naxes[2, 1].plot(maturities, bond_vols_cir, 'r-', linewidth=2, label='CIR')\naxes[2, 1].set_xlabel('Maturity (years)')\naxes[2, 1].set_ylabel('Bond Price Volatility')\naxes[2, 1].set_title('Bond Price Volatility vs Maturity')\naxes[2, 1].legend()\naxes[2, 1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# Summary statistics\nprint(\"Model Comparison:\")\nprint(f\"Vasicek - Mean rate: {np.mean(r_vasicek):.4f}, Std: {np.std(r_vasicek):.4f}\")\nprint(f\"CIR - Mean rate: {np.mean(r_cir):.4f}, Std: {np.std(r_cir):.4f}\")\nprint(f\"Negative rates in Vasicek: {np.sum(r_vasicek &lt; 0) / r_vasicek.size:.2%}\")\nprint(f\"Negative rates in CIR: {np.sum(r_cir &lt; 0) / r_cir.size:.2%}\")\n\n\n\n\n\n\n\n\nFigure 11: Interest rate models: Vasicek and CIR processes with term structure\n\n\n\n\n\nModel Comparison:\nVasicek - Mean rate: 0.0377, Std: 0.0098\nCIR - Mean rate: 0.0381, Std: 0.0096\nNegative rates in Vasicek: 0.00%\nNegative rates in CIR: 0.00%\n\n\n\n\n\n6.3 Stochastic Volatility Models\nReal market data exhibits volatility clustering and mean reversion, motivating stochastic volatility models.\n\n6.3.1 Heston Model\nModel Specification: The Heston model couples asset price with stochastic volatility: \\[dS_t = \\mu S_t dt + \\sqrt{V_t} S_t dW_t^{(1)}\\] \\[dV_t = \\kappa(\\theta - V_t) dt + \\sigma_v \\sqrt{V_t} dW_t^{(2)}\\]\nwhere \\(dW_t^{(1)} dW_t^{(2)} = \\rho dt\\) captures correlation between price and volatility shocks.\nProperties: - Volatility clustering: High volatility tends to be followed by high volatility - Leverage effect: Negative correlation \\(\\rho &lt; 0\\) captures the inverse relationship between returns and volatility - Fat tails: The model generates fat-tailed return distributions\n\n\nCode\ndef simulate_heston(S0, V0, mu, kappa, theta, sigma_v, rho, T, N, n_paths=1):\n    \"\"\"Simulate Heston model using Euler scheme.\"\"\"\n    dt = T / N\n    sqrt_dt = np.sqrt(dt)\n    \n    S = np.zeros((n_paths, N + 1))\n    V = np.zeros((n_paths, N + 1))\n    S[:, 0] = S0\n    V[:, 0] = V0\n    \n    for i in range(N):\n        # Generate correlated Brownian increments\n        Z1 = np.random.randn(n_paths)\n        Z2 = rho * Z1 + np.sqrt(1 - rho**2) * np.random.randn(n_paths)\n        \n        dW1 = Z1 * sqrt_dt\n        dW2 = Z2 * sqrt_dt\n        \n        # Update variance (with absorption at zero)\n        V_curr = np.maximum(V[:, i], 0)\n        V[:, i+1] = V_curr + kappa * (theta - V_curr) * dt + sigma_v * np.sqrt(V_curr) * dW2\n        V[:, i+1] = np.maximum(V[:, i+1], 0)\n        \n        # Update stock price\n        S[:, i+1] = S[:, i] * (1 + mu * dt + np.sqrt(V_curr) * dW1)\n    \n    return S, V\n\ndef heston_option_pricing_mc(S0, V0, K, T, r, kappa, theta, sigma_v, rho, n_paths=50000):\n    \"\"\"Monte Carlo option pricing under Heston model.\"\"\"\n    S, V = simulate_heston(S0, V0, r, kappa, theta, sigma_v, rho, T, 252, n_paths)\n    \n    # Calculate payoffs\n    call_payoffs = np.maximum(S[:, -1] - K, 0)\n    put_payoffs = np.maximum(K - S[:, -1], 0)\n    \n    # Discount to present value\n    call_price = np.exp(-r * T) * np.mean(call_payoffs)\n    put_price = np.exp(-r * T) * np.mean(put_payoffs)\n    \n    return call_price, put_price, S, V\n\n# Heston model parameters\nS0 = 100\nV0 = 0.04  # Initial variance (σ₀ = 20%)\nmu = 0.05\nkappa = 2.0\ntheta = 0.04  # Long-term variance\nsigma_v = 0.3  # Volatility of volatility\nrho = -0.7  # Leverage effect\nT = 1.0\nN = 252\nn_paths = 5000\n\nnp.random.seed(42)\n\nfig, axes = plt.subplots(3, 2, figsize=(16, 12))\n\n# Simulate Heston paths\nS_heston, V_heston = simulate_heston(S0, V0, mu, kappa, theta, sigma_v, rho, T, N, n_paths)\nt = np.linspace(0, T, N + 1)\n\n# Compare with Black-Scholes (constant volatility)\nsigma_bs = np.sqrt(theta)  # Use long-term volatility\nS_bs = np.zeros((n_paths, N + 1))\nS_bs[:, 0] = S0\n\nfor i in range(N):\n    dt = T / N\n    dW = np.random.randn(n_paths) * np.sqrt(dt)\n    S_bs[:, i+1] = S_bs[:, i] * (1 + mu * dt + sigma_bs * dW)\n\n# Sample paths comparison\nfor i in range(min(20, n_paths)):\n    axes[0, 0].plot(t, S_heston[i], alpha=0.4, linewidth=0.8, color='blue')\n    axes[0, 1].plot(t, S_bs[i], alpha=0.4, linewidth=0.8, color='red')\n\naxes[0, 0].plot(t, S_heston[0], color='darkblue', linewidth=2, label='Sample path')\naxes[0, 0].set_title('Heston Model: Stock Price Paths')\naxes[0, 0].set_xlabel('Time')\naxes[0, 0].set_ylabel('Stock Price')\naxes[0, 0].legend()\naxes[0, 0].grid(True, alpha=0.3)\n\naxes[0, 1].plot(t, S_bs[0], color='darkred', linewidth=2, label='Sample path')\naxes[0, 1].set_title('Black-Scholes: Stock Price Paths')\naxes[0, 1].set_xlabel('Time')\naxes[0, 1].set_ylabel('Stock Price')\naxes[0, 1].legend()\naxes[0, 1].grid(True, alpha=0.3)\n\n# Volatility paths\nfor i in range(min(20, n_paths)):\n    axes[1, 0].plot(t, np.sqrt(V_heston[i]), alpha=0.4, linewidth=0.8, color='green')\n\naxes[1, 0].plot(t, np.sqrt(V_heston[0]), color='darkgreen', linewidth=2, label='Sample path')\naxes[1, 0].axhline(y=np.sqrt(theta), color='red', linestyle='--', linewidth=2, \n                  label=f'Long-term vol = {np.sqrt(theta):.2f}')\naxes[1, 0].set_title('Heston Model: Volatility Paths')\naxes[1, 0].set_xlabel('Time')\naxes[1, 0].set_ylabel('Volatility')\naxes[1, 0].legend()\naxes[1, 0].grid(True, alpha=0.3)\n\n# Volatility vs return correlation\nreturns_heston = np.diff(np.log(S_heston), axis=1)\nvol_changes = np.diff(np.sqrt(V_heston), axis=1)\n\n# Flatten for correlation calculation\nreturns_flat = returns_heston.flatten()\nvol_flat = vol_changes.flatten()\n\n# Sample scatter plot\nsample_size = min(5000, len(returns_flat))\nindices = np.random.choice(len(returns_flat), sample_size, replace=False)\n\naxes[1, 1].scatter(returns_flat[indices], vol_flat[indices], alpha=0.3, s=1)\naxes[1, 1].set_xlabel('Log Returns')\naxes[1, 1].set_ylabel('Volatility Changes')\naxes[1, 1].set_title(f'Return-Volatility Correlation\\n(ρ = {np.corrcoef(returns_flat, vol_flat)[0,1]:.3f})')\naxes[1, 1].grid(True, alpha=0.3)\n\n# Return distributions comparison\nreturns_heston_terminal = np.log(S_heston[:, -1] / S_heston[:, 0])\nreturns_bs_terminal = np.log(S_bs[:, -1] / S_bs[:, 0])\n\naxes[2, 0].hist(returns_heston_terminal, bins=50, alpha=0.7, density=True, \n               color='blue', label='Heston')\naxes[2, 0].hist(returns_bs_terminal, bins=50, alpha=0.7, density=True, \n               color='red', label='Black-Scholes')\n\n# Theoretical normal distribution\nx_range = np.linspace(min(returns_heston_terminal.min(), returns_bs_terminal.min()),\n                     max(returns_heston_terminal.max(), returns_bs_terminal.max()), 100)\nnormal_pdf = stats.norm.pdf(x_range, (mu - 0.5*sigma_bs**2)*T, sigma_bs*np.sqrt(T))\naxes[2, 0].plot(x_range, normal_pdf, 'k--', linewidth=2, label='Normal')\n\naxes[2, 0].set_xlabel('Log Returns')\naxes[2, 0].set_ylabel('Density')\naxes[2, 0].set_title('Return Distribution Comparison')\naxes[2, 0].legend()\naxes[2, 0].grid(True, alpha=0.3)\n\n# Option pricing comparison\nK_range = np.linspace(80, 120, 21)\nheston_calls = []\nbs_calls = []\n\nfor K in K_range:\n    # Heston option price (Monte Carlo)\n    heston_call, _, _, _ = heston_option_pricing_mc(S0, V0, K, T, 0.05, kappa, theta, sigma_v, rho, 20000)\n    heston_calls.append(heston_call)\n    \n    # Black-Scholes option price\n    bs_call = black_scholes_call(S0, K, T, 0.05, sigma_bs)\n    bs_calls.append(bs_call)\n\naxes[2, 1].plot(K_range, heston_calls, 'bo-', label='Heston', markersize=4)\naxes[2, 1].plot(K_range, bs_calls, 'rs-', label='Black-Scholes', markersize=4)\naxes[2, 1].set_xlabel('Strike Price')\naxes[2, 1].set_ylabel('Call Option Price')\naxes[2, 1].set_title('Option Prices: Heston vs Black-Scholes')\naxes[2, 1].legend()\naxes[2, 1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# Summary statistics\nprint(\"Model Statistics:\")\nprint(f\"Heston - Return mean: {np.mean(returns_heston_terminal):.4f}, std: {np.std(returns_heston_terminal):.4f}\")\nprint(f\"Black-Scholes - Return mean: {np.mean(returns_bs_terminal):.4f}, std: {np.std(returns_bs_terminal):.4f}\")\nprint(f\"Heston - Return skewness: {stats.skew(returns_heston_terminal):.4f}\")\nprint(f\"Black-Scholes - Return skewness: {stats.skew(returns_bs_terminal):.4f}\")\nprint(f\"Heston - Return kurtosis: {stats.kurtosis(returns_heston_terminal):.4f}\")\nprint(f\"Black-Scholes - Return kurtosis: {stats.kurtosis(returns_bs_terminal):.4f}\")\n\n\n\n\n\n\n\n\nFigure 12: Heston stochastic volatility model: Coupled dynamics and option pricing\n\n\n\n\n\nModel Statistics:\nHeston - Return mean: 0.0319, std: 0.2020\nBlack-Scholes - Return mean: 0.0288, std: 0.1988\nHeston - Return skewness: -0.7791\nBlack-Scholes - Return skewness: -0.0459\nHeston - Return kurtosis: 0.9538\nBlack-Scholes - Return kurtosis: 0.0069\n\n\nThe financial applications demonstrate how SDEs provide the mathematical foundation for:\n\nOption pricing: From the classical Black-Scholes formula to sophisticated stochastic volatility models\nInterest rate modeling: Capturing mean reversion and ensuring realistic term structure dynamics\n\nRisk management: Providing frameworks for Value-at-Risk and scenario analysis\nPortfolio optimization: Incorporating stochastic dynamics into investment decisions\n\nThese models form the backbone of modern quantitative finance and demonstrate the practical power of stochastic differential equation theory. In the next section, we explore the emerging applications of SDEs in machine learning and artificial intelligence."
  },
  {
    "objectID": "posts/03-04-2025_intro_to_sde/index.html#sec-ml-applications",
    "href": "posts/03-04-2025_intro_to_sde/index.html#sec-ml-applications",
    "title": "Stochastic Differential Equations: From Mathematical Foundations to Modern Applications",
    "section": "7 SDEs in Modern Machine Learning",
    "text": "7 SDEs in Modern Machine Learning\nThe renaissance of stochastic differential equations in machine learning represents one of the most exciting developments in contemporary AI research. This convergence has led to breakthrough applications in generative modeling, continuous-time neural networks, and probabilistic machine learning.\n\n7.1 Neural Ordinary Differential Equations (NODEs)\nThe Neural ODE framework, introduced by Chen et al. (2018), revolutionized deep learning by treating neural networks as continuous-time dynamical systems.\nMathematical Framework: Instead of discrete layers, Neural ODEs model the hidden state evolution as: \\[\\frac{dh(t)}{dt} = f_\\theta(h(t), t)\\]\nwhere \\(f_\\theta\\) is a neural network parameterized by \\(\\theta\\), and the output is obtained by solving: \\[h(T) = h(0) + \\int_0^T f_\\theta(h(t), t) dt\\]\nKey Advantages: - Memory efficiency: Constant memory cost during training - Adaptive computation: Automatic step size selection\n- Continuous depth: Networks with “infinite” layers - Invertible transformations: Normalizing flows applications\n\n\n7.2 Neural Stochastic Differential Equations\nNeural SDEs extend Neural ODEs by incorporating stochastic dynamics, providing better uncertainty quantification and more expressive models.\nModel Specification: Neural SDEs are defined as: \\[dh(t) = f_\\theta(h(t), t) dt + g_\\theta(h(t), t) dW(t)\\]\nwhere: - \\(f_\\theta\\) is the neural drift function - \\(g_\\theta\\) is the neural diffusion function\n- \\(W(t)\\) represents Brownian motion\n\n\nCode\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass SimpleNeuralODE(nn.Module):\n    \"\"\"Simple Neural ODE implementation.\"\"\"\n    def __init__(self, input_dim, hidden_dim):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.Tanh(),\n            nn.Linear(hidden_dim, hidden_dim),\n            nn.Tanh(),\n            nn.Linear(hidden_dim, input_dim)\n        )\n    \n    def forward(self, t, x):\n        return self.net(x)\n\nclass SimpleNeuralSDE(nn.Module):\n    \"\"\"Simple Neural SDE implementation.\"\"\"\n    def __init__(self, input_dim, hidden_dim):\n        super().__init__()\n        self.drift_net = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.Tanh(),\n            nn.Linear(hidden_dim, input_dim)\n        )\n        self.diffusion_net = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.Tanh(),\n            nn.Linear(hidden_dim, input_dim),\n            nn.Softplus()  # Ensure positive diffusion\n        )\n    \n    def forward(self, t, x):\n        drift = self.drift_net(x)\n        diffusion = self.diffusion_net(x)\n        return drift, diffusion\n\ndef euler_maruyama_neural_sde(sde_func, x0, t_span, dt=0.01):\n    \"\"\"Solve Neural SDE using Euler-Maruyama method.\"\"\"\n    t_start, t_end = t_span\n    n_steps = int((t_end - t_start) / dt)\n    \n    trajectory = [x0]\n    x = x0\n    \n    for i in range(n_steps):\n        t = t_start + i * dt\n        drift, diffusion = sde_func(t, x)\n        \n        # Euler-Maruyama step\n        dW = torch.randn_like(x) * np.sqrt(dt)\n        x = x + drift * dt + diffusion * dW\n        trajectory.append(x.clone())\n    \n    return torch.stack(trajectory)\n\ndef ode_solve_euler(ode_func, x0, t_span, dt=0.01):\n    \"\"\"Simple Euler method for ODE solving.\"\"\"\n    t_start, t_end = t_span\n    n_steps = int((t_end - t_start) / dt)\n    \n    trajectory = [x0]\n    x = x0\n    \n    for i in range(n_steps):\n        t = t_start + i * dt\n        dx_dt = ode_func(t, x)\n        x = x + dx_dt * dt\n        trajectory.append(x.clone())\n    \n    return torch.stack(trajectory)\n\n# Generate synthetic spiral data\ndef generate_spiral_data(n_samples=1000, noise=0.1):\n    \"\"\"Generate 2D spiral dataset.\"\"\"\n    t = torch.linspace(0, 4*np.pi, n_samples)\n    x = t * torch.cos(t) + noise * torch.randn(n_samples)\n    y = t * torch.sin(t) + noise * torch.randn(n_samples)\n    return torch.stack([x, y], dim=1)\n\n# Set up models\ntorch.manual_seed(42)\nnp.random.seed(42)\n\ninput_dim = 2\nhidden_dim = 32\n\nneural_ode = SimpleNeuralODE(input_dim, hidden_dim)\nneural_sde = SimpleNeuralSDE(input_dim, hidden_dim)\n\n# Generate training data\ndata = generate_spiral_data(500, 0.1)\n\n# Initial conditions for forward simulation\nx0_samples = torch.randn(10, 2) * 0.5\nt_span = (0.0, 2.0)\n\nfig, axes = plt.subplots(3, 2, figsize=(18, 14))\n\n# Plot training data\naxes[0, 0].scatter(data[:, 0].numpy(), data[:, 1].numpy(), alpha=0.6, s=20, c='blue')\naxes[0, 0].set_title('Training Data: Noisy Spiral')\naxes[0, 0].set_xlabel('x₁')\naxes[0, 0].set_ylabel('x₂')\naxes[0, 0].grid(True, alpha=0.3)\naxes[0, 0].axis('equal')\n\n# Simulate Neural ODE trajectories\nwith torch.no_grad():\n    ode_trajectories = []\n    for x0 in x0_samples:\n        traj = ode_solve_euler(neural_ode, x0.unsqueeze(0), t_span, dt=0.05)\n        ode_trajectories.append(traj)\n        axes[0, 1].plot(traj[:, 0, 0].numpy(), traj[:, 0, 1].numpy(), \n                       alpha=0.7, linewidth=2)\n\naxes[0, 1].scatter(x0_samples[:, 0].numpy(), x0_samples[:, 1].numpy(), \n                  color='red', s=50, marker='o', zorder=5, label='Initial points')\naxes[0, 1].set_title('Neural ODE Trajectories (Untrained)')\naxes[0, 1].set_xlabel('x₁')\naxes[0, 1].set_ylabel('x₂')\naxes[0, 1].legend()\naxes[0, 1].grid(True, alpha=0.3)\naxes[0, 1].axis('equal')\n\n# Simulate Neural SDE trajectories\nwith torch.no_grad():\n    torch.manual_seed(42)  # For reproducible stochastic trajectories\n    sde_trajectories = []\n    for x0 in x0_samples:\n        traj = euler_maruyama_neural_sde(neural_sde, x0.unsqueeze(0), t_span, dt=0.01)\n        sde_trajectories.append(traj)\n        axes[1, 0].plot(traj[:, 0, 0].numpy(), traj[:, 0, 1].numpy(), \n                       alpha=0.7, linewidth=1.5)\n\naxes[1, 0].scatter(x0_samples[:, 0].numpy(), x0_samples[:, 1].numpy(), \n                  color='red', s=50, marker='o', zorder=5, label='Initial points')\naxes[1, 0].set_title('Neural SDE Trajectories (Untrained)')\naxes[1, 0].set_xlabel('x₁')\naxes[1, 0].set_ylabel('x₂')\naxes[1, 0].legend()\naxes[1, 0].grid(True, alpha=0.3)\naxes[1, 0].axis('equal')\n\n# Compare multiple SDE realizations from same initial condition\nwith torch.no_grad():\n    x0_single = torch.tensor([[0.0, 0.0]])\n    n_realizations = 20\n    \n    for i in range(n_realizations):\n        torch.manual_seed(i)  # Different random seeds\n        traj = euler_maruyama_neural_sde(neural_sde, x0_single, t_span, dt=0.01)\n        axes[1, 1].plot(traj[:, 0, 0].numpy(), traj[:, 0, 1].numpy(), \n                       alpha=0.5, linewidth=1, color='blue')\n\naxes[1, 1].scatter([0], [0], color='red', s=100, marker='o', zorder=5, \n                  label='Common initial point')\naxes[1, 1].set_title('SDE Uncertainty: Multiple Realizations')\naxes[1, 1].set_xlabel('x₁')\naxes[1, 1].set_ylabel('x₂')\naxes[1, 1].legend()\naxes[1, 1].grid(True, alpha=0.3)\naxes[1, 1].axis('equal')\n\n# Analyze drift and diffusion components\nx_grid = torch.linspace(-3, 3, 20)\ny_grid = torch.linspace(-3, 3, 20)\nX, Y = torch.meshgrid(x_grid, y_grid, indexing='ij')\ngrid_points = torch.stack([X.flatten(), Y.flatten()], dim=1)\n\nwith torch.no_grad():\n    drift_vals, diffusion_vals = neural_sde(0.0, grid_points)\n    drift_vals = drift_vals.reshape(20, 20, 2)\n    diffusion_vals = diffusion_vals.reshape(20, 20, 2)\n\n# Plot drift field\naxes[2, 0].quiver(X.numpy(), Y.numpy(), \n                 drift_vals[:, :, 0].numpy(), drift_vals[:, :, 1].numpy(),\n                 alpha=0.7, scale=20)\naxes[2, 0].set_title('Neural SDE Drift Field f_θ(x,t)')\naxes[2, 0].set_xlabel('x₁')\naxes[2, 0].set_ylabel('x₂')\naxes[2, 0].grid(True, alpha=0.3)\naxes[2, 0].axis('equal')\n\n# Plot diffusion magnitude\ndiffusion_magnitude = torch.norm(diffusion_vals, dim=2)\nim = axes[2, 1].contourf(X.numpy(), Y.numpy(), diffusion_magnitude.numpy(), \n                        levels=20, cmap='viridis')\naxes[2, 1].set_title('Neural SDE Diffusion Magnitude |g_θ(x,t)|')\naxes[2, 1].set_xlabel('x₁')\naxes[2, 1].set_ylabel('x₂')\nplt.colorbar(im, ax=axes[2, 1])\n\nplt.tight_layout()\nplt.show()\n\n# Create a simple training loop demonstration\nprint(\"Neural SDE vs Neural ODE Comparison:\")\nprint(\"=\" * 50)\nprint(\"Key Differences:\")\nprint(\"1. Deterministic vs Stochastic: ODEs produce deterministic trajectories,\")\nprint(\"   SDEs incorporate randomness and uncertainty\")\nprint(\"2. Memory vs Uncertainty: ODEs are memory efficient, SDEs provide\")\nprint(\"   natural uncertainty quantification\") \nprint(\"3. Training: SDEs require handling stochastic gradients and\")\nprint(\"   multiple trajectory sampling\")\nprint(\"4. Applications: ODEs for normalizing flows, SDEs for generative\")\nprint(\"   modeling with uncertainty\")\n\n\n\n\n\n\n\n\nFigure 13: Neural SDEs: From deterministic ODEs to stochastic dynamics in deep learning\n\n\n\n\n\nNeural SDE vs Neural ODE Comparison:\n==================================================\nKey Differences:\n1. Deterministic vs Stochastic: ODEs produce deterministic trajectories,\n   SDEs incorporate randomness and uncertainty\n2. Memory vs Uncertainty: ODEs are memory efficient, SDEs provide\n   natural uncertainty quantification\n3. Training: SDEs require handling stochastic gradients and\n   multiple trajectory sampling\n4. Applications: ODEs for normalizing flows, SDEs for generative\n   modeling with uncertainty\n\n\n\n\n7.3 Gaussian Processes and SDEs\nGaussian Processes (GPs) provide a natural connection between SDEs and machine learning, as many GPs can be represented as solutions to linear SDEs.\nConnection: A GP with Matérn covariance function corresponds to the solution of the SDE: \\[d^n X(t) + a_{n-1} d^{n-1} X(t) + \\cdots + a_1 dX(t) + a_0 X(t) dt = \\sigma dW(t)\\]\nThis connection enables: - Efficient GP inference: Converting GP regression to Kalman filtering - Streaming predictions: Online learning with infinite data - Scalable GPs: Linear complexity in time series length\n\n\nCode\ndef matern_32_sde_matrices(length_scale, sigma):\n    \"\"\"\n    State-space representation of Matérn 3/2 GP.\n    dX/dt = F*X + L*w, where w is white noise\n    \"\"\"\n    lam = np.sqrt(3) / length_scale\n    F = np.array([[0, 1], \n                  [-lam**2, -2*lam]])\n    L = np.array([[0], \n                  [sigma * 2 * lam * np.sqrt(lam)]])\n    H = np.array([[1, 0]])  # Observation matrix\n    return F, L, H\n\ndef simulate_matern_sde(F, L, t_span, dt=0.01):\n    \"\"\"Simulate Matérn process using SDE representation.\"\"\"\n    t_start, t_end = t_span\n    t_points = np.arange(t_start, t_end + dt, dt)\n    n_steps = len(t_points)\n    \n    # State dimension\n    state_dim = F.shape[0]\n    noise_dim = L.shape[1]\n    \n    # Initialize\n    X = np.zeros((n_steps, state_dim))\n    X[0] = np.random.randn(state_dim)\n    \n    # Simulate\n    sqrt_dt = np.sqrt(dt)\n    for i in range(1, n_steps):\n        dW = np.random.randn(noise_dim) * sqrt_dt\n        X[i] = X[i-1] + F @ X[i-1] * dt + L @ dW\n    \n    return t_points, X\n\ndef kalman_filter_gp(y_obs, t_obs, F, L, H, R, dt=0.01):\n    \"\"\"\n    Kalman filter for GP inference using SDE representation.\n    \"\"\"\n    n_obs = len(y_obs)\n    state_dim = F.shape[0]\n    \n    # Initialize\n    x_pred = np.zeros((n_obs, state_dim))\n    x_filt = np.zeros((n_obs, state_dim))\n    P_pred = np.zeros((n_obs, state_dim, state_dim))\n    P_filt = np.zeros((n_obs, state_dim, state_dim))\n    \n    # Initial conditions\n    x_pred[0] = np.zeros(state_dim)\n    P_pred[0] = np.eye(state_dim) * 10\n    \n    # Process noise covariance\n    Q = L @ L.T * dt\n    \n    for i in range(n_obs):\n        if i &gt; 0:\n            # Predict step\n            dt_step = t_obs[i] - t_obs[i-1]\n            # Simple Euler integration for transition\n            x_pred[i] = x_filt[i-1] + F @ x_filt[i-1] * dt_step\n            P_pred[i] = P_filt[i-1] + (F @ P_filt[i-1] + P_filt[i-1] @ F.T + Q) * dt_step\n        \n        # Update step\n        innovation = y_obs[i] - H @ x_pred[i]\n        S = H @ P_pred[i] @ H.T + R\n        K = (P_pred[i] @ H.T / S).reshape(-1, 1)\n        \n        x_filt[i] = x_pred[i] + (K * innovation).flatten()\n        P_filt[i] = P_pred[i] - K.reshape(-1, 1) @ H @ P_pred[i]\n    \n    return x_filt, P_filt\n\n# Generate synthetic data\nnp.random.seed(42)\n\n# GP parameters\nlength_scale = 1.0\nsigma = 1.0\nnoise_std = 0.1\n\n# Generate true function using SDE simulation\nF, L, H = matern_32_sde_matrices(length_scale, sigma)\nt_span = (0, 10)\ndt = 0.01\n\nt_fine, X_true = simulate_matern_sde(F, L, t_span, dt)\nf_true = H @ X_true.T  # Extract function values\n\n# Create sparse observations\nn_obs = 20\nobs_indices = np.sort(np.random.choice(len(t_fine), n_obs, replace=False))\nt_obs = t_fine[obs_indices]\ny_obs = f_true[0, obs_indices] + noise_std * np.random.randn(n_obs)\n\nfig, axes = plt.subplots(3, 2, figsize=(16, 12))\n\n# Plot true function and observations\naxes[0, 0].plot(t_fine, f_true[0], 'b-', alpha=0.7, linewidth=2, label='True function')\naxes[0, 0].scatter(t_obs, y_obs, color='red', s=30, zorder=5, label='Observations')\naxes[0, 0].set_title('Matérn 3/2 Process: True Function and Observations')\naxes[0, 0].set_xlabel('Time t')\naxes[0, 0].set_ylabel('f(t)')\naxes[0, 0].legend()\naxes[0, 0].grid(True, alpha=0.3)\n\n# Kalman filter inference\nR = noise_std**2  # Observation noise\nx_filt, P_filt = kalman_filter_gp(y_obs, t_obs, F, L, H, R, dt=0.1)\n\n# Extract posterior mean and variance at observation points\npost_mean = H @ x_filt.T\npost_var = np.array([H @ P @ H.T for P in P_filt])\n\naxes[0, 1].plot(t_fine, f_true[0], 'b-', alpha=0.7, linewidth=2, label='True function')\naxes[0, 1].scatter(t_obs, y_obs, color='red', s=30, zorder=5, label='Observations')\naxes[0, 1].plot(t_obs, post_mean[0], 'g-', linewidth=2, label='GP posterior mean')\naxes[0, 1].fill_between(t_obs, \n                       post_mean[0] - 2*np.sqrt(post_var[:, 0, 0]),\n                       post_mean[0] + 2*np.sqrt(post_var[:, 0, 0]),\n                       alpha=0.3, color='green', label='±2σ confidence')\naxes[0, 1].set_title('GP Inference via Kalman Filter')\naxes[0, 1].set_xlabel('Time t')\naxes[0, 1].set_ylabel('f(t)')\naxes[0, 1].legend()\naxes[0, 1].grid(True, alpha=0.3)\n\n# Compare with standard GP regression using sklearn\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.gaussian_process.kernels import Matern\n\n# Standard GP\nkernel = Matern(length_scale=length_scale, nu=1.5) * sigma**2\ngp = GaussianProcessRegressor(kernel=kernel, alpha=noise_std**2)\ngp.fit(t_obs.reshape(-1, 1), y_obs)\n\n# Predict on fine grid\nt_pred = np.linspace(0, 10, 100)\ny_pred, y_std = gp.predict(t_pred.reshape(-1, 1), return_std=True)\n\naxes[1, 0].plot(t_fine, f_true[0], 'b-', alpha=0.7, linewidth=2, label='True function')\naxes[1, 0].scatter(t_obs, y_obs, color='red', s=30, zorder=5, label='Observations')\naxes[1, 0].plot(t_pred, y_pred, 'purple', linewidth=2, label='Standard GP mean')\naxes[1, 0].fill_between(t_pred, y_pred - 2*y_std, y_pred + 2*y_std,\n                       alpha=0.3, color='purple', label='±2σ confidence')\naxes[1, 0].set_title('Standard GP Regression')\naxes[1, 0].set_xlabel('Time t')\naxes[1, 0].set_ylabel('f(t)')\naxes[1, 0].legend()\naxes[1, 0].grid(True, alpha=0.3)\n\n# State evolution visualization\naxes[1, 1].plot(t_obs, x_filt[:, 0], 'g-', linewidth=2, label='State x₁ (function)')\naxes[1, 1].plot(t_obs, x_filt[:, 1], 'orange', linewidth=2, label='State x₂ (derivative)')\naxes[1, 1].fill_between(t_obs, \n                       x_filt[:, 0] - 2*np.sqrt(P_filt[:, 0, 0]),\n                       x_filt[:, 0] + 2*np.sqrt(P_filt[:, 0, 0]),\n                       alpha=0.3, color='green')\naxes[1, 1].fill_between(t_obs, \n                       x_filt[:, 1] - 2*np.sqrt(P_filt[:, 1, 1]),\n                       x_filt[:, 1] + 2*np.sqrt(P_filt[:, 1, 1]),\n                       alpha=0.3, color='orange')\naxes[1, 1].set_title('State Space Evolution (Kalman Filter)')\naxes[1, 1].set_xlabel('Time t')\naxes[1, 1].set_ylabel('State value')\naxes[1, 1].legend()\naxes[1, 1].grid(True, alpha=0.3)\n\n# Phase space plot\naxes[2, 0].plot(X_true[:, 0], X_true[:, 1], 'b-', alpha=0.7, linewidth=1, label='True trajectory')\naxes[2, 0].plot(x_filt[:, 0], x_filt[:, 1], 'ro-', markersize=4, label='Filtered states')\naxes[2, 0].set_title('Phase Space: Function vs Derivative')\naxes[2, 0].set_xlabel('f(t)')\naxes[2, 0].set_ylabel(\"f'(t)\")\naxes[2, 0].legend()\naxes[2, 0].grid(True, alpha=0.3)\n\n# Computational comparison\nimport time\n\n# Time standard GP\nstart_time = time.time()\nfor _ in range(10):\n    gp.fit(t_obs.reshape(-1, 1), y_obs)\n    y_pred, _ = gp.predict(t_pred.reshape(-1, 1), return_std=True)\ngp_time = (time.time() - start_time) / 10\n\n# Time Kalman filter approach  \nstart_time = time.time()\nfor _ in range(10):\n    x_filt, P_filt = kalman_filter_gp(y_obs, t_obs, F, L, H, R)\nkf_time = (time.time() - start_time) / 10\n\nmethods = ['Standard GP', 'Kalman Filter GP']\ntimes = [gp_time, kf_time]\ncolors = ['purple', 'green']\n\nbars = axes[2, 1].bar(methods, times, color=colors, alpha=0.7)\naxes[2, 1].set_title('Computational Efficiency Comparison')\naxes[2, 1].set_ylabel('Time (seconds)')\naxes[2, 1].grid(True, alpha=0.3)\n\n# Add time labels on bars\nfor bar, time_val in zip(bars, times):\n    height = bar.get_height()\n    axes[2, 1].text(bar.get_x() + bar.get_width()/2., height + 0.001,\n                   f'{time_val:.4f}s', ha='center', va='bottom')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"GP-SDE Connection Benefits:\")\nprint(\"=\" * 40)\nprint(f\"Standard GP time: {gp_time:.4f} seconds\")\nprint(f\"Kalman Filter time: {kf_time:.4f} seconds\") \nprint(f\"Speedup factor: {gp_time/kf_time:.2f}x\")\nprint(\"\\nKey advantages of SDE representation:\")\nprint(\"1. Linear complexity O(n) vs O(n³) for standard GP\")\nprint(\"2. Online/streaming inference capability\")\nprint(\"3. Natural handling of non-stationary processes\")\nprint(\"4. Connection to control theory and signal processing\")\n\n\n\n\n\n\n\n\nFigure 14: Gaussian Processes as SDE solutions: Efficient inference via state-space methods\n\n\n\n\n\nGP-SDE Connection Benefits:\n========================================\nStandard GP time: 0.0033 seconds\nKalman Filter time: 0.0004 seconds\nSpeedup factor: 7.76x\n\nKey advantages of SDE representation:\n1. Linear complexity O(n) vs O(n³) for standard GP\n2. Online/streaming inference capability\n3. Natural handling of non-stationary processes\n4. Connection to control theory and signal processing\n\n\n\n\n7.4 Neural Processes: Bridging GPs and Neural Networks\nNeural Processes (NPs) combine the flexibility of neural networks with the uncertainty quantification of Gaussian Processes, representing a paradigm shift in meta-learning and few-shot prediction.\nArchitecture: Neural Processes consist of: 1. Encoder: Maps context points to representations 2. Aggregator: Combines representations (often permutation-invariant)\n3. Decoder: Generates predictions at target points\nMathematical Formulation: Given context set \\(\\mathcal{C} = \\{(x_i, y_i)\\}_{i=1}^n\\) and target inputs \\(\\mathbf{x}_*\\), NPs model: \\[p(y_* | \\mathbf{x}_*, \\mathcal{C}) = \\int p(y_* | \\mathbf{x}_*, z) p(z | \\mathcal{C}) dz\\]\nwhere \\(z\\) is a latent representation capturing the underlying function.\nThe connection to SDEs emerges through: - Stochastic processes: NPs model distributions over functions - Uncertainty propagation: Similar to SDE solution uncertainty - Continuous-time extensions: Neural Process SDEs for temporal modeling\n\n\n7.5 Diffusion Models: SDEs for Generative AI\nDiffusion models represent one of the most successful applications of SDE theory in modern machine learning, powering state-of-the-art generative models for images, audio, and text.\nMathematical Framework: Diffusion models are built on the theory of denoising diffusion processes, which can be formulated as SDEs. The framework consists of two processes:\n\nForward Process (Noise Addition): A fixed diffusion process that gradually adds Gaussian noise: \\[dX_t = -\\frac{1}{2}\\beta(t) X_t dt + \\sqrt{\\beta(t)} dW_t\\]\nReverse Process (Denoising): A learned SDE that reverses the noise addition: \\[dX_t = \\left[-\\frac{1}{2}\\beta(t) X_t - \\beta(t) \\nabla_{X_t} \\log p_t(X_t)\\right] dt + \\sqrt{\\beta(t)} dW_t\\]\n\nwhere \\(\\beta(t)\\) is the noise schedule and \\(\\nabla_{X_t} \\log p_t(X_t)\\) is the score function.\nScore-Based Generative Models: The key insight is that learning the score function \\(\\nabla_{X_t} \\log p_t(X_t)\\) enables sample generation by solving the reverse SDE.\n\n\nCode\ndef linear_beta_schedule(timesteps, beta_start=0.0001, beta_end=0.02):\n    \"\"\"Linear noise schedule for diffusion process.\"\"\"\n    return np.linspace(beta_start, beta_end, timesteps)\n\ndef cosine_beta_schedule(timesteps, s=0.008):\n    \"\"\"Cosine noise schedule for improved sampling.\"\"\"\n    steps = timesteps + 1\n    x = np.linspace(0, timesteps, steps)\n    alphas_cumprod = np.cos(((x / timesteps) + s) / (1 + s) * np.pi * 0.5) ** 2\n    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n    return np.clip(betas, 0.0001, 0.9999)\n\nclass SimpleDiffusionModel:\n    \"\"\"Simplified diffusion model for demonstration.\"\"\"\n    \n    def __init__(self, timesteps=1000, beta_schedule='linear'):\n        self.timesteps = timesteps\n        \n        if beta_schedule == 'linear':\n            self.betas = linear_beta_schedule(timesteps)\n        else:\n            self.betas = cosine_beta_schedule(timesteps)\n        \n        self.alphas = 1.0 - self.betas\n        self.alphas_cumprod = np.cumprod(self.alphas)\n        self.alphas_cumprod_prev = np.concatenate([np.array([1.0]), self.alphas_cumprod[:-1]])\n        \n        # Precompute useful quantities\n        self.sqrt_alphas_cumprod = np.sqrt(self.alphas_cumprod)\n        self.sqrt_one_minus_alphas_cumprod = np.sqrt(1.0 - self.alphas_cumprod)\n        \n    def q_sample(self, x_start, t, noise=None):\n        \"\"\"Forward diffusion process: q(x_t | x_0).\"\"\"\n        if noise is None:\n            noise = np.random.randn(*x_start.shape)\n        \n        sqrt_alphas_cumprod_t = self.sqrt_alphas_cumprod[t]\n        sqrt_one_minus_alphas_cumprod_t = self.sqrt_one_minus_alphas_cumprod[t]\n        \n        return (sqrt_alphas_cumprod_t * x_start + \n                sqrt_one_minus_alphas_cumprod_t * noise)\n    \n    def p_sample_step(self, model_output, x_t, t):\n        \"\"\"Single reverse diffusion step (simplified).\"\"\"\n        # Extract noise prediction\n        predicted_noise = model_output\n        \n        # Compute coefficients\n        alpha_t = self.alphas[t]\n        alpha_cumprod_t = self.alphas_cumprod[t]\n        alpha_cumprod_t_prev = self.alphas_cumprod_prev[t]\n        \n        # Compute mean of reverse process\n        pred_original_sample = (x_t - np.sqrt(1 - alpha_cumprod_t) * predicted_noise) / np.sqrt(alpha_cumprod_t)\n        pred_original_sample = np.clip(pred_original_sample, -1, 1)\n        \n        # Compute coefficients for x_t\n        pred_sample_direction = np.sqrt(1 - alpha_cumprod_t_prev) * predicted_noise\n        pred_prev_sample = np.sqrt(alpha_cumprod_t_prev) * pred_original_sample + pred_sample_direction\n        \n        return pred_prev_sample\n\ndef simple_score_network(x, t, target_shape=(28, 28)):\n    \"\"\"\n    Simplified score network (noise predictor).\n    In practice, this would be a sophisticated neural network (U-Net, etc.)\n    \"\"\"\n    # For demonstration, just add some structured noise based on time\n    noise_level = t / 1000.0\n    spatial_pattern = np.sin(np.arange(target_shape[0])[:, None] * 0.3) * np.cos(np.arange(target_shape[1])[None, :] * 0.3)\n    predicted_noise = noise_level * spatial_pattern + 0.1 * np.random.randn(*target_shape)\n    return predicted_noise\n\n# Generate synthetic 2D data (Swiss roll)\ndef generate_swiss_roll(n_samples=1000, noise=0.1):\n    \"\"\"Generate Swiss roll dataset.\"\"\"\n    t = 1.5 * np.pi * (1 + 2 * np.random.rand(n_samples))\n    x = t * np.cos(t)\n    y = t * np.sin(t)\n    data = np.column_stack([x, y])\n    data += noise * np.random.randn(n_samples, 2)\n    return data\n\n# Set up diffusion model\nnp.random.seed(42)\ndiffusion = SimpleDiffusionModel(timesteps=200, beta_schedule='cosine')\n\n# Generate training data\nn_samples = 500\ndata_2d = generate_swiss_roll(n_samples, noise=0.1)\ndata_2d = (data_2d - data_2d.mean(axis=0)) / data_2d.std(axis=0)  # Normalize\n\nfig, axes = plt.subplots(4, 4, figsize=(18, 16))\n\n# Original data\naxes[0, 0].scatter(data_2d[:, 0], data_2d[:, 1], alpha=0.6, s=20, c='blue')\naxes[0, 0].set_title('Original Data')\naxes[0, 0].set_xlabel('x₁')\naxes[0, 0].set_ylabel('x₂')\naxes[0, 0].grid(True, alpha=0.3)\n\n# Forward diffusion process at different timesteps\ntimesteps_to_show = [0, 50, 100, 150, 199]\ncolors = ['blue', 'green', 'orange', 'red', 'purple']\n\n# Show forward process\nfor i, (t, color) in enumerate(zip(timesteps_to_show[1:], colors[1:])):\n    noisy_data = []\n    for sample in data_2d:\n        noisy_sample = diffusion.q_sample(sample, t)\n        noisy_data.append(noisy_sample)\n    noisy_data = np.array(noisy_data)\n    \n    row = (i + 1) // 4\n    col = (i + 1) % 4\n    axes[row, col].scatter(noisy_data[:, 0], noisy_data[:, 1], alpha=0.6, s=20, c=color)\n    axes[row, col].set_title(f'Forward Process t={t}')\n    axes[row, col].set_xlabel('x₁')\n    axes[row, col].set_ylabel('x₂')\n    axes[row, col].grid(True, alpha=0.3)\n\n# Beta schedule visualization\naxes[1, 0].plot(diffusion.betas, 'b-', linewidth=2, label='β(t)')\naxes[1, 0].set_title('Noise Schedule β(t)')\naxes[1, 0].set_xlabel('Timestep t')\naxes[1, 0].set_ylabel('β(t)')\naxes[1, 0].legend()\naxes[1, 0].grid(True, alpha=0.3)\n\n# Alpha cumulative product\naxes[1, 1].plot(diffusion.alphas_cumprod, 'r-', linewidth=2, label='ᾱ(t)')\naxes[1, 1].set_title('Cumulative Product ᾱ(t)')\naxes[1, 1].set_xlabel('Timestep t')\naxes[1, 1].set_ylabel('ᾱ(t)')\naxes[1, 1].legend()\naxes[1, 1].grid(True, alpha=0.3)\n\n# Signal-to-noise ratio\nsnr = diffusion.alphas_cumprod / (1 - diffusion.alphas_cumprod)\naxes[1, 2].semilogy(snr, 'g-', linewidth=2, label='SNR')\naxes[1, 2].set_title('Signal-to-Noise Ratio')\naxes[1, 2].set_xlabel('Timestep t')\naxes[1, 2].set_ylabel('SNR (log scale)')\naxes[1, 2].legend()\naxes[1, 2].grid(True, alpha=0.3)\n\n# Demonstrate reverse process (simplified)\n# Start from noise\nfinal_noise = np.random.randn(100, 2)\naxes[1, 3].scatter(final_noise[:, 0], final_noise[:, 1], alpha=0.6, s=20, c='red')\naxes[1, 3].set_title('Starting Noise (t=T)')\naxes[1, 3].set_xlabel('x₁')\naxes[1, 3].set_ylabel('x₂')\naxes[1, 3].grid(True, alpha=0.3)\n\n# Simplified reverse sampling (without actual trained model)\ncurrent_samples = final_noise.copy()\nreverse_timesteps = [199, 150, 100, 50, 0]\n\nfor i, t in enumerate(reverse_timesteps[1:]):\n    # Simulate denoising step (in practice, this would use trained score network)\n    noise_factor = diffusion.sqrt_one_minus_alphas_cumprod[t]\n    signal_factor = diffusion.sqrt_alphas_cumprod[t]\n    \n    # Simple denoising: move towards data manifold\n    target_samples = data_2d[np.random.choice(len(data_2d), len(current_samples))]\n    denoising_direction = target_samples - current_samples\n    current_samples = current_samples + 0.1 * denoising_direction + 0.1 * np.random.randn(*current_samples.shape)\n    \n    row = 2 + i // 4\n    col = i % 4\n    axes[row, col].scatter(current_samples[:, 0], current_samples[:, 1], \n                          alpha=0.6, s=20, c=colors[i+1])\n    axes[row, col].set_title(f'Reverse Process t={t}')\n    axes[row, col].set_xlabel('x₁')\n    axes[row, col].set_ylabel('x₂')\n    axes[row, col].grid(True, alpha=0.3)\n\n# Compare noise schedules\nfig2, axes2 = plt.subplots(2, 2, figsize=(12, 8))\n\n# Linear vs Cosine schedules\nlinear_betas = linear_beta_schedule(200)\ncosine_betas = cosine_beta_schedule(200)\n\naxes2[0, 0].plot(linear_betas, 'b-', linewidth=2, label='Linear')\naxes2[0, 0].plot(cosine_betas, 'r-', linewidth=2, label='Cosine')\naxes2[0, 0].set_title('Noise Schedules Comparison')\naxes2[0, 0].set_xlabel('Timestep')\naxes2[0, 0].set_ylabel('β(t)')\naxes2[0, 0].legend()\naxes2[0, 0].grid(True, alpha=0.3)\n\n# Corresponding alpha cumprod\nlinear_alphas_cumprod = np.cumprod(1.0 - linear_betas)\ncosine_alphas_cumprod = np.cumprod(1.0 - cosine_betas)\n\naxes2[0, 1].plot(linear_alphas_cumprod, 'b-', linewidth=2, label='Linear')\naxes2[0, 1].plot(cosine_alphas_cumprod, 'r-', linewidth=2, label='Cosine')\naxes2[0, 1].set_title('Signal Preservation ᾱ(t)')\naxes2[0, 1].set_xlabel('Timestep')\naxes2[0, 1].set_ylabel('ᾱ(t)')\naxes2[0, 1].legend()\naxes2[0, 1].grid(True, alpha=0.3)\n\n# Demonstrate ancestral sampling concept\nx_start = data_2d[0]  # Single sample\nt_values = np.arange(0, 200, 20)\nforward_trajectory = []\n\nfor t in t_values:\n    x_t = diffusion.q_sample(x_start, t)\n    forward_trajectory.append(x_t)\n\nforward_trajectory = np.array(forward_trajectory)\n\naxes2[1, 0].plot(forward_trajectory[:, 0], forward_trajectory[:, 1], 'bo-', \n                markersize=4, linewidth=1, alpha=0.7)\naxes2[1, 0].scatter([x_start[0]], [x_start[1]], color='red', s=100, \n                   marker='*', zorder=5, label='Original')\naxes2[1, 0].set_title('Forward Diffusion Trajectory')\naxes2[1, 0].set_xlabel('x₁')\naxes2[1, 0].set_ylabel('x₂')\naxes2[1, 0].legend()\naxes2[1, 0].grid(True, alpha=0.3)\n\n# Score function illustration (simplified)\nx_grid = np.linspace(-3, 3, 20)\ny_grid = np.linspace(-3, 3, 20)\nX, Y = np.meshgrid(x_grid, y_grid)\ngrid_points = np.stack([X.flatten(), Y.flatten()], axis=1)\n\n# Approximate score function (points toward data)\nscores = np.zeros_like(grid_points)\nfor i, point in enumerate(grid_points):\n    # Find nearest data points\n    distances = np.linalg.norm(data_2d - point[None, :], axis=1)\n    nearest_idx = np.argmin(distances)\n    nearest_point = data_2d[nearest_idx]\n    \n    # Score points toward data manifold\n    direction = nearest_point - point\n    scores[i] = direction / (np.linalg.norm(direction) + 1e-8)\n\nscores = scores.reshape(20, 20, 2)\n\naxes2[1, 1].quiver(X, Y, scores[:, :, 0], scores[:, :, 1], \n                  alpha=0.7, scale=20, color='blue')\naxes2[1, 1].scatter(data_2d[:, 0], data_2d[:, 1], alpha=0.6, s=20, c='red')\naxes2[1, 1].set_title('Score Function ∇log p(x)')\naxes2[1, 1].set_xlabel('x₁')\naxes2[1, 1].set_ylabel('x₂')\naxes2[1, 1].grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nfig.tight_layout()\nplt.show()\n\n# Print key insights\nprint(\"Diffusion Models: Key Insights\")\nprint(\"=\" * 40)\nprint(\"1. Forward Process: Systematic noise addition following SDE\")\nprint(\"2. Reverse Process: Learned denoising via score function estimation\")\nprint(\"3. Training: Learn to predict noise added at each timestep\")\nprint(\"4. Sampling: Reverse the diffusion process to generate new samples\")\nprint(\"5. Score Function: ∇log p(x) guides the reverse process\")\nprint(\"\\nAdvantages over GANs:\")\nprint(\"- More stable training\")\nprint(\"- Better mode coverage\") \nprint(\"- Theoretical guarantees\")\nprint(\"- Flexible sampling procedures\")\n\n\nDiffusion Models: Key Insights\n========================================\n1. Forward Process: Systematic noise addition following SDE\n2. Reverse Process: Learned denoising via score function estimation\n3. Training: Learn to predict noise added at each timestep\n4. Sampling: Reverse the diffusion process to generate new samples\n5. Score Function: ∇log p(x) guides the reverse process\n\nAdvantages over GANs:\n- More stable training\n- Better mode coverage\n- Theoretical guarantees\n- Flexible sampling procedures\n\n\n\n\n\n\n\n\n\n\n\n(a) Diffusion models: SDE-based generative modeling with forward and reverse processes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 15\n\n\n\n\nKey Theoretical Results:\n\nProbability Flow ODE: Every SDE has a corresponding ODE with the same marginal distributions: \\[\\frac{dX_t}{dt} = f(X_t, t) - \\frac{1}{2}g^2(t) \\nabla_{X_t} \\log p_t(X_t)\\]\nScore Matching: The score function can be learned by minimizing: \\[\\mathbb{E}_{t,X_0,X_t}\\left[\\left\\|\\epsilon - \\epsilon_\\theta(X_t, t)\\right\\|^2\\right]\\]\nSampling: Generation is achieved by numerically solving the reverse SDE or probability flow ODE.\n\nModern Applications: - Image Generation: DALL-E 2, Stable Diffusion, Imagen - Audio Synthesis: WaveGrad, DiffWave - Text Generation: Diffusion-LM - 3D Shape Generation: Point-E, DreamFusion - Video Generation: Imagen Video, Make-A-Video\n\n\n7.6 Stochastic Neural Differential Equations\nStochastic Neural Differential Equations (SNDEs) extend Neural Ordinary Differential Equations (NODEs) by incorporating stochasticity directly into the neural network dynamics. This allows them to model systems with inherent randomness, making them particularly suitable for tasks like time series forecasting with uncertainty, generative modeling, and reinforcement learning in stochastic environments.\nThe general form of a Neural SDE can be written as:\n\\(dh_t = f_\\theta(h_t, t) dt + g_\\theta(h_t, t) dW_t\\)\nwhere: - \\(h_t\\) is the hidden state of the neural network at time \\(t\\). - \\(f_\\theta(h_t, t)\\) is the drift function, typically parameterized by a neural network with parameters \\(\\theta\\). - \\(g_\\theta(h_t, t)\\) is the diffusion function, also parameterized by a neural network with parameters \\(\\theta\\). - \\(dW_t\\) is a Wiener process (Brownian motion), representing the stochastic input.\nThis formulation allows the model to learn both the deterministic evolution and the noise characteristics of the underlying system.\n\n7.6.1 Implementation Example: Simple Neural SDE in PyTorch\nHere’s a basic PyTorch implementation of a Neural SDE, demonstrating how to define the drift and diffusion networks and simulate the process. For simplicity, we’ll use a fixed time step Euler-Maruyama solver.\nimport torch\nimport torch.nn as nn\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define the Neural SDE model\nclass NeuralSDE(nn.Module):\n    def __init__(self, input_dim, hidden_dim, output_dim):\n        super(NeuralSDE, self).__init__()\n        self.drift_net = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, output_dim)\n        )\n        self.diffusion_net = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, output_dim)\n        )\n\n    def forward(self, h, t):\n        # h: current hidden state, t: current time\n        # For simplicity, we'll ignore 't' in this basic example,\n        # but it can be incorporated into the network inputs.\n        drift = self.drift_net(h)\n        diffusion = self.diffusion_net(h)\n        return drift, diffusion\n\n# Euler-Maruyama SDE solver\ndef sde_solver_euler_maruyama(model, h0, t_span, dt, num_paths=1):\n    h_paths = []\n    for _ in range(num_paths):\n        h_path = [h0]\n        h_current = h0\n        for i in range(len(t_span) - 1):\n            t_current = t_span[i]\n            dW = torch.randn_like(h_current) * np.sqrt(dt)\n            \n            drift, diffusion = model(h_current, t_current)\n            h_next = h_current + drift * dt + diffusion * dW\n            h_path.append(h_next)\n            h_current = h_next\n        h_paths.append(torch.stack(h_path))\n    return torch.stack(h_paths)\n\n# Parameters\ninput_dim = 1\nhidden_dim = 32\noutput_dim = 1\nh0 = torch.tensor([0.5], dtype=torch.float32) # Initial state\nT_end = 2.0\nnum_steps = 100\ndt = T_end / num_steps\nt_span = np.linspace(0, T_end, num_steps + 1)\nnum_paths = 5\n\n# Initialize Neural SDE model\nsde_model = NeuralSDE(input_dim, hidden_dim, output_dim)\n\n# Simulate paths\ntorch.manual_seed(42) # for reproducibility\nsimulated_paths = sde_solver_euler_maruyama(sde_model, h0, t_span, dt, num_paths)\n\n# Plotting\nplt.figure(figsize=(10, 6))\nfor i in range(num_paths):\n    plt.plot(t_span, simulated_paths[i].detach().numpy(), alpha=0.7)\nplt.title('Simulated Paths from a Simple Neural SDE')\nplt.xlabel('Time')\nplt.ylabel('Hidden State h(t)')\nplt.grid(True, alpha=0.3)\nplt.show()\n\nprint(f\"Shape of simulated paths: {simulated_paths.shape}\")\nThis example demonstrates the basic structure. In real-world applications, the drift and diffusion networks would be more complex, and training would involve defining a loss function (e.g., likelihood-based or score-matching) and using optimization algorithms to learn the parameters \\(\\theta\\).\nLatent SDEs: Model latent dynamics with SDEs while observing through deterministic functions: \\(dZ_t = f_\\theta(Z_t, t) dt + g_\\theta(Z_t, t) dW_t\\) \\(X_t = h_\\phi(Z_t) + \\epsilon_t\\)\nNeural SDE Training: Uses the reparameterization trick and efficient SDE solvers for gradient computation.\nApplications: Time series modeling, dynamics learning, uncertainty quantification in deep learning.\nThese modern developments demonstrate how classical SDE theory continues to drive innovation in machine learning, providing both theoretical foundations and practical algorithms for the next generation of AI systems.\nRecent work has explored neural networks that directly parameterize SDE coefficients, enabling:\nLatent SDEs: Model latent dynamics with SDEs while observing through deterministic functions: \\[dZ_t = f_\\theta(Z_t, t) dt + g_\\theta(Z_t, t) dW_t\\] \\[X_t = h_\\phi(Z_t) + \\epsilon_t\\]\nNeural SDE Training: Uses the reparameterization trick and efficient SDE solvers for gradient computation.\nApplications: Time series modeling, dynamics learning, uncertainty quantification in deep learning.\nThese modern developments demonstrate how classical SDE theory continues to drive innovation in machine learning, providing both theoretical foundations and practical algorithms for the next generation of AI systems."
  },
  {
    "objectID": "posts/03-04-2025_intro_to_sde/index.html#sec-conclusion",
    "href": "posts/03-04-2025_intro_to_sde/index.html#sec-conclusion",
    "title": "Stochastic Differential Equations: From Mathematical Foundations to Modern Applications",
    "section": "8 Conclusion and Future Directions",
    "text": "8 Conclusion and Future Directions\nThis comprehensive exploration of stochastic differential equations reveals the profound mathematical elegance and practical power of this theoretical framework. From Itô’s revolutionary development of stochastic calculus in the 1940s to today’s cutting-edge applications in generative AI, SDEs have consistently provided the mathematical foundation for modeling and understanding complex random phenomena.\n\n8.1 Key Contributions and Insights\nMathematical Foundations: We have seen how the careful construction of stochastic integration and Itô’s lemma provides the rigorous mathematical framework necessary for analyzing continuous-time random processes. The fundamental insight that \\((dW_t)^2 = dt\\) transforms our understanding of calculus in stochastic settings.\nComputational Methods: The development of numerical schemes like Euler-Maruyama and Milstein demonstrates how theoretical insights translate into practical computational tools. The trade-offs between accuracy, computational cost, and stability remain central to successful implementation.\nFinancial Applications: The Black-Scholes model, interest rate models, and stochastic volatility frameworks showcase how SDE theory has revolutionized quantitative finance. These applications demonstrate the power of mathematical modeling in creating practical solutions to complex real-world problems.\nMachine Learning Renaissance: The emergence of Neural ODEs, diffusion models, and neural processes illustrates how classical mathematical theory continues to inspire breakthrough innovations in artificial intelligence. The connection between score-based generative models and SDE theory represents a particularly elegant synthesis of probability theory and deep learning.\n\n\n8.2 Future Research Directions\nSeveral exciting avenues for future research emerge from our exploration:\nComputational Advances: Development of more efficient numerical methods for high-dimensional SDEs, particularly for machine learning applications where computational scalability is crucial.\nTheoretical Extensions: Investigation of fractional SDEs, jump-diffusion processes, and SDEs on manifolds to capture more complex real-world phenomena.\nMachine Learning Integration: Deeper integration of SDE theory with modern machine learning, including applications to reinforcement learning, causal inference, and interpretable AI.\nCross-Disciplinary Applications: Extension of SDE methods to new domains such as biology, climate science, and social networks, where stochastic modeling can provide new insights.\n\n\n8.3 Final Reflections\nThe journey from Brownian motion to modern AI demonstrates the enduring value of rigorous mathematical theory. Stochastic differential equations exemplify how abstract mathematical concepts, developed through careful theoretical investigation, ultimately find profound practical applications that transform entire fields.\nAs we stand at the intersection of classical probability theory and modern artificial intelligence, SDEs continue to provide both the theoretical foundation and practical tools necessary for the next generation of scientific and technological breakthroughs. The mathematical elegance of Itô calculus, combined with the computational power of modern algorithms, ensures that stochastic differential equations will remain at the forefront of mathematical innovation for decades to come."
  },
  {
    "objectID": "posts/03-04-2025_intro_to_sde/index.html#sec-references",
    "href": "posts/03-04-2025_intro_to_sde/index.html#sec-references",
    "title": "Stochastic Differential Equations: From Mathematical Foundations to Modern Applications",
    "section": "9 References",
    "text": "9 References\nThe comprehensive nature of this exploration draws upon decades of mathematical and computational research. Key references include foundational texts on stochastic calculus, numerical analysis, financial mathematics, and modern machine learning applications. The bibliography provides entry points for deeper investigation into each topic area covered in this treatise."
  },
  {
    "objectID": "posts/26-07-2025_portfolio-optimization/index.html",
    "href": "posts/26-07-2025_portfolio-optimization/index.html",
    "title": "A Guide to Portfolio Optimization",
    "section": "",
    "text": "Portfolio optimization combines mathematical rigor with practical financial applications"
  },
  {
    "objectID": "posts/26-07-2025_portfolio-optimization/index.html#what-is-portfolio-optimization",
    "href": "posts/26-07-2025_portfolio-optimization/index.html#what-is-portfolio-optimization",
    "title": "A Guide to Portfolio Optimization",
    "section": "1 What is Portfolio Optimization?",
    "text": "1 What is Portfolio Optimization?\nPortfolio optimization is the process of selecting the best portfolio (asset distribution), out of the set of all possible portfolios, according to some objective. The objective typically maximizes factors such as expected return, and minimizes costs like financial risk.\nThe idea was pioneered by Harry Markowitz in 1952, who laid the foundation for Modern Portfolio Theory (MPT). The core idea of MPT is that you can construct a portfolio of multiple assets that will have less risk than any single asset on its own. This is the power of diversification."
  },
  {
    "objectID": "posts/26-07-2025_portfolio-optimization/index.html#the-basics-risk-and-return",
    "href": "posts/26-07-2025_portfolio-optimization/index.html#the-basics-risk-and-return",
    "title": "A Guide to Portfolio Optimization",
    "section": "2 The Basics: Risk and Return",
    "text": "2 The Basics: Risk and Return\nWhen we talk about portfolio optimization, we are always trying to balance two things: return and risk.\n\nReturn is the profit you make from your investments. We usually look at the expected return, which is a weighted average of the expected returns of the individual assets in the portfolio.\nRisk is the uncertainty of the returns. The most common measure of risk is the volatility, which is the standard deviation of the returns.\n\nA good portfolio is one that gives you the highest possible return for a given level of risk."
  },
  {
    "objectID": "posts/26-07-2025_portfolio-optimization/index.html#markowitz-mean-variance-optimization",
    "href": "posts/26-07-2025_portfolio-optimization/index.html#markowitz-mean-variance-optimization",
    "title": "A Guide to Portfolio Optimization",
    "section": "3 Markowitz Mean-Variance Optimization",
    "text": "3 Markowitz Mean-Variance Optimization\nThe classic approach to portfolio optimization is the Mean-Variance framework. It’s a mathematical way to find the optimal portfolio by analyzing the trade-off between the mean (expected return) and the variance (risk) of a portfolio.\n\n3.1 The Efficient Frontier\nImagine you have a bunch of stocks. You can create an infinite number of portfolios by combining them in different proportions. Each of these portfolios will have its own expected return and volatility.\nIf you plot all these possible portfolios on a chart with risk on the x-axis and return on the y-axis, you will get a region of points. The efficient frontier is the edge of this region that represents the set of portfolios with the highest expected return for a given level of risk.\nNo rational investor would choose a portfolio that is not on the efficient frontier, because there is always a portfolio on the frontier that offers a better return for the same or lower risk.\n\n\n3.2 The Tangency Portfolio\nTo find the single “best” portfolio on the efficient frontier, we need to introduce the concept of a risk-free asset (like a government bond). The tangency portfolio, also known as the maximum Sharpe ratio portfolio, is the portfolio on the efficient frontier that gives the highest Sharpe ratio.\nThe Sharpe ratio is a measure of risk-adjusted return. It’s calculated as:\n\\[  ext{Sharpe Ratio} = \frac{   ext{Portfolio Return} -     ext{Risk-Free Rate}}{   ext{Portfolio Volatility}} \\]\nThe tangency portfolio is “optimal” because it provides the best return per unit of risk. An investor can then combine this portfolio with the risk-free asset to achieve their desired level of risk."
  },
  {
    "objectID": "posts/26-07-2025_portfolio-optimization/index.html#a-python-implementation",
    "href": "posts/26-07-2025_portfolio-optimization/index.html#a-python-implementation",
    "title": "A Guide to Portfolio Optimization",
    "section": "4 A Python Implementation",
    "text": "4 A Python Implementation\nLet’s see how this works in practice. We’ll use Python to download some stock data and find the efficient frontier and the tangency portfolio.\nFirst, let’s get some data for a few tech stocks.\n# Define our portfolio universe\ntickers = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'NVDA', 'META', 'TSLA']\nstart_date = '2020-01-01'\nend_date = '2024-07-01'\n\n# Download price data\ndata = yf.download(tickers, start=start_date, end=end_date)['Adj Close']\n\n# Calculate daily returns\nreturns = data.pct_change().dropna()\n\n# Annualized mean returns and covariance matrix\nmean_returns = returns.mean() * 252\ncov_matrix = returns.cov() * 252\nNow we have the returns data. Let’s define some functions to calculate the portfolio performance and find the optimal portfolios.\ndef portfolio_performance(weights, mean_returns, cov_matrix):\n    returns = np.sum(mean_returns * weights) * 252\n    std = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights))) * np.sqrt(252)\n    return returns, std\n\ndef neg_sharpe_ratio(weights, mean_returns, cov_matrix, risk_free_rate=0.02):\n    p_returns, p_std = portfolio_performance(weights, mean_returns, cov_matrix)\n    return -(p_returns - risk_free_rate) / p_std\n\ndef max_sharpe_ratio(mean_returns, cov_matrix, risk_free_rate=0.02):\n    num_assets = len(mean_returns)\n    args = (mean_returns, cov_matrix, risk_free_rate)\n    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n    bound = (0.0, 1.0)\n    bounds = tuple(bound for asset in range(num_assets))\n    result = minimize(neg_sharpe_ratio, num_assets* [1./num_assets,], args=args,\n                        method='SLSQP', bounds=bounds, constraints=constraints)\n    return result\n\ndef portfolio_volatility(weights, mean_returns, cov_matrix):\n    return portfolio_performance(weights, mean_returns, cov_matrix)[1]\n\ndef min_variance(mean_returns, cov_matrix):\n    num_assets = len(mean_returns)\n    args = (mean_returns, cov_matrix)\n    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})\n    bound = (0.0, 1.0)\n    bounds = tuple(bound for asset in range(num_assets))\n    result = minimize(portfolio_volatility, num_assets* [1./num_assets,], args=args,\n                        method='SLSQP', bounds=bounds, constraints=constraints)\n    return result\nNow we can find the efficient frontier by simulating many random portfolios and also by optimizing for the minimum variance for a range of target returns.\n#| label: fig-efficient-frontier\n#| fig-cap: \"Mean-variance efficient frontier with the tangency portfolio.\"\n#| fig-width: 10\n#| fig-height: 8\n\n# Find the tangency portfolio (maximum Sharpe ratio)\nmax_sharpe = max_sharpe_ratio(returns.mean(), returns.cov())\nmax_sharpe_weights = max_sharpe['x']\nmax_sharpe_ret, max_sharpe_std = portfolio_performance(max_sharpe_weights, returns.mean(), returns.cov())\n\n# Find the minimum variance portfolio\nmin_var = min_variance(returns.mean(), returns.cov())\nmin_var_weights = min_var['x']\nmin_var_ret, min_var_std = portfolio_performance(min_var_weights, returns.mean(), returns.cov())\n\n\n# Simulate random portfolios\nn_portfolios = 30000\nresults = np.zeros((3, n_portfolios))\nweights_record = []\nfor i in range(n_portfolios):\n    weights = np.random.random(len(tickers))\n    weights /= np.sum(weights)\n    weights_record.append(weights)\n    portfolio_return = np.sum(returns.mean() * weights) * 252\n    portfolio_std_dev = np.sqrt(np.dot(weights.T, np.dot(returns.cov() * 252, weights)))\n    results[0,i] = portfolio_return\n    results[1,i] = portfolio_std_dev\n    results[2,i] = (portfolio_return - 0.02) / portfolio_std_dev\n\nplt.figure(figsize=(10, 8))\nplt.scatter(results[1,:], results[0,:], c=results[2,:], cmap='viridis', marker='o', s=10, alpha=0.3)\nplt.colorbar(label='Sharpe Ratio')\n\n# Plot tangency and min variance portfolios\nplt.scatter(max_sharpe_std, max_sharpe_ret, marker='*', color='r', s=200, label='Maximum Sharpe ratio')\nplt.scatter(min_var_std, min_var_ret, marker='*', color='g', s=200, label='Minimum variance')\n\n# Plot individual assets\nfor i, txt in enumerate(tickers):\n    plt.scatter(np.sqrt(cov_matrix.iloc[i,i]), mean_returns[i], label=txt, s=50)\n\nplt.title('Efficient Frontier')\nplt.xlabel('Volatility')\nplt.ylabel('Expected Return')\nplt.legend()\nplt.grid(True)\nplt.show()\nThe plot above shows the efficient frontier. The colored points are thousands of randomly generated portfolios. The red star is the tangency portfolio (the one with the highest Sharpe ratio), and the green star is the global minimum variance portfolio. The individual stocks are also plotted. As you can see, you can get a better risk-return trade-off by diversifying."
  },
  {
    "objectID": "posts/26-07-2025_portfolio-optimization/index.html#beyond-mean-variance",
    "href": "posts/26-07-2025_portfolio-optimization/index.html#beyond-mean-variance",
    "title": "A Guide to Portfolio Optimization",
    "section": "5 Beyond Mean-Variance",
    "text": "5 Beyond Mean-Variance\nThe Mean-Variance framework is a great starting point, but it has its limitations. It assumes that returns are normally distributed and that variance is a good measure of risk. In reality, financial returns often have “fat tails,” meaning that extreme events are more common than a normal distribution would suggest.\nTo address these issues, more advanced methods have been developed:\n\nCVaR Optimization: Instead of minimizing variance, this method minimizes Conditional Value-at-Risk (CVaR), which is the expected loss in the worst-case scenarios. This is better at capturing tail risk.\nGenetic Algorithms: These are optimization techniques inspired by natural evolution. They can be used to solve very complex portfolio optimization problems with many constraints.\n\nThese methods are more complex, but they can provide a more robust and realistic approach to portfolio optimization."
  },
  {
    "objectID": "posts/26-07-2025_portfolio-optimization/index.html#conclusion",
    "href": "posts/26-07-2025_portfolio-optimization/index.html#conclusion",
    "title": "A Guide to Portfolio Optimization",
    "section": "6 Conclusion",
    "text": "6 Conclusion\nPortfolio optimization is a fundamental concept in finance that helps investors make informed decisions about how to allocate their capital. The Mean-Variance framework developed by Markowitz provides a solid foundation for understanding the trade-off between risk and return. While more advanced methods exist, the principles of diversification and the efficient frontier remain as relevant as ever."
  }
]